{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/backend-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/backend-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Backend } from './backend.js';\nimport { InferenceSession } from './inference-session.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n  error?: string;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, { backend, priority });\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Try to resolve and initialize a backend.\n *\n * @param backendName - the name of the backend.\n * @returns the backend instance if resolved and initialized successfully, or an error message if failed.\n */\nconst tryResolveAndInitializeBackend = async (backendName: string): Promise<Backend | string> => {\n  const backendInfo = backends.get(backendName);\n  if (!backendInfo) {\n    return 'backend not found.';\n  }\n\n  if (backendInfo.initialized) {\n    return backendInfo.backend;\n  } else if (backendInfo.aborted) {\n    return backendInfo.error!;\n  } else {\n    const isInitializing = !!backendInfo.initPromise;\n    try {\n      if (!isInitializing) {\n        backendInfo.initPromise = backendInfo.backend.init(backendName);\n      }\n      await backendInfo.initPromise;\n      backendInfo.initialized = true;\n      return backendInfo.backend;\n    } catch (e) {\n      if (!isInitializing) {\n        backendInfo.error = `${e}`;\n        backendInfo.aborted = true;\n      }\n      return backendInfo.error!;\n    } finally {\n      delete backendInfo.initPromise;\n    }\n  }\n};\n\n/**\n * Resolve execution providers from the specific session options.\n *\n * @param options - the session options object.\n * @returns a promise that resolves to a tuple of an initialized backend instance and a session options object with\n * filtered EP list.\n *\n * @ignore\n */\nexport const resolveBackendAndExecutionProviders = async (\n  options: InferenceSession.SessionOptions,\n): Promise<[backend: Backend, options: InferenceSession.SessionOptions]> => {\n  // extract backend hints from session options\n  const eps = options.executionProviders || [];\n  const backendHints = eps.map((i) => (typeof i === 'string' ? i : i.name));\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n\n  // try to resolve and initialize all requested backends\n  let backend: Backend | undefined;\n  const errors = [];\n  const availableBackendNames = new Set<string>();\n  for (const backendName of backendNames) {\n    const resolveResult = await tryResolveAndInitializeBackend(backendName);\n    if (typeof resolveResult === 'string') {\n      errors.push({ name: backendName, err: resolveResult });\n    } else {\n      if (!backend) {\n        backend = resolveResult;\n      }\n      if (backend === resolveResult) {\n        availableBackendNames.add(backendName);\n      }\n    }\n  }\n\n  // if no backend is available, throw error.\n  if (!backend) {\n    throw new Error(`no available backend found. ERR: ${errors.map((e) => `[${e.name}] ${e.err}`).join(', ')}`);\n  }\n\n  // for each explicitly requested backend, if it's not available, output warning message.\n  for (const { name, err } of errors) {\n    if (backendHints.includes(name)) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        `removing requested execution provider \"${name}\" from session options because it is not available: ${err}`,\n      );\n    }\n  }\n\n  const filteredEps = eps.filter((i) => availableBackendNames.has(typeof i === 'string' ? i : i.name));\n\n  return [\n    backend,\n    new Proxy(options, {\n      get: (target, prop) => {\n        if (prop === 'executionProviders') {\n          return filteredEps;\n        }\n        return Reflect.get(target, prop);\n      },\n    }),\n  ];\n};\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;;;AAelC,MAAM,QAAQ,GAA6B,IAAI,GAAG,EAAE,CAAC;AACrD,MAAM,wBAAwB,GAAa,EAAE,CAAC;AAYvC,MAAM,eAAe,GAAG,CAAC,IAAY,EAAE,OAAgB,EAAE,QAAgB,EAAQ,EAAE;IACxF,IAAI,OAAO,IAAI,OAAO,OAAO,CAAC,IAAI,KAAK,UAAU,IAAI,OAAO,OAAO,CAAC,6BAA6B,KAAK,UAAU,EAAE;QAChH,MAAM,cAAc,GAAG,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;QAC1C,IAAI,cAAc,KAAK,SAAS,EAAE;YAChC,QAAQ,CAAC,GAAG,CAAC,IAAI,EAAE;gBAAE,OAAO;gBAAE,QAAQ;YAAA,CAAE,CAAC,CAAC;SAC3C,MAAM,IAAI,cAAc,CAAC,QAAQ,GAAG,QAAQ,EAAE;YAC7C,8EAA8E;YAC9E,OAAO;SACR,MAAM,IAAI,cAAc,CAAC,QAAQ,KAAK,QAAQ,EAAE;YAC/C,IAAI,cAAc,CAAC,OAAO,KAAK,OAAO,EAAE;gBACtC,MAAM,IAAI,KAAK,CAAC,CAAA,yBAAA,EAA4B,IAAI,CAAA,iBAAA,EAAoB,QAAQ,EAAE,CAAC,CAAC;aACjF;SACF;QAED,IAAI,QAAQ,IAAI,CAAC,EAAE;YACjB,MAAM,CAAC,GAAG,wBAAwB,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;YACjD,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;gBACZ,wBAAwB,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;aACvC;YAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,wBAAwB,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;gBACxD,IAAI,QAAQ,CAAC,GAAG,CAAC,wBAAwB,CAAC,CAAC,CAAC,CAAE,CAAC,QAAQ,IAAI,QAAQ,EAAE;oBACnE,wBAAwB,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC;oBAC5C,OAAO;iBACR;aACF;YACD,wBAAwB,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;SACrC;QACD,OAAO;KACR;IAED,MAAM,IAAI,SAAS,CAAC,qBAAqB,CAAC,CAAC;AAC7C,CAAC,CAAC;AAEF;;;;;GAKG,CACH,MAAM,8BAA8B,GAAG,KAAK,EAAE,WAAmB,EAA6B,EAAE;IAC9F,MAAM,WAAW,GAAG,QAAQ,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;IAC9C,IAAI,CAAC,WAAW,EAAE;QAChB,OAAO,oBAAoB,CAAC;KAC7B;IAED,IAAI,WAAW,CAAC,WAAW,EAAE;QAC3B,OAAO,WAAW,CAAC,OAAO,CAAC;KAC5B,MAAM,IAAI,WAAW,CAAC,OAAO,EAAE;QAC9B,OAAO,WAAW,CAAC,KAAM,CAAC;KAC3B,MAAM;QACL,MAAM,cAAc,GAAG,CAAC,CAAC,WAAW,CAAC,WAAW,CAAC;QACjD,IAAI;YACF,IAAI,CAAC,cAAc,EAAE;gBACnB,WAAW,CAAC,WAAW,GAAG,WAAW,CAAC,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;aACjE;YACD,MAAM,WAAW,CAAC,WAAW,CAAC;YAC9B,WAAW,CAAC,WAAW,GAAG,IAAI,CAAC;YAC/B,OAAO,WAAW,CAAC,OAAO,CAAC;SAC5B,CAAC,OAAO,CAAC,EAAE;YACV,IAAI,CAAC,cAAc,EAAE;gBACnB,WAAW,CAAC,KAAK,GAAG,GAAG,CAAC,EAAE,CAAC;gBAC3B,WAAW,CAAC,OAAO,GAAG,IAAI,CAAC;aAC5B;YACD,OAAO,WAAW,CAAC,KAAM,CAAC;SAC3B,QAAS;YACR,OAAO,WAAW,CAAC,WAAW,CAAC;SAChC;KACF;AACH,CAAC,CAAC;AAWK,MAAM,mCAAmC,GAAG,KAAK,EACtD,OAAwC,EAC+B,EAAE;IACzE,6CAA6C;IAC7C,MAAM,GAAG,GAAG,OAAO,CAAC,kBAAkB,IAAI,EAAE,CAAC;IAC7C,MAAM,YAAY,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAI,CAAF,CAAC,KAAQ,CAAC,KAAK,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC;IAC1E,MAAM,YAAY,GAAG,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC,CAAC,wBAAwB,CAAC,CAAC,CAAC,YAAY,CAAC;IAEzF,uDAAuD;IACvD,IAAI,OAA4B,CAAC;IACjC,MAAM,MAAM,GAAG,EAAE,CAAC;IAClB,MAAM,qBAAqB,GAAG,IAAI,GAAG,EAAU,CAAC;IAChD,KAAK,MAAM,WAAW,IAAI,YAAY,CAAE;QACtC,MAAM,aAAa,GAAG,MAAM,8BAA8B,CAAC,WAAW,CAAC,CAAC;QACxE,IAAI,OAAO,aAAa,KAAK,QAAQ,EAAE;YACrC,MAAM,CAAC,IAAI,CAAC;gBAAE,IAAI,EAAE,WAAW;gBAAE,GAAG,EAAE,aAAa;YAAA,CAAE,CAAC,CAAC;SACxD,MAAM;YACL,IAAI,CAAC,OAAO,EAAE;gBACZ,OAAO,GAAG,aAAa,CAAC;aACzB;YACD,IAAI,OAAO,KAAK,aAAa,EAAE;gBAC7B,qBAAqB,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;aACxC;SACF;KACF;IAED,2CAA2C;IAC3C,IAAI,CAAC,OAAO,EAAE;QACZ,MAAM,IAAI,KAAK,CAAC,CAAA,iCAAA,EAAoC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAC,CAAA,EAAI,CAAC,CAAC,IAAI,CAAA,EAAA,EAAK,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;KAC7G;IAED,wFAAwF;IACxF,KAAK,MAAM,EAAE,IAAI,EAAE,GAAG,EAAE,IAAI,MAAM,CAAE;QAClC,IAAI,YAAY,CAAC,QAAQ,CAAC,IAAI,CAAC,EAAE;YAC/B,sCAAsC;YACtC,OAAO,CAAC,IAAI,CACV,CAAA,uCAAA,EAA0C,IAAI,CAAA,oDAAA,EAAuD,GAAG,EAAE,CAC3G,CAAC;SACH;KACF;IAED,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,oBAAsB,CAAC,GAAG,CAAC,OAAO,CAAC,KAAK,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC;IAErG,OAAO;QACL,OAAO;QACP,IAAI,KAAK,CAAC,OAAO,EAAE;YACjB,GAAG,EAAE,CAAC,MAAM,EAAE,IAAI,EAAE,EAAE;gBACpB,IAAI,IAAI,KAAK,oBAAoB,EAAE;oBACjC,OAAO,WAAW,CAAC;iBACpB;gBACD,OAAO,OAAO,CAAC,GAAG,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;YACnC,CAAC;SACF,CAAC;KACH,CAAC;AACJ,CAAC,CAAC"}},
    {"offset": {"line": 134, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/backend.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/backend.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { InferenceSession } from './inference-session.js';\nimport { OnnxValue } from './onnx-value.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = { [name: string]: OnnxValue };\n  type FetchesType = { [name: string]: OnnxValue | null };\n  type ReturnType = { [name: string]: OnnxValue };\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n\n  readonly inputMetadata: readonly InferenceSession.ValueMetadata[];\n  readonly outputMetadata: readonly InferenceSession.ValueMetadata[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(\n    feeds: SessionHandler.FeedsType,\n    fetches: SessionHandler.FetchesType,\n    options: InferenceSession.RunOptions,\n  ): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(backendName: string): Promise<void>;\n\n  createInferenceSessionHandler(\n    uriOrBuffer: string | Uint8Array,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler>;\n}\n\nexport { registerBackend } from './backend-impl.js';\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;AA8DlC,OAAO,EAAE,eAAe,EAAE,MAAM,mBAAmB,CAAC"}},
    {"offset": {"line": 143, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/version.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/version.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.23.2';\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;AAElC,0DAA0D;AAC1D,uCAAuC;;;;;AAEhC,MAAM,OAAO,GAAG,QAAQ,CAAC"}},
    {"offset": {"line": 156, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/env-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/env-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Env } from './env.js';\nimport { version } from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: { common: version },\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', { enumerable: true });\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;AAGlC,OAAO,EAAE,OAAO,EAAE,MAAM,cAAc,CAAC;;AAIvC,IAAI,aAAa,GAA2B,SAAS,CAAC;AAE/C,MAAM,GAAG,GAAQ;IACtB,IAAI,EAAE,CAAA,CAA0B;IAChC,KAAK,EAAE,CAAA,CAAoB;IAC3B,MAAM,EAAE,CAAA,CAAqB;IAC7B,QAAQ,EAAE;QAAE,MAAM,EAAE,0KAAO;IAAA,CAAE;IAE7B,IAAI,QAAQ,EAAC,KAAmB,CAAA;QAC9B,IAAI,KAAK,KAAK,SAAS,EAAE;YACvB,OAAO;SACR;QACD,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI;YAAC,SAAS;YAAE,MAAM;YAAE,SAAS;YAAE,OAAO;YAAE,OAAO;SAAC,CAAC,OAAO,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE;YACvG,MAAM,IAAI,KAAK,CAAC,CAAA,2BAAA,EAA8B,KAAK,EAAE,CAAC,CAAC;SACxD;QACD,aAAa,GAAG,KAAK,CAAC;IACxB,CAAC;IACD,IAAI,QAAQ,IAAA;QACV,OAAO,aAAa,CAAC;IACvB,CAAC;CACF,CAAC;AAEF,kGAAkG;AAClG,MAAM,CAAC,cAAc,CAAC,GAAG,EAAE,UAAU,EAAE;IAAE,UAAU,EAAE,IAAI;AAAA,CAAE,CAAC,CAAC"}},
    {"offset": {"line": 199, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/env.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/env.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env as envImpl } from './env-impl.js';\nimport { TryGetGlobalType } from './type-helper.js';\n\nexport declare namespace Env {\n  export type WasmPathPrefix = string;\n  export interface WasmFilePaths {\n    /**\n     * Specify the override path for the main .wasm file.\n     *\n     * This path should be an absolute path.\n     *\n     * If not modified, the filename of the .wasm file is:\n     * - `ort-wasm-simd-threaded.wasm` for default build\n     * - `ort-wasm-simd-threaded.jsep.wasm` for JSEP build (with WebGPU and WebNN)\n     * - `ort-wasm-simd-threaded.asyncify.wasm` for WebGPU build with Asyncify (with WebNN)\n     */\n    wasm?: URL | string;\n    /**\n     * Specify the override path for the main .mjs file.\n     *\n     * This path should be an absolute path.\n     *\n     * If not modified, the filename of the .mjs file is:\n     * - `ort-wasm-simd-threaded.mjs` for default build\n     * - `ort-wasm-simd-threaded.jsep.mjs` for JSEP build (with WebGPU and WebNN)\n     * - `ort-wasm-simd-threaded.asyncify.mjs` for WebGPU build with Asyncify (with WebNN)\n     */\n    mjs?: URL | string;\n  }\n  export type WasmPrefixOrFilePaths = WasmPathPrefix | WasmFilePaths;\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set a value indicating whether to enable SIMD.\n     *\n     * ONNX Runtime will perform feature detection based on the value of this property. Specifically, when the value is\n     * set to:\n     * - `undefined`, `true` or `\"fixed\"`: will check availability of Fixed-width SIMD.\n     * - `\"relaxed\"`: will check availability of Relaxed SIMD.\n     * - `false`: will not perform SIMD feature checking.\n     *\n     * Setting this property does not make ONNX Runtime to switch to the corresponding runtime automatically. User need\n     * to set `wasmPaths` or `wasmBinary` property to load the corresponding runtime.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean | 'fixed' | 'relaxed';\n\n    /**\n     * set or get a boolean value indicating whether to enable trace.\n     *\n     * @defaultValue `false`\n     *\n     * @deprecated Use `env.trace` instead. If `env.trace` is set, this property will be ignored.\n     */\n    trace?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm/.mjs files, or an object of overrides for both .wasm/.mjs file. The override\n     * path should be an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set a custom buffer which contains the WebAssembly binary. If this property is set, the `wasmPaths` property will\n     * be ignored.\n     */\n    wasmBinary?: ArrayBufferLike | Uint8Array;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl' | 'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly' | 'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuProfilingDataV1TensorMetadata {\n    dims: readonly number[];\n    dataType: string;\n  }\n  export interface WebGpuProfilingDataV1 {\n    version: 1;\n    inputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\n    outputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\n    kernelId: number;\n    kernelType: string;\n    kernelName: string;\n    programName: string;\n    startTime: number;\n    endTime: number;\n  }\n\n  export type WebGpuProfilingData = WebGpuProfilingDataV1;\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     *\n     * @deprecated Use `env.webgpu.profiling.mode` instead. If `env.webgpu.profiling.mode` is set, this property will be\n     * ignored.\n     */\n    profilingMode?: 'off' | 'default';\n    /**\n     * Set or get the profiling configuration.\n     */\n    profiling: {\n      /**\n       * Set or get the profiling mode.\n       *\n       * @defaultValue `'off'`\n       */\n      mode?: 'off' | 'default';\n\n      /**\n       * Set or get a callback function when a profiling data is received. If not set, the profiling data will be\n       * printed to console.\n       */\n      ondata?: (data: WebGpuProfilingData) => void;\n    };\n    /**\n     * Set or get the power preference.\n     *\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\n     * used as options for `navigator.gpu.requestAdapter()`.\n     *\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\n     *\n     * @defaultValue `undefined`\n     *\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\n     * you want to use a specific power preference.\n     */\n    powerPreference?: 'low-power' | 'high-performance';\n    /**\n     * Set or get the force fallback adapter flag.\n     *\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\n     * used as options for `navigator.gpu.requestAdapter()`.\n     *\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\n     *\n     * @defaultValue `undefined`\n     *\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\n     * you want to use a specific fallback option.\n     */\n    forceFallbackAdapter?: boolean;\n    /**\n     * Set or get the adapter for WebGPU.\n     *\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\n     * used as the GPU adapter for the underlying WebGPU backend to create GPU device.\n     *\n     * If this property is not set, it will be available to get after the first WebGPU inference session is created. The\n     * value will be the GPU adapter that created by the underlying WebGPU backend.\n     *\n     * When use with TypeScript, the type of this property is `GPUAdapter` defined in \"@webgpu/types\".\n     *\n     * @deprecated It is no longer recommended to use this property. The latest WebGPU spec adds `GPUDevice.adapterInfo`\n     * (https://www.w3.org/TR/webgpu/#dom-gpudevice-adapterinfo), which allows to get the adapter information from the\n     * device. When it's available, there is no need to set/get the {@link adapter} property.\n     */\n    adapter: TryGetGlobalType<'GPUAdapter'>;\n    /**\n     * Set or get the GPU device for WebGPU.\n     *\n     * There are 3 valid scenarios of accessing this property:\n     * - Set a value before the first WebGPU inference session is created. The value will be used by the WebGPU backend\n     * to perform calculations. If the value is not a `GPUDevice` object, an error will be thrown.\n     * - Get the value before the first WebGPU inference session is created. This will try to create a new GPUDevice\n     * instance. Returns a `Promise` that resolves to a `GPUDevice` object.\n     * - Get the value after the first WebGPU inference session is created. Returns a resolved `Promise` to the\n     * `GPUDevice` object used by the WebGPU backend.\n     */\n    get device(): Promise<TryGetGlobalType<'GPUDevice'>>;\n    set device(value: TryGetGlobalType<'GPUDevice'>);\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal';\n\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * set or get a boolean value indicating whether to enable trace.\n   *\n   * @defaultValue `false`\n   */\n  trace?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;AAElC,OAAO,EAAE,GAAG,IAAI,OAAO,EAAE,MAAM,eAAe,CAAC;;AAwSxC,MAAM,GAAG,GAAQ,0KAAO,CAAC"}},
    {"offset": {"line": 212, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-conversion-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-conversion-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\nimport { Tensor } from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = typeof document !== 'undefined' ? document.createElement('canvas') : new OffscreenCanvas(1, 1);\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d') as\n    | CanvasRenderingContext2D\n    | OffscreenCanvasRenderingContext2D\n    | null;\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {\n      // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof norm.mean === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof norm.bias === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0,\n      gTensorPointer = stride,\n      bTensorPointer = stride * 2,\n      aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\n        const A = aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    if ('toDataURL' in canvas) {\n      return canvas.toDataURL();\n    } else {\n      throw new Error('toDataURL is not supported');\n    }\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext =\n    typeof document !== 'undefined'\n      ? document.createElement('canvas').getContext('2d')\n      : (new OffscreenCanvas(1, 1).getContext('2d') as OffscreenCanvasRenderingContext2D);\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {\n      // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof norm.mean === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof norm.bias === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (\n        (options.format !== undefined && channels === 4 && options.format !== 'RGBA') ||\n        (channels === 3 && options.format !== 'RGB' && options.format !== 'BGR')\n      ) {\n        throw new Error(\"Tensor format doesn't match input tensor dims\");\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0,\n      gImagePointer = 1,\n      bImagePointer = 2,\n      aImagePointer = 3;\n    let rTensorPointer = 0,\n      gTensorPointer = stride,\n      bTensorPointer = stride * 2,\n      aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (\n      let i = 0;\n      i < height * width;\n      rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++\n    ) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\n      image.data[aImagePointer] =\n        aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\n    }\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;AAKlC;;GAEG;;;;;;AACI,MAAM,eAAe,GAAG,CAAC,MAAc,EAAE,OAAgC,EAAU,EAAE;IAC1F,MAAM,MAAM,GAAG,OAAO,QAAQ,KAAK,WAAW,CAAC,CAAC,CAAC,QAAQ,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,IAAI,eAAe,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAC9G,MAAM,CAAC,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IAC9B,MAAM,CAAC,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IAC/B,MAAM,eAAe,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,CAGtC,CAAC;IAET,IAAI,eAAe,IAAI,IAAI,EAAE;QAC3B,+CAA+C;QAC/C,IAAI,KAAa,CAAC;QAClB,IAAI,MAAc,CAAC;QACnB,IAAI,OAAO,EAAE,YAAY,KAAK,SAAS,IAAI,OAAO,CAAC,YAAY,KAAK,MAAM,EAAE;YAC1E,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACvB,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACzB,MAAM;YACL,yBAAyB;YACzB,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACvB,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACzB;QAED,MAAM,WAAW,GAAG,OAAO,EAAE,MAAM,KAAK,SAAS,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC;QAE3E,MAAM,IAAI,GAAG,OAAO,EAAE,IAAI,CAAC;QAC3B,IAAI,QAA0C,CAAC;QAC/C,IAAI,QAA0C,CAAC;QAC/C,IAAI,IAAI,KAAK,SAAS,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,EAAE;YACjD,QAAQ,GAAG;gBAAC,GAAG;gBAAE,GAAG;gBAAE,GAAG;gBAAE,GAAG;aAAC,CAAC;SACjC,MAAM;YACL,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;gBACjC,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;iBAAC,CAAC;aACzD,MAAM;gBACL,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC;gBACzD,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,SAAS,EAAE;oBAC9B,QAAQ,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC5B;aACF;SACF;QACD,IAAI,IAAI,KAAK,SAAS,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,EAAE;YACjD,QAAQ,GAAG;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC;SACzB,MAAM;YACL,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;gBACjC,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;iBAAC,CAAC;aACzD,MAAM;gBACL,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC;gBACzD,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,SAAS,EAAE;oBAC9B,QAAQ,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC5B;aACF;SACF;QAED,MAAM,MAAM,GAAG,MAAM,GAAG,KAAK,CAAC;QAC9B,8BAA8B;QAC9B,IAAI,cAAc,GAAG,CAAC,EACpB,cAAc,GAAG,MAAM,EACvB,cAAc,GAAG,MAAM,GAAG,CAAC,EAC3B,cAAc,GAAG,CAAC,CAAC,CAAC;QAEtB,mEAAmE;QACnE,IAAI,WAAW,KAAK,MAAM,EAAE;YAC1B,cAAc,GAAG,CAAC,CAAC;YACnB,cAAc,GAAG,MAAM,CAAC;YACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;YAC5B,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;SAC7B,MAAM,IAAI,WAAW,KAAK,KAAK,EAAE;YAChC,cAAc,GAAG,CAAC,CAAC;YACnB,cAAc,GAAG,MAAM,CAAC;YACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;SAC7B,MAAM,IAAI,WAAW,KAAK,KAAK,EAAE;YAChC,cAAc,GAAG,CAAC,CAAC;YACnB,cAAc,GAAG,MAAM,CAAC;YACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;SAC7B;QAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,CAAE;YAC/B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,CAAC,EAAE,CAAE;gBAC9B,MAAM,CAAC,GAAG,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;gBAC7F,MAAM,CAAC,GAAG,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;gBAC7F,MAAM,CAAC,GAAG,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;gBAC7F,MAAM,CAAC,GAAG,cAAc,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;gBAC3H,qEAAqE;gBACrE,eAAe,CAAC,SAAS,GAAG,OAAO,GAAG,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC;gBAC5E,eAAe,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;aACtC;SACF;QACD,IAAI,WAAW,IAAI,MAAM,EAAE;YACzB,OAAO,MAAM,CAAC,SAAS,EAAE,CAAC;SAC3B,MAAM;YACL,MAAM,IAAI,KAAK,CAAC,4BAA4B,CAAC,CAAC;SAC/C;KACF,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,2BAA2B,CAAC,CAAC;KAC9C;AACH,CAAC,CAAC;AAKK,MAAM,iBAAiB,GAAG,CAAC,MAAc,EAAE,OAAkC,EAAa,EAAE;IACjG,MAAM,eAAe,GACnB,OAAO,QAAQ,KAAK,WAAW,GAC3B,QAAQ,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC,UAAU,CAAC,IAAI,CAAC,GAChD,IAAI,eAAe,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,UAAU,CAAC,IAAI,CAAuC,CAAC;IACxF,IAAI,KAAgB,CAAC;IACrB,IAAI,eAAe,IAAI,IAAI,EAAE;QAC3B,+CAA+C;QAC/C,IAAI,KAAa,CAAC;QAClB,IAAI,MAAc,CAAC;QACnB,IAAI,QAAgB,CAAC;QACrB,IAAI,OAAO,EAAE,YAAY,KAAK,SAAS,IAAI,OAAO,CAAC,YAAY,KAAK,MAAM,EAAE;YAC1E,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACvB,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACxB,QAAQ,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SAC3B,MAAM;YACL,yBAAyB;YACzB,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACvB,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACxB,QAAQ,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SAC3B;QACD,MAAM,WAAW,GAAG,OAAO,KAAK,SAAS,CAAC,CAAC,CAAC,AAAC,OAAO,CAAC,MAAM,KAAK,SAAS,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,AAAC,KAAK,CAAC;QAE5G,MAAM,IAAI,GAAG,OAAO,EAAE,IAAI,CAAC;QAC3B,IAAI,QAA0C,CAAC;QAC/C,IAAI,QAA0C,CAAC;QAC/C,IAAI,IAAI,KAAK,SAAS,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,EAAE;YACjD,QAAQ,GAAG;gBAAC,GAAG;gBAAE,GAAG;gBAAE,GAAG;gBAAE,GAAG;aAAC,CAAC;SACjC,MAAM;YACL,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;gBACjC,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;iBAAC,CAAC;aACzD,MAAM;gBACL,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,GAAG;iBAAC,CAAC;gBAC3D,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,SAAS,EAAE;oBAC9B,QAAQ,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC5B;aACF;SACF;QACD,IAAI,IAAI,KAAK,SAAS,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,EAAE;YACjD,QAAQ,GAAG;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC;SACzB,MAAM;YACL,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;gBACjC,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI,CAAC,IAAI;iBAAC,CAAC;aACzD,MAAM;gBACL,QAAQ,GAAG;oBAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC;gBACzD,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,SAAS,EAAE;oBAC9B,QAAQ,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC5B;aACF;SACF;QAED,MAAM,MAAM,GAAG,MAAM,GAAG,KAAK,CAAC;QAC9B,IAAI,OAAO,KAAK,SAAS,EAAE;YACzB,IACE,AAAC,OAAO,CAAC,MAAM,KAAK,SAAS,IAAI,QAAQ,KAAK,CAAC,IAAI,OAAO,CAAC,MAAM,KAAK,MAAM,CAAC,GAC5E,QAAQ,KAAK,CAAC,IAAI,OAAO,CAAC,MAAM,KAAK,KAAK,IAAI,OAAO,CAAC,MAAM,KAAK,KAAK,CAAC,CACxE;gBACA,MAAM,IAAI,KAAK,CAAC,+CAA+C,CAAC,CAAC;aAClE;SACF;QAED,8BAA8B;QAC9B,MAAM,IAAI,GAAG,CAAC,CAAC;QACf,IAAI,aAAa,GAAG,CAAC,EACnB,aAAa,GAAG,CAAC,EACjB,aAAa,GAAG,CAAC,EACjB,aAAa,GAAG,CAAC,CAAC;QACpB,IAAI,cAAc,GAAG,CAAC,EACpB,cAAc,GAAG,MAAM,EACvB,cAAc,GAAG,MAAM,GAAG,CAAC,EAC3B,cAAc,GAAG,CAAC,CAAC,CAAC;QAEtB,mEAAmE;QACnE,IAAI,WAAW,KAAK,MAAM,EAAE;YAC1B,cAAc,GAAG,CAAC,CAAC;YACnB,cAAc,GAAG,MAAM,CAAC;YACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;YAC5B,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;SAC7B,MAAM,IAAI,WAAW,KAAK,KAAK,EAAE;YAChC,cAAc,GAAG,CAAC,CAAC;YACnB,cAAc,GAAG,MAAM,CAAC;YACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;SAC7B,MAAM,IAAI,WAAW,KAAK,KAAK,EAAE;YAChC,cAAc,GAAG,CAAC,CAAC;YACnB,cAAc,GAAG,MAAM,CAAC;YACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;SAC7B;QAED,KAAK,GAAG,eAAe,CAAC,eAAe,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;QAEvD,IACE,IAAI,CAAC,GAAG,CAAC,EACT,CAAC,GAAG,MAAM,GAAG,KAAK,EAClB,aAAa,IAAI,IAAI,EAAE,aAAa,IAAI,IAAI,EAAE,aAAa,IAAI,IAAI,EAAE,aAAa,IAAI,IAAI,EAAE,CAAC,EAAE,CAC/F;YACA,KAAK,CAAC,IAAI,CAAC,aAAa,CAAC,GAAG,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;YAC/G,KAAK,CAAC,IAAI,CAAC,aAAa,CAAC,GAAG,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;YAC/G,KAAK,CAAC,IAAI,CAAC,aAAa,CAAC,GAAG,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;YAC/G,KAAK,CAAC,IAAI,CAAC,aAAa,CAAC,GACvB,cAAc,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAE,MAAM,CAAC,IAAI,CAAC,cAAc,EAAE,CAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU;SACpH;KACF,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,2BAA2B,CAAC,CAAC;KAC9C;IACD,OAAO,KAAK,CAAC;AACf,CAAC,CAAC"}},
    {"offset": {"line": 452, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-factory-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-factory-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {\n  OptionsDimensions,\n  OptionsFormat,\n  OptionsNormalizationParameters,\n  OptionsTensorFormat,\n  OptionsTensorLayout,\n  TensorFromGpuBufferOptions,\n  TensorFromImageBitmapOptions,\n  TensorFromImageDataOptions,\n  TensorFromImageElementOptions,\n  TensorFromMLTensorOptions,\n  TensorFromTextureOptions,\n  TensorFromUrlOptions,\n} from './tensor-factory.js';\nimport { Tensor } from './tensor-impl.js';\nimport { Tensor as TensorInterface } from './tensor.js';\n\ninterface BufferToTensorOptions\n  extends OptionsDimensions,\n    OptionsTensorLayout,\n    OptionsNormalizationParameters,\n    OptionsFormat,\n    OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray | undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const { height, width } = options;\n\n  const norm = options.norm ?? { mean: 255, bias: 0 };\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof norm.mean === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof norm.bias === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n    options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4,\n    rImagePointer = 0,\n    gImagePointer = 1,\n    bImagePointer = 2,\n    aImagePointer = 3;\n  let rTensorPointer = 0,\n    gTensorPointer = stride,\n    bTensorPointer = stride * 2,\n    aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (\n    let i = 0;\n    i < stride;\n    i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step\n  ) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor =\n    outputformat === 'RGBA'\n      ? new Tensor('float32', float32Data, [1, 4, height, width])\n      : new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async (\n  image: ImageData | HTMLImageElement | ImageBitmap | string,\n  options?:\n    | TensorFromImageDataOptions\n    | TensorFromImageElementOptions\n    | TensorFromImageBitmapOptions\n    | TensorFromUrlOptions,\n): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof ImageData !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray | undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  const createCanvas = () => {\n    if (typeof document !== 'undefined') {\n      return document.createElement('canvas');\n    } else if (typeof OffscreenCanvas !== 'undefined') {\n      return new OffscreenCanvas(1, 1);\n    } else {\n      throw new Error('Canvas is not supported');\n    }\n  };\n  const createCanvasContext = (canvas: HTMLCanvasElement | OffscreenCanvas) => {\n    if (typeof HTMLCanvasElement !== 'undefined' && canvas instanceof HTMLCanvasElement) {\n      return canvas.getContext('2d');\n    } else if (canvas instanceof OffscreenCanvas) {\n      return canvas.getContext('2d') as OffscreenCanvasRenderingContext2D;\n    } else {\n      return null;\n    }\n  };\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = createCanvas();\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = createCanvasContext(canvas);\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = createCanvas();\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = createCanvasContext(tempCanvas);\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = createCanvas();\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = createCanvasContext(canvas);\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = createCanvas();\n      const context = createCanvasContext(canvas);\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n  texture: TensorInterface.TextureType,\n  options: TensorFromTextureOptions<T>,\n): Tensor => {\n  const { width, height, download, dispose } = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({ location: 'texture', type: 'float32', texture, dims, download, dispose });\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n  gpuBuffer: TensorInterface.GpuBufferType,\n  options: TensorFromGpuBufferOptions<T>,\n): Tensor => {\n  const { dataType, dims, download, dispose } = options;\n  return new Tensor({ location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose });\n};\n\n/**\n * implementation of Tensor.fromMLTensor().\n */\nexport const tensorFromMLTensor = <T extends TensorInterface.MLTensorDataTypes>(\n  mlTensor: TensorInterface.MLTensorType,\n  options: TensorFromMLTensorOptions<T>,\n): Tensor => {\n  const { dataType, dims, download, dispose } = options;\n  return new Tensor({ location: 'ml-tensor', type: dataType ?? 'float32', mlTensor, dims, download, dispose });\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n  type: T,\n  buffer: TensorInterface.DataTypeMap[T],\n  dims?: readonly number[],\n): Tensor => new Tensor({ location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length] });\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;;;;;;;;;;;AAgBlC,OAAO,EAAE,MAAM,EAAE,MAAM,kBAAkB,CAAC;;AAiBnC,MAAM,cAAc,GAAG,CAAC,MAAqC,EAAE,OAA8B,EAAU,EAAE;IAC9G,IAAI,MAAM,KAAK,SAAS,EAAE;QACxB,MAAM,IAAI,KAAK,CAAC,8BAA8B,CAAC,CAAC;KACjD;IACD,IAAI,OAAO,CAAC,MAAM,KAAK,SAAS,IAAI,OAAO,CAAC,KAAK,KAAK,SAAS,EAAE;QAC/D,MAAM,IAAI,KAAK,CAAC,wCAAwC,CAAC,CAAC;KAC3D;IACD,IAAI,OAAO,CAAC,YAAY,KAAK,MAAM,EAAE;QACnC,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;KAC5D;IAED,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,GAAG,OAAO,CAAC;IAElC,MAAM,IAAI,GAAG,OAAO,CAAC,IAAI,IAAI;QAAE,IAAI,EAAE,GAAG;QAAE,IAAI,EAAE,CAAC;IAAA,CAAE,CAAC;IACpD,IAAI,QAA0C,CAAC;IAC/C,IAAI,QAA0C,CAAC;IAE/C,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;QACjC,QAAQ,GAAG;YAAC,IAAI,CAAC,IAAI;YAAE,IAAI,CAAC,IAAI;YAAE,IAAI,CAAC,IAAI;YAAE,IAAI,CAAC,IAAI;SAAC,CAAC;KACzD,MAAM;QACL,QAAQ,GAAG;YAAC,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC,IAAI,GAAG;SAAC,CAAC;KAChF;IAED,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;QACjC,QAAQ,GAAG;YAAC,IAAI,CAAC,IAAI;YAAE,IAAI,CAAC,IAAI;YAAE,IAAI,CAAC,IAAI;YAAE,IAAI,CAAC,IAAI;SAAC,CAAC;KACzD,MAAM;QACL,QAAQ,GAAG;YAAC,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,IAAK,CAAC,CAAC,CAAC,IAAI,CAAC;SAAC,CAAC;KAC9E;IAED,MAAM,WAAW,GAAG,OAAO,CAAC,MAAM,KAAK,SAAS,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC;IAC3E,qEAAqE;IAErE,MAAM,YAAY,GAChB,OAAO,CAAC,YAAY,KAAK,SAAS,CAAC,CAAC,CAAC,AAAC,OAAO,CAAC,YAAY,KAAK,SAAS,CAAC,CAAC,CAAC,OAAO,CAAC,YAAY,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,AAAC,KAAK,CAAC;IACnH,MAAM,MAAM,GAAG,MAAM,GAAG,KAAK,CAAC;IAC9B,MAAM,WAAW,GAAG,YAAY,KAAK,MAAM,CAAC,CAAC,CAAC,IAAI,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;IAE1G,8BAA8B;IAC9B,IAAI,IAAI,GAAG,CAAC,EACV,aAAa,GAAG,CAAC,EACjB,aAAa,GAAG,CAAC,EACjB,aAAa,GAAG,CAAC,EACjB,aAAa,GAAG,CAAC,CAAC;IACpB,IAAI,cAAc,GAAG,CAAC,EACpB,cAAc,GAAG,MAAM,EACvB,cAAc,GAAG,MAAM,GAAG,CAAC,EAC3B,cAAc,GAAG,CAAC,CAAC,CAAC;IAEtB,mEAAmE;IACnE,IAAI,WAAW,KAAK,KAAK,EAAE;QACzB,IAAI,GAAG,CAAC,CAAC;QACT,aAAa,GAAG,CAAC,CAAC;QAClB,aAAa,GAAG,CAAC,CAAC;QAClB,aAAa,GAAG,CAAC,CAAC;QAClB,aAAa,GAAG,CAAC,CAAC,CAAC;KACpB;IAED,qEAAqE;IACrE,IAAI,YAAY,KAAK,MAAM,EAAE;QAC3B,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;KAC7B,MAAM,IAAI,YAAY,KAAK,KAAK,EAAE;QACjC,cAAc,GAAG,CAAC,CAAC;QACnB,cAAc,GAAG,MAAM,CAAC;QACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;KAC7B,MAAM,IAAI,YAAY,KAAK,KAAK,EAAE;QACjC,cAAc,GAAG,CAAC,CAAC;QACnB,cAAc,GAAG,MAAM,CAAC;QACxB,cAAc,GAAG,MAAM,GAAG,CAAC,CAAC;KAC7B;IAED,IACE,IAAI,CAAC,GAAG,CAAC,EACT,CAAC,GAAG,MAAM,EACV,CAAC,EAAE,EAAE,aAAa,IAAI,IAAI,EAAE,aAAa,IAAI,IAAI,EAAE,aAAa,IAAI,IAAI,EAAE,aAAa,IAAI,IAAI,CAC/F;QACA,WAAW,CAAC,cAAc,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;QACpF,WAAW,CAAC,cAAc,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;QACpF,WAAW,CAAC,cAAc,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;QACpF,IAAI,cAAc,KAAK,CAAC,CAAC,IAAI,aAAa,KAAK,CAAC,CAAC,EAAE;YACjD,WAAW,CAAC,cAAc,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;SACrF;KACF;IAED,6BAA6B;IAC7B,MAAM,YAAY,GAChB,YAAY,KAAK,MAAM,GACnB,IAAI,gLAAM,CAAC,SAAS,EAAE,WAAW,EAAE;QAAC,CAAC;QAAE,CAAC;QAAE,MAAM;QAAE,KAAK;KAAC,CAAC,GACzD,IAAI,gLAAM,CAAC,SAAS,EAAE,WAAW,EAAE;QAAC,CAAC;QAAE,CAAC;QAAE,MAAM;QAAE,KAAK;KAAC,CAAC,CAAC;IAChE,OAAO,YAAY,CAAC;AACtB,CAAC,CAAC;AAKK,MAAM,eAAe,GAAG,KAAK,EAClC,KAA0D,EAC1D,OAIwB,EACP,EAAE;IACnB,oCAAoC;IACpC,MAAM,cAAc,GAAG,OAAO,gBAAgB,KAAK,WAAW,IAAI,KAAK,YAAY,gBAAgB,CAAC;IACpG,MAAM,cAAc,GAAG,OAAO,SAAS,KAAK,WAAW,IAAI,KAAK,YAAY,SAAS,CAAC;IACtF,MAAM,aAAa,GAAG,OAAO,WAAW,KAAK,WAAW,IAAI,KAAK,YAAY,WAAW,CAAC;IACzF,MAAM,QAAQ,GAAG,OAAO,KAAK,KAAK,QAAQ,CAAC;IAE3C,IAAI,IAAmC,CAAC;IACxC,IAAI,qBAAqB,GAA0B,OAAO,IAAI,CAAA,CAAE,CAAC;IAEjE,MAAM,YAAY,GAAG,GAAG,EAAE;QACxB,IAAI,OAAO,QAAQ,KAAK,WAAW,EAAE;YACnC,OAAO,QAAQ,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;SACzC,MAAM,IAAI,OAAO,eAAe,KAAK,WAAW,EAAE;YACjD,OAAO,IAAI,eAAe,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SAClC,MAAM;YACL,MAAM,IAAI,KAAK,CAAC,yBAAyB,CAAC,CAAC;SAC5C;IACH,CAAC,CAAC;IACF,MAAM,mBAAmB,GAAG,CAAC,MAA2C,EAAE,EAAE;QAC1E,IAAI,OAAO,iBAAiB,KAAK,WAAW,IAAI,MAAM,YAAY,iBAAiB,EAAE;YACnF,OAAO,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;SAChC,MAAM,IAAI,MAAM,YAAY,eAAe,EAAE;YAC5C,OAAO,MAAM,CAAC,UAAU,CAAC,IAAI,CAAsC,CAAC;SACrE,MAAM;YACL,OAAO,IAAI,CAAC;SACb;IACH,CAAC,CAAC;IACF,mDAAmD;IACnD,IAAI,cAAc,EAAE;QAClB,8DAA8D;QAC9D,MAAM,MAAM,GAAG,YAAY,EAAE,CAAC;QAC9B,MAAM,CAAC,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC;QAC3B,MAAM,CAAC,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,eAAe,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;QAEpD,IAAI,eAAe,IAAI,IAAI,EAAE;YAC3B,IAAI,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;YAC1B,IAAI,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC;YACxB,IAAI,OAAO,KAAK,SAAS,IAAI,OAAO,CAAC,aAAa,KAAK,SAAS,IAAI,OAAO,CAAC,YAAY,KAAK,SAAS,EAAE;gBACtG,MAAM,GAAG,OAAO,CAAC,aAAa,CAAC;gBAC/B,KAAK,GAAG,OAAO,CAAC,YAAY,CAAC;aAC9B;YAED,IAAI,OAAO,KAAK,SAAS,EAAE;gBACzB,qBAAqB,GAAG,OAAO,CAAC;gBAChC,IAAI,OAAO,CAAC,YAAY,KAAK,SAAS,EAAE;oBACtC,MAAM,IAAI,KAAK,CAAC,6DAA6D,CAAC,CAAC;iBAChF,MAAM;oBACL,qBAAqB,CAAC,YAAY,GAAG,MAAM,CAAC;iBAC7C;gBACD,qBAAqB,CAAC,MAAM,GAAG,MAAM,CAAC;gBACtC,qBAAqB,CAAC,KAAK,GAAG,KAAK,CAAC;aACrC,MAAM;gBACL,qBAAqB,CAAC,YAAY,GAAG,MAAM,CAAC;gBAC5C,qBAAqB,CAAC,MAAM,GAAG,MAAM,CAAC;gBACtC,qBAAqB,CAAC,KAAK,GAAG,KAAK,CAAC;aACrC;YAED,eAAe,CAAC,SAAS,CAAC,KAAK,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACvC,IAAI,GAAG,eAAe,CAAC,YAAY,CAAC,CAAC,EAAE,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC,IAAI,CAAC;SAC/D,MAAM;YACL,MAAM,IAAI,KAAK,CAAC,2BAA2B,CAAC,CAAC;SAC9C;KACF,MAAM,IAAI,cAAc,EAAE;QACzB,IAAI,MAAc,CAAC;QACnB,IAAI,KAAa,CAAC;QAElB,IAAI,OAAO,KAAK,SAAS,IAAI,OAAO,CAAC,YAAY,KAAK,SAAS,IAAI,OAAO,CAAC,aAAa,KAAK,SAAS,EAAE;YACtG,MAAM,GAAG,OAAO,CAAC,aAAa,CAAC;YAC/B,KAAK,GAAG,OAAO,CAAC,YAAY,CAAC;SAC9B,MAAM;YACL,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;YACtB,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC;SACrB;QAED,IAAI,OAAO,KAAK,SAAS,EAAE;YACzB,qBAAqB,GAAG,OAAO,CAAC;SACjC;QACD,qBAAqB,CAAC,MAAM,GAAG,MAAM,CAAC;QACtC,qBAAqB,CAAC,MAAM,GAAG,MAAM,CAAC;QACtC,qBAAqB,CAAC,KAAK,GAAG,KAAK,CAAC;QAEpC,IAAI,OAAO,KAAK,SAAS,EAAE;YACzB,MAAM,UAAU,GAAG,YAAY,EAAE,CAAC;YAElC,UAAU,CAAC,KAAK,GAAG,KAAK,CAAC;YACzB,UAAU,CAAC,MAAM,GAAG,MAAM,CAAC;YAE3B,MAAM,eAAe,GAAG,mBAAmB,CAAC,UAAU,CAAC,CAAC;YAExD,IAAI,eAAe,IAAI,IAAI,EAAE;gBAC3B,eAAe,CAAC,YAAY,CAAC,KAAK,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;gBAC1C,IAAI,GAAG,eAAe,CAAC,YAAY,CAAC,CAAC,EAAE,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC,IAAI,CAAC;aAC/D,MAAM;gBACL,MAAM,IAAI,KAAK,CAAC,2BAA2B,CAAC,CAAC;aAC9C;SACF,MAAM;YACL,IAAI,GAAG,KAAK,CAAC,IAAI,CAAC;SACnB;KACF,MAAM,IAAI,aAAa,EAAE;QACxB,+DAA+D;QAC/D,IAAI,OAAO,KAAK,SAAS,EAAE;YACzB,MAAM,IAAI,KAAK,CAAC,yDAAyD,CAAC,CAAC;SAC5E;QAED,MAAM,MAAM,GAAG,YAAY,EAAE,CAAC;QAC9B,MAAM,CAAC,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC;QAC3B,MAAM,CAAC,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;QAC7B,MAAM,eAAe,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;QAEpD,IAAI,eAAe,IAAI,IAAI,EAAE;YAC3B,MAAM,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC;YAC5B,MAAM,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC;YAC1B,eAAe,CAAC,SAAS,CAAC,KAAK,EAAE,CAAC,EAAE,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC;YACtD,IAAI,GAAG,eAAe,CAAC,YAAY,CAAC,CAAC,EAAE,CAAC,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC,IAAI,CAAC;YAC9D,qBAAqB,CAAC,MAAM,GAAG,MAAM,CAAC;YACtC,qBAAqB,CAAC,KAAK,GAAG,KAAK,CAAC;YACpC,OAAO,cAAc,CAAC,IAAI,EAAE,qBAAqB,CAAC,CAAC;SACpD,MAAM;YACL,MAAM,IAAI,KAAK,CAAC,2BAA2B,CAAC,CAAC;SAC9C;KACF,MAAM,IAAI,QAAQ,EAAE;QACnB,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACrC,MAAM,MAAM,GAAG,YAAY,EAAE,CAAC;YAC9B,MAAM,OAAO,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;YAC5C,IAAI,CAAC,KAAK,IAAI,CAAC,OAAO,EAAE;gBACtB,OAAO,MAAM,EAAE,CAAC;aACjB;YACD,MAAM,QAAQ,GAAG,IAAI,KAAK,EAAE,CAAC;YAC7B,QAAQ,CAAC,WAAW,GAAG,WAAW,CAAC;YACnC,QAAQ,CAAC,GAAG,GAAG,KAAK,CAAC;YACrB,QAAQ,CAAC,MAAM,GAAG,GAAG,EAAE;gBACrB,MAAM,CAAC,KAAK,GAAG,QAAQ,CAAC,KAAK,CAAC;gBAC9B,MAAM,CAAC,MAAM,GAAG,QAAQ,CAAC,MAAM,CAAC;gBAChC,OAAO,CAAC,SAAS,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;gBAC/D,MAAM,GAAG,GAAG,OAAO,CAAC,YAAY,CAAC,CAAC,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;gBAEpE,qBAAqB,CAAC,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC;gBAC7C,qBAAqB,CAAC,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC;gBAC3C,OAAO,CAAC,cAAc,CAAC,GAAG,CAAC,IAAI,EAAE,qBAAqB,CAAC,CAAC,CAAC;YAC3D,CAAC,CAAC;QACJ,CAAC,CAAC,CAAC;KACJ,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,gEAAgE,CAAC,CAAC;KACnF;IAED,IAAI,IAAI,KAAK,SAAS,EAAE;QACtB,OAAO,cAAc,CAAC,IAAI,EAAE,qBAAqB,CAAC,CAAC;KACpD,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,gEAAgE,CAAC,CAAC;KACnF;AACH,CAAC,CAAC;AAKK,MAAM,iBAAiB,GAAG,CAC/B,OAAoC,EACpC,OAAoC,EAC5B,EAAE;IACV,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,GAAG,OAAO,CAAC;IACrD,gEAAgE;IAChE,MAAM,IAAI,GAAG;QAAC,CAAC;QAAE,MAAM;QAAE,KAAK;QAAE,CAAC;KAAC,CAAC;IACnC,OAAO,IAAI,gLAAM,CAAC;QAAE,QAAQ,EAAE,SAAS;QAAE,IAAI,EAAE,SAAS;QAAE,OAAO;QAAE,IAAI;QAAE,QAAQ;QAAE,OAAO;IAAA,CAAE,CAAC,CAAC;AAChG,CAAC,CAAC;AAKK,MAAM,mBAAmB,GAAG,CACjC,SAAwC,EACxC,OAAsC,EAC9B,EAAE;IACV,MAAM,EAAE,QAAQ,EAAE,IAAI,EAAE,QAAQ,EAAE,OAAO,EAAE,GAAG,OAAO,CAAC;IACtD,OAAO,IAAI,gLAAM,CAAC;QAAE,QAAQ,EAAE,YAAY;QAAE,IAAI,EAAE,QAAQ,IAAI,SAAS;QAAE,SAAS;QAAE,IAAI;QAAE,QAAQ;QAAE,OAAO;IAAA,CAAE,CAAC,CAAC;AACjH,CAAC,CAAC;AAKK,MAAM,kBAAkB,GAAG,CAChC,QAAsC,EACtC,OAAqC,EAC7B,EAAE;IACV,MAAM,EAAE,QAAQ,EAAE,IAAI,EAAE,QAAQ,EAAE,OAAO,EAAE,GAAG,OAAO,CAAC;IACtD,OAAO,IAAI,gLAAM,CAAC;QAAE,QAAQ,EAAE,WAAW;QAAE,IAAI,EAAE,QAAQ,IAAI,SAAS;QAAE,QAAQ;QAAE,IAAI;QAAE,QAAQ;QAAE,OAAO;IAAA,CAAE,CAAC,CAAC;AAC/G,CAAC,CAAC;AAKK,MAAM,sBAAsB,GAAG,CACpC,IAAO,EACP,MAAsC,EACtC,IAAwB,EAChB,CAAG,CAAD,GAAK,gLAAM,CAAC;QAAE,QAAQ,EAAE,YAAY;QAAE,IAAI;QAAE,IAAI,EAAE,MAAM;QAAE,IAAI,EAAE,IAAI,IAAI;YAAC,MAAM,CAAC,MAAM;SAAC;IAAA,CAAE,CAAC,CAAC"}},
    {"offset": {"line": 757, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-impl-type-mapping.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-impl-type-mapping.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from './tensor.js';\n\nexport type SupportedTypedArrayConstructors =\n  | Float32ArrayConstructor\n  | Uint8ArrayConstructor\n  | Int8ArrayConstructor\n  | Uint16ArrayConstructor\n  | Int16ArrayConstructor\n  | Int32ArrayConstructor\n  | BigInt64ArrayConstructor\n  | Uint8ArrayConstructor\n  | Float64ArrayConstructor\n  | Uint32ArrayConstructor\n  | BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n  ['int4', Uint8Array],\n  ['uint4', Uint8Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt/Float16Array checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt/Float16Array\n// polyfill if available.\nlet isTypedArrayChecked = false;\nexport const checkTypedArray = () => {\n  if (!isTypedArrayChecked) {\n    isTypedArrayChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && BigInt64Array.from;\n    const isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && BigUint64Array.from;\n\n    // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\n    const Float16Array = (globalThis as any).Float16Array;\n    const isFloat16ArrayAvailable = typeof Float16Array !== 'undefined' && Float16Array.from;\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n    if (isFloat16ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Float16Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(Float16Array, 'float16');\n    } else {\n      // if Float16Array is not available, use 'Uint16Array' to store the data.\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Uint16Array);\n    }\n  }\n};\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;AAkBlC,kGAAkG;;;;;;;;;AAC3F,MAAM,qCAAqC,GAAG,IAAI,GAAG,CAA0C;IACpG;QAAC,SAAS;QAAE,YAAY;KAAC;IACzB;QAAC,OAAO;QAAE,UAAU;KAAC;IACrB;QAAC,MAAM;QAAE,SAAS;KAAC;IACnB;QAAC,QAAQ;QAAE,WAAW;KAAC;IACvB;QAAC,OAAO;QAAE,UAAU;KAAC;IACrB;QAAC,OAAO;QAAE,UAAU;KAAC;IACrB;QAAC,MAAM;QAAE,UAAU;KAAC;IACpB;QAAC,SAAS;QAAE,YAAY;KAAC;IACzB;QAAC,QAAQ;QAAE,WAAW;KAAC;IACvB;QAAC,MAAM;QAAE,UAAU;KAAC;IACpB;QAAC,OAAO;QAAE,UAAU;KAAC;CACtB,CAAC,CAAC;AAGI,MAAM,qCAAqC,GAAG,IAAI,GAAG,CAA+C;IACzG;QAAC,YAAY;QAAE,SAAS;KAAC;IACzB;QAAC,UAAU;QAAE,OAAO;KAAC;IACrB;QAAC,SAAS;QAAE,MAAM;KAAC;IACnB;QAAC,WAAW;QAAE,QAAQ;KAAC;IACvB;QAAC,UAAU;QAAE,OAAO;KAAC;IACrB;QAAC,UAAU;QAAE,OAAO;KAAC;IACrB;QAAC,YAAY;QAAE,SAAS;KAAC;IACzB;QAAC,WAAW;QAAE,QAAQ;KAAC;CACxB,CAAC,CAAC;AAEH,oHAAoH;AACpH,oHAAoH;AACpH,yBAAyB;AACzB,IAAI,mBAAmB,GAAG,KAAK,CAAC;AACzB,MAAM,eAAe,GAAG,GAAG,EAAE;IAClC,IAAI,CAAC,mBAAmB,EAAE;QACxB,mBAAmB,GAAG,IAAI,CAAC;QAC3B,MAAM,wBAAwB,GAAG,OAAO,aAAa,KAAK,WAAW,IAAI,aAAa,CAAC,IAAI,CAAC;QAC5F,MAAM,yBAAyB,GAAG,OAAO,cAAc,KAAK,WAAW,IAAI,cAAc,CAAC,IAAI,CAAC;QAE/F,oGAAoG;QACpG,MAAM,YAAY,GAAI,UAAkB,CAAC,YAAY,CAAC;QACtD,MAAM,uBAAuB,GAAG,OAAO,YAAY,KAAK,WAAW,IAAI,YAAY,CAAC,IAAI,CAAC;QAEzF,IAAI,wBAAwB,EAAE;YAC5B,qCAAqC,CAAC,GAAG,CAAC,OAAO,EAAE,aAAa,CAAC,CAAC;YAClE,qCAAqC,CAAC,GAAG,CAAC,aAAa,EAAE,OAAO,CAAC,CAAC;SACnE;QACD,IAAI,yBAAyB,EAAE;YAC7B,qCAAqC,CAAC,GAAG,CAAC,QAAQ,EAAE,cAAc,CAAC,CAAC;YACpE,qCAAqC,CAAC,GAAG,CAAC,cAAc,EAAE,QAAQ,CAAC,CAAC;SACrE;QACD,IAAI,uBAAuB,EAAE;YAC3B,qCAAqC,CAAC,GAAG,CAAC,SAAS,EAAE,YAAY,CAAC,CAAC;YACnE,qCAAqC,CAAC,GAAG,CAAC,YAAY,EAAE,SAAS,CAAC,CAAC;SACpE,MAAM;YACL,yEAAyE;YACzE,qCAAqC,CAAC,GAAG,CAAC,SAAS,EAAE,WAAW,CAAC,CAAC;SACnE;KACF;AACH,CAAC,CAAC"}},
    {"offset": {"line": 881, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-utils-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-utils-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {\n  CpuPinnedConstructorParameters,\n  GpuBufferConstructorParameters,\n  MLTensorConstructorParameters,\n  TextureConstructorParameters,\n} from './tensor-factory.js';\nimport { Tensor } from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    case 'ml-tensor':\n      return new Tensor({\n        location: 'ml-tensor',\n        mlTensor: tensor.mlTensor,\n        type: tensor.type as MLTensorConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;;;AAQlC,OAAO,EAAE,MAAM,EAAE,MAAM,kBAAkB,CAAC;;AAOnC,MAAM,aAAa,GAAG,CAAC,IAAwB,EAAU,EAAE;IAChE,IAAI,IAAI,GAAG,CAAC,CAAC;IACb,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;QACpC,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QACpB,IAAI,OAAO,GAAG,KAAK,QAAQ,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,GAAG,CAAC,EAAE;YACzD,MAAM,IAAI,SAAS,CAAC,CAAA,KAAA,EAAQ,CAAC,CAAA,2BAAA,EAA8B,GAAG,EAAE,CAAC,CAAC;SACnE;QACD,IAAI,GAAG,GAAG,CAAC,EAAE;YACX,MAAM,IAAI,UAAU,CAAC,CAAA,KAAA,EAAQ,CAAC,CAAA,uCAAA,EAA0C,GAAG,EAAE,CAAC,CAAC;SAChF;QACD,IAAI,IAAI,GAAG,CAAC;KACb;IACD,OAAO,IAAI,CAAC;AACd,CAAC,CAAC;AAKK,MAAM,aAAa,GAAG,CAAC,MAAc,EAAE,IAAuB,EAAU,EAAE;IAC/E,OAAQ,MAAM,CAAC,QAAQ,EAAE;QACvB,KAAK,KAAK;YACR,OAAO,IAAI,gLAAM,CAAC,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;QACpD,KAAK,YAAY;YACf,OAAO,IAAI,gLAAM,CAAC;gBAChB,QAAQ,EAAE,YAAY;gBACtB,IAAI,EAAE,MAAM,CAAC,IAA8C;gBAC3D,IAAI,EAAE,MAAM,CAAC,IAA8C;gBAC3D,IAAI;aACL,CAAC,CAAC;QACL,KAAK,SAAS;YACZ,OAAO,IAAI,gLAAM,CAAC;gBAChB,QAAQ,EAAE,SAAS;gBACnB,OAAO,EAAE,MAAM,CAAC,OAAO;gBACvB,IAAI,EAAE,MAAM,CAAC,IAA4C;gBACzD,IAAI;aACL,CAAC,CAAC;QACL,KAAK,YAAY;YACf,OAAO,IAAI,gLAAM,CAAC;gBAChB,QAAQ,EAAE,YAAY;gBACtB,SAAS,EAAE,MAAM,CAAC,SAAS;gBAC3B,IAAI,EAAE,MAAM,CAAC,IAA8C;gBAC3D,IAAI;aACL,CAAC,CAAC;QACL,KAAK,WAAW;YACd,OAAO,IAAI,gLAAM,CAAC;gBAChB,QAAQ,EAAE,WAAW;gBACrB,QAAQ,EAAE,MAAM,CAAC,QAAQ;gBACzB,IAAI,EAAE,MAAM,CAAC,IAA6C;gBAC1D,IAAI;aACL,CAAC,CAAC;QACL;YACE,MAAM,IAAI,KAAK,CAAC,CAAA,+BAAA,EAAkC,MAAM,CAAC,QAAQ,CAAA,iBAAA,CAAmB,CAAC,CAAC;KACzF;AACH,CAAC,CAAC"}},
    {"offset": {"line": 945, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { tensorToDataURL, tensorToImageData } from './tensor-conversion-impl.js';\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\nimport {\n  tensorFromGpuBuffer,\n  tensorFromImage,\n  tensorFromMLTensor,\n  tensorFromPinnedBuffer,\n  tensorFromTexture,\n} from './tensor-factory-impl.js';\nimport {\n  CpuPinnedConstructorParameters,\n  GpuBufferConstructorParameters,\n  MLTensorConstructorParameters,\n  TensorFromGpuBufferOptions,\n  TensorFromImageBitmapOptions,\n  TensorFromImageDataOptions,\n  TensorFromImageElementOptions,\n  TensorFromMLTensorOptions,\n  TensorFromTextureOptions,\n  TensorFromUrlOptions,\n  TextureConstructorParameters,\n} from './tensor-factory.js';\nimport {\n  checkTypedArray,\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP,\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP,\n  SupportedTypedArray,\n  SupportedTypedArrayConstructors,\n} from './tensor-impl-type-mapping.js';\nimport { calculateSize, tensorReshape } from './tensor-utils-impl.js';\nimport { Tensor as TensorInterface } from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\ntype TensorMLTensorType = TensorInterface.MLTensorType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n    type: TensorType,\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly number[] | readonly boolean[],\n    dims?: readonly number[],\n  );\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly boolean[],\n    dims?: readonly number[],\n  );\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * Construct a new tensor object from the WebNN MLTensor with the given type and dims.\n   *\n   * Tensor's location will be set to 'ml-tensor'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: MLTensorConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n    arg0:\n      | TensorType\n      | TensorDataType\n      | Uint8ClampedArray\n      | readonly string[]\n      | readonly boolean[]\n      | CpuPinnedConstructorParameters\n      | TextureConstructorParameters\n      | GpuBufferConstructorParameters\n      | MLTensorConstructorParameters,\n    arg1?: TensorDataType | Uint8ClampedArray | readonly number[] | readonly string[] | readonly boolean[],\n    arg2?: readonly number[],\n  ) {\n    // perform one-time check for BigInt/Float16Array support\n    checkTypedArray();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if (\n            type !== 'float32' &&\n            type !== 'float16' &&\n            type !== 'int32' &&\n            type !== 'int64' &&\n            type !== 'uint32' &&\n            type !== 'uint8' &&\n            type !== 'bool' &&\n            type !== 'uint4' &&\n            type !== 'int4'\n          ) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'ml-tensor': {\n          if (\n            type !== 'float32' &&\n            type !== 'float16' &&\n            type !== 'int32' &&\n            type !== 'int64' &&\n            type !== 'uint32' &&\n            type !== 'uint64' &&\n            type !== 'int8' &&\n            type !== 'uint8' &&\n            type !== 'bool' &&\n            type !== 'uint4' &&\n            type !== 'int4'\n          ) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from MLTensor`);\n          }\n          this.mlTensorData = arg0.mlTensor;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1 | typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError(\"A string tensor's data must be a string array.\");\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if ((arg0 === 'float16' && typedArrayConstructor === Uint16Array) || arg0 === 'uint4' || arg0 === 'int4') {\n              // - 'float16':\n              //   When no Float16Array polyfill is used, we cannot create 'float16' tensor from number array.\n              //\n              //   Throw error here because when user try to use number array as data,\n              //   e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              //   Uint16Array.from(arg1) which generates wrong data.\n              //\n              // - 'uint4' and 'int4':\n              //   Uint8Array.from(arg1) will generate wrong data for 'uint4' and 'int4' tensor.\n              //\n              throw new TypeError(\n                `Creating a ${arg0} tensor from number array is not supported. Please use ${typedArrayConstructor.name} as data.`,\n              );\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else if (arg1 instanceof Uint8ClampedArray) {\n            if (arg0 === 'uint8') {\n              data = Uint8Array.from(arg1);\n            } else {\n              throw new TypeError(`A Uint8ClampedArray tensor's data must be type of uint8`);\n            }\n          } else if (arg0 === 'float16' && arg1 instanceof Uint16Array && typedArrayConstructor !== Uint16Array) {\n            // when Float16Array is available and data is of type Uint16Array.\n            // We allow Uint16Array to be passed in as data for 'float16' tensor until Float16Array is generally\n            // supported in JavaScript environment.\n\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = new (globalThis as any).Float16Array(arg1.buffer, arg1.byteOffset, arg1.length);\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else if (arg0 instanceof Uint8ClampedArray) {\n          type = 'uint8';\n          data = Uint8Array.from(arg0);\n        } else {\n          // get tensor type from TypedArray\n          const mappedType = NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(\n            arg0.constructor as SupportedTypedArrayConstructors,\n          );\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError(\"A tensor's dims must be a number array\");\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      if ((type === 'uint4' || type === 'int4') && Math.ceil(size / 2) === this.cpuData.length) {\n        // for (u)int4, the data length is half of the tensor size. So we check this special case when size is odd.\n      } else {\n        throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n      }\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n    image: ImageData | HTMLImageElement | ImageBitmap | string,\n    options?:\n      | TensorFromImageDataOptions\n      | TensorFromImageElementOptions\n      | TensorFromImageBitmapOptions\n      | TensorFromUrlOptions,\n  ): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n    texture: TensorTextureType,\n    options: TensorFromTextureOptions<T>,\n  ): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorGpuBufferType,\n    options: TensorFromGpuBufferOptions<T>,\n  ): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromMLTensor<T extends TensorInterface.MLTensorDataTypes>(\n    mlTensor: TensorMLTensorType,\n    options: TensorFromMLTensorOptions<T>,\n  ): TensorInterface {\n    return tensorFromMLTensor(mlTensor, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T,\n    buffer: TensorInterface.DataTypeMap[T],\n    dims?: readonly number[],\n  ): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores the underlying WebNN MLTensor when location is 'ml-tensor'. otherwise empty.\n   */\n  private mlTensorData?: TensorMLTensorType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n        'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.',\n      );\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n\n  get mlTensor(): TensorMLTensorType {\n    this.ensureValid();\n    if (!this.mlTensorData) {\n      throw new Error('The data is not stored as a WebNN MLTensor.');\n    }\n    return this.mlTensorData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer':\n      case 'ml-tensor': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.mlTensorData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;AAElC,OAAO,EAAE,eAAe,EAAE,iBAAiB,EAAE,MAAM,6BAA6B,CAAC;AAEjF,OAAO,EACL,mBAAmB,EACnB,eAAe,EACf,kBAAkB,EAClB,sBAAsB,EACtB,iBAAiB,GAClB,MAAM,0BAA0B,CAAC;AAclC,OAAO,EACL,eAAe,EACf,qCAAqC,EACrC,qCAAqC,GAGtC,MAAM,+BAA+B,CAAC;AACvC,OAAO,EAAE,aAAa,EAAE,aAAa,EAAE,MAAM,wBAAwB,CAAC;;;;;AAiBhE,MAAO,MAAM;IAoDjB;;OAEG,CACH,YACE,IASiC,EACjC,IAAsG,EACtG,IAAwB,CAAA;QAExB,yDAAyD;YACzD,4MAAe,EAAE,CAAC;QAElB,IAAI,IAAgB,CAAC;QACrB,IAAI,IAAuB,CAAC;QAE5B,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,UAAU,IAAI,IAAI,EAAE;YAClD,EAAE;YACF,6CAA6C;YAC7C,EAAE;YACF,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,QAAQ,CAAC;YAClC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;YACjB,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;YACjB,OAAQ,IAAI,CAAC,QAAQ,EAAE;gBACrB,KAAK,YAAY,CAAC;oBAAC;wBACjB,MAAM,6BAA6B,GAAG,kOAAqC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;wBACtF,IAAI,CAAC,6BAA6B,EAAE;4BAClC,MAAM,IAAI,SAAS,CAAC,CAAA,kBAAA,EAAqB,IAAI,CAAA,qCAAA,CAAuC,CAAC,CAAC;yBACvF;wBACD,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,YAAY,6BAA6B,CAAC,EAAE;4BACzD,MAAM,IAAI,SAAS,CAAC,CAAA,yBAAA,EAA4B,6BAA6B,CAAC,IAAI,EAAE,CAAC,CAAC;yBACvF;wBACD,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,IAAI,CAAC;wBACzB,MAAM;qBACP;gBACD,KAAK,SAAS,CAAC;oBAAC;wBACd,IAAI,IAAI,KAAK,SAAS,EAAE;4BACtB,MAAM,IAAI,SAAS,CAAC,CAAA,kBAAA,EAAqB,IAAI,CAAA,+BAAA,CAAiC,CAAC,CAAC;yBACjF;wBACD,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,OAAO,CAAC;wBACnC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,QAAQ,CAAC;wBAChC,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,OAAO,CAAC;wBAC7B,MAAM;qBACP;gBACD,KAAK,YAAY,CAAC;oBAAC;wBACjB,IACE,IAAI,KAAK,SAAS,IAClB,IAAI,KAAK,SAAS,IAClB,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,QAAQ,IACjB,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,MAAM,IACf,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,MAAM,EACf;4BACA,MAAM,IAAI,SAAS,CAAC,CAAA,kBAAA,EAAqB,IAAI,CAAA,kCAAA,CAAoC,CAAC,CAAC;yBACpF;wBACD,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,SAAS,CAAC;wBACpC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,QAAQ,CAAC;wBAChC,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,OAAO,CAAC;wBAC7B,MAAM;qBACP;gBACD,KAAK,WAAW,CAAC;oBAAC;wBAChB,IACE,IAAI,KAAK,SAAS,IAClB,IAAI,KAAK,SAAS,IAClB,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,QAAQ,IACjB,IAAI,KAAK,QAAQ,IACjB,IAAI,KAAK,MAAM,IACf,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,MAAM,IACf,IAAI,KAAK,OAAO,IAChB,IAAI,KAAK,MAAM,EACf;4BACA,MAAM,IAAI,SAAS,CAAC,CAAA,kBAAA,EAAqB,IAAI,CAAA,gCAAA,CAAkC,CAAC,CAAC;yBAClF;wBACD,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,QAAQ,CAAC;wBAClC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,QAAQ,CAAC;wBAChC,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,OAAO,CAAC;wBAC7B,MAAM;qBACP;gBACD;oBACE,MAAM,IAAI,KAAK,CAAC,CAAA,0CAAA,EAA6C,IAAI,CAAC,YAAY,CAAA,CAAA,CAAG,CAAC,CAAC;aACtF;SACF,MAAM;YACL,EAAE;YACF,wCAAwC;YACxC,EAAE;YACF,IAAI,IAAoB,CAAC;YACzB,IAAI,SAAoC,CAAC;YACzC,qCAAqC;YACrC,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;gBAC5B,EAAE;gBACF,yCAAyC;gBACzC,EAAE;gBACF,IAAI,GAAG,IAAI,CAAC;gBACZ,SAAS,GAAG,IAAI,CAAC;gBACjB,IAAI,IAAI,KAAK,QAAQ,EAAE;oBACrB,gBAAgB;oBAChB,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;wBACxB,MAAM,IAAI,SAAS,CAAC,gDAAgD,CAAC,CAAC;qBACvE;oBACD,4GAA4G;oBAC5G,uCAAuC;oBACvC,IAAI,GAAG,IAAI,CAAC;iBACb,MAAM;oBACL,iBAAiB;oBACjB,MAAM,qBAAqB,GAAG,kOAAqC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;oBAC9E,IAAI,qBAAqB,KAAK,SAAS,EAAE;wBACvC,MAAM,IAAI,SAAS,CAAC,CAAA,yBAAA,EAA4B,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;qBAC1D;oBACD,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;wBACvB,IAAI,AAAC,IAAI,KAAK,SAAS,IAAI,qBAAqB,KAAK,WAAW,CAAC,GAAI,IAAI,KAAK,OAAO,IAAI,IAAI,KAAK,MAAM,EAAE;4BACxG,eAAe;4BACf,gGAAgG;4BAChG,EAAE;4BACF,wEAAwE;4BACxE,2EAA2E;4BAC3E,uDAAuD;4BACvD,EAAE;4BACF,wBAAwB;4BACxB,kFAAkF;4BAClF,EAAE;4BACF,MAAM,IAAI,SAAS,CACjB,CAAA,WAAA,EAAc,IAAI,CAAA,uDAAA,EAA0D,qBAAqB,CAAC,IAAI,CAAA,SAAA,CAAW,CAClH,CAAC;yBACH,MAAM,IAAI,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,OAAO,EAAE;4BAChD,6BAA6B;4BAC7B,yFAAyF;4BACzF,2DAA2D;4BAC3D,uGAAuG;4BACvG,mCAAmC;4BACnC,wGAAwG;4BACxG,QAAQ;4BAER,uEAAuE;4BAEvE,8DAA8D;4BAC9D,IAAI,GAAI,qBAA6B,CAAC,IAAI,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC;yBAC1D,MAAM;4BACL,qDAAqD;4BACrD,8DAA8D;4BAC9D,IAAI,GAAI,qBAA6B,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;yBAClD;qBACF,MAAM,IAAI,IAAI,YAAY,qBAAqB,EAAE;wBAChD,IAAI,GAAG,IAAI,CAAC;qBACb,MAAM,IAAI,IAAI,YAAY,iBAAiB,EAAE;wBAC5C,IAAI,IAAI,KAAK,OAAO,EAAE;4BACpB,IAAI,GAAG,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;yBAC9B,MAAM;4BACL,MAAM,IAAI,SAAS,CAAC,CAAA,uDAAA,CAAyD,CAAC,CAAC;yBAChF;qBACF,MAAM,IAAI,IAAI,KAAK,SAAS,IAAI,IAAI,YAAY,WAAW,IAAI,qBAAqB,KAAK,WAAW,EAAE;wBACrG,kEAAkE;wBAClE,oGAAoG;wBACpG,uCAAuC;wBAEvC,8DAA8D;wBAC9D,IAAI,GAAG,IAAK,UAAkB,CAAC,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;qBACxF,MAAM;wBACL,MAAM,IAAI,SAAS,CAAC,CAAA,EAAA,EAAK,IAAI,CAAA,+BAAA,EAAkC,qBAAqB,EAAE,CAAC,CAAC;qBACzF;iBACF;aACF,MAAM;gBACL,EAAE;gBACF,mCAAmC;gBACnC,EAAE;gBACF,SAAS,GAAG,IAAI,CAAC;gBACjB,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;oBACvB,2CAA2C;oBAC3C,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;wBACrB,MAAM,IAAI,SAAS,CAAC,qDAAqD,CAAC,CAAC;qBAC5E;oBACD,MAAM,gBAAgB,GAAG,OAAO,IAAI,CAAC,CAAC,CAAC,CAAC;oBACxC,IAAI,gBAAgB,KAAK,QAAQ,EAAE;wBACjC,IAAI,GAAG,QAAQ,CAAC;wBAChB,IAAI,GAAG,IAAI,CAAC;qBACb,MAAM,IAAI,gBAAgB,KAAK,SAAS,EAAE;wBACzC,IAAI,GAAG,MAAM,CAAC;wBACd,0GAA0G;wBAC1G,gDAAgD;wBAChD,8DAA8D;wBAC9D,IAAI,GAAG,UAAU,CAAC,IAAI,CAAC,IAAa,CAAC,CAAC;qBACvC,MAAM;wBACL,MAAM,IAAI,SAAS,CAAC,CAAA,oCAAA,EAAuC,gBAAgB,CAAA,CAAA,CAAG,CAAC,CAAC;qBACjF;iBACF,MAAM,IAAI,IAAI,YAAY,iBAAiB,EAAE;oBAC5C,IAAI,GAAG,OAAO,CAAC;oBACf,IAAI,GAAG,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;iBAC9B,MAAM;oBACL,kCAAkC;oBAClC,MAAM,UAAU,GAAG,kOAAqC,CAAC,GAAG,CAC1D,IAAI,CAAC,WAA8C,CACpD,CAAC;oBACF,IAAI,UAAU,KAAK,SAAS,EAAE;wBAC5B,MAAM,IAAI,SAAS,CAAC,CAAA,kCAAA,EAAqC,IAAI,CAAC,WAAW,CAAA,CAAA,CAAG,CAAC,CAAC;qBAC/E;oBACD,IAAI,GAAG,UAAU,CAAC;oBAClB,IAAI,GAAG,IAA2B,CAAC;iBACpC;aACF;YAED,kDAAkD;YAClD,IAAI,SAAS,KAAK,SAAS,EAAE;gBAC3B,oCAAoC;gBACpC,SAAS,GAAG;oBAAC,IAAI,CAAC,MAAM;iBAAC,CAAC;aAC3B,MAAM,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC,EAAE;gBACpC,MAAM,IAAI,SAAS,CAAC,wCAAwC,CAAC,CAAC;aAC/D;YACD,IAAI,GAAG,SAA8B,CAAC;YAEtC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;YACpB,IAAI,CAAC,YAAY,GAAG,KAAK,CAAC;SAC3B;QAED,wBAAwB;QACxB,MAAM,IAAI,OAAG,gMAAa,EAAC,IAAI,CAAC,CAAC;QACjC,mEAAmE;QACnE,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,KAAK,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;YAChD,IAAI,CAAC,IAAI,KAAK,OAAO,IAAI,IAAI,KAAK,MAAM,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,CAAC,CAAC,KAAK,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;YACxF,2GAA2G;aAC5G,MAAM;gBACL,MAAM,IAAI,KAAK,CAAC,CAAA,cAAA,EAAiB,IAAI,CAAA,6BAAA,EAAgC,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,EAAA,CAAI,CAAC,CAAC;aAC/F;SACF;QAED,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;QACjB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;QACjB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;IACnB,CAAC;IACD,aAAa;IAEb,kBAAkB;IAClB,MAAM,CAAC,KAAK,CAAC,SAAS,CACpB,KAA0D,EAC1D,OAIwB,EAAA;QAExB,WAAO,oMAAe,EAAC,KAAK,EAAE,OAAO,CAAC,CAAC;IACzC,CAAC;IAED,MAAM,CAAC,WAAW,CAChB,OAA0B,EAC1B,OAAoC,EAAA;QAEpC,WAAO,sMAAiB,EAAC,OAAO,EAAE,OAAO,CAAC,CAAC;IAC7C,CAAC;IAED,MAAM,CAAC,aAAa,CAClB,SAA8B,EAC9B,OAAsC,EAAA;QAEtC,WAAO,wMAAmB,EAAC,SAAS,EAAE,OAAO,CAAC,CAAC;IACjD,CAAC;IAED,MAAM,CAAC,YAAY,CACjB,QAA4B,EAC5B,OAAqC,EAAA;QAErC,WAAO,uMAAkB,EAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;IAC/C,CAAC;IAED,MAAM,CAAC,gBAAgB,CACrB,IAAO,EACP,MAAsC,EACtC,IAAwB,EAAA;QAExB,WAAO,2MAAsB,EAAC,IAAI,EAAE,MAAM,EAAE,IAAI,CAAC,CAAC;IACpD,CAAC;IAED,aAAa;IAEb,sBAAsB;IACtB,SAAS,CAAC,OAAgC,EAAA;QACxC,WAAO,uMAAe,EAAC,IAAI,EAAE,OAAO,CAAC,CAAC;IACxC,CAAC;IAED,WAAW,CAAC,OAAkC,EAAA;QAC5C,WAAO,yMAAiB,EAAC,IAAI,EAAE,OAAO,CAAC,CAAC;IAC1C,CAAC;IAkDD,aAAa;IAEb,qBAAqB;IACrB,IAAI,IAAI,GAAA;QACN,IAAI,CAAC,WAAW,EAAE,CAAC;QACnB,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE;YACjB,MAAM,IAAI,KAAK,CACb,uEAAuE,GACrE,2EAA2E,CAC9E,CAAC;SACH;QACD,OAAO,IAAI,CAAC,OAAO,CAAC;IACtB,CAAC;IAED,IAAI,QAAQ,GAAA;QACV,OAAO,IAAI,CAAC,YAAY,CAAC;IAC3B,CAAC;IAED,IAAI,OAAO,GAAA;QACT,IAAI,CAAC,WAAW,EAAE,CAAC;QACnB,IAAI,CAAC,IAAI,CAAC,cAAc,EAAE;YACxB,MAAM,IAAI,KAAK,CAAC,4CAA4C,CAAC,CAAC;SAC/D;QACD,OAAO,IAAI,CAAC,cAAc,CAAC;IAC7B,CAAC;IAED,IAAI,SAAS,GAAA;QACX,IAAI,CAAC,WAAW,EAAE,CAAC;QACnB,IAAI,CAAC,IAAI,CAAC,aAAa,EAAE;YACvB,MAAM,IAAI,KAAK,CAAC,4CAA4C,CAAC,CAAC;SAC/D;QACD,OAAO,IAAI,CAAC,aAAa,CAAC;IAC5B,CAAC;IAED,IAAI,QAAQ,GAAA;QACV,IAAI,CAAC,WAAW,EAAE,CAAC;QACnB,IAAI,CAAC,IAAI,CAAC,YAAY,EAAE;YACtB,MAAM,IAAI,KAAK,CAAC,6CAA6C,CAAC,CAAC;SAChE;QACD,OAAO,IAAI,CAAC,YAAY,CAAC;IAC3B,CAAC;IACD,aAAa;IAEb,kBAAkB;IAElB,KAAK,CAAC,OAAO,CAAC,WAAqB,EAAA;QACjC,IAAI,CAAC,WAAW,EAAE,CAAC;QACnB,OAAQ,IAAI,CAAC,YAAY,EAAE;YACzB,KAAK,KAAK,CAAC;YACX,KAAK,YAAY;gBACf,OAAO,IAAI,CAAC,IAAI,CAAC;YACnB,KAAK,SAAS,CAAC;YACf,KAAK,YAAY,CAAC;YAClB,KAAK,WAAW,CAAC;gBAAC;oBAChB,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE;wBACpB,MAAM,IAAI,KAAK,CAAC,qEAAqE,CAAC,CAAC;qBACxF;oBACD,IAAI,IAAI,CAAC,aAAa,EAAE;wBACtB,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;qBAC5D;oBACD,IAAI;wBACF,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC;wBAC1B,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,UAAU,EAAE,CAAC;wBACrC,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC;wBAC5B,IAAI,CAAC,YAAY,GAAG,KAAK,CAAC;wBAC1B,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;wBAEpB,IAAI,WAAW,IAAI,IAAI,CAAC,QAAQ,EAAE;4BAChC,IAAI,CAAC,QAAQ,EAAE,CAAC;4BAChB,IAAI,CAAC,QAAQ,GAAG,SAAS,CAAC;yBAC3B;wBAED,OAAO,IAAI,CAAC;qBACb,QAAS;wBACR,IAAI,CAAC,aAAa,GAAG,KAAK,CAAC;qBAC5B;iBACF;YACD;gBACE,MAAM,IAAI,KAAK,CAAC,CAAA,+BAAA,EAAkC,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC1E;IACH,CAAC;IAED,OAAO,GAAA;QACL,IAAI,IAAI,CAAC,aAAa,EAAE;YACtB,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;SAC5D;QAED,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,IAAI,CAAC,QAAQ,EAAE,CAAC;YAChB,IAAI,CAAC,QAAQ,GAAG,SAAS,CAAC;SAC3B;QACD,IAAI,CAAC,OAAO,GAAG,SAAS,CAAC;QACzB,IAAI,CAAC,cAAc,GAAG,SAAS,CAAC;QAChC,IAAI,CAAC,aAAa,GAAG,SAAS,CAAC;QAC/B,IAAI,CAAC,YAAY,GAAG,SAAS,CAAC;QAC9B,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC;QAC5B,IAAI,CAAC,aAAa,GAAG,SAAS,CAAC;QAE/B,IAAI,CAAC,YAAY,GAAG,MAAM,CAAC;IAC7B,CAAC;IAED,aAAa;IAEb,2BAA2B;IACnB,WAAW,GAAA;QACjB,IAAI,IAAI,CAAC,YAAY,KAAK,MAAM,EAAE;YAChC,MAAM,IAAI,KAAK,CAAC,yBAAyB,CAAC,CAAC;SAC5C;IACH,CAAC;IAED,OAAO,CAAC,IAAuB,EAAA;QAC7B,IAAI,CAAC,WAAW,EAAE,CAAC;QACnB,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,QAAQ,EAAE;YACpC,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;SACpE;QACD,WAAO,gMAAa,EAAC,IAAI,EAAE,IAAI,CAAC,CAAC;IACnC,CAAC;CAEF"}},
    {"offset": {"line": 1287, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorFactory } from './tensor-factory.js';\nimport { Tensor as TensorImpl } from './tensor-impl.js';\nimport { TypedTensorUtils } from './tensor-utils.js';\nimport { TryGetGlobalType } from './type-helper.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the WebNN MLTensor that holds the tensor data.\n   *\n   * If the data is not in a WebNN MLTensor, throw error.\n   */\n  readonly mlTensor: Tensor.MLTensorType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array; // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n    uint4: Uint8Array;\n    int4: Int8Array;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number; // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n    uint4: number;\n    int4: number;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  type GpuBufferTypeFallback = { size: number; mapState: 'unmapped' | 'pending' | 'mapped' };\n  /**\n   * type alias for WebGPU buffer\n   */\n  export type GpuBufferType = TryGetGlobalType<'GPUBuffer', GpuBufferTypeFallback>;\n\n  type MLTensorTypeFallback = { destroy(): void };\n  /**\n   * type alias for WebNN MLTensor\n   *\n   * The specification for WebNN's MLTensor is currently in flux.\n   */\n  export type MLTensorType = TryGetGlobalType<'MLTensor', MLTensorTypeFallback>;\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32' | 'float16' | 'int32' | 'int64' | 'uint32' | 'uint8' | 'bool';\n\n  /**\n   * supported data types for constructing a tensor from a WebNN MLTensor\n   */\n  export type MLTensorDataTypes =\n    | 'float32'\n    | 'float16'\n    | 'int8'\n    | 'uint8'\n    | 'int32'\n    | 'uint32'\n    | 'int64'\n    | 'uint64'\n    | 'bool'\n    | 'uint4'\n    | 'int4';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none' | 'cpu' | 'cpu-pinned' | 'texture' | 'gpu-buffer' | 'ml-tensor';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor extends TensorFactory {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (\n    type: 'string',\n    data: Tensor.DataTypeMap['string'] | readonly string[],\n    dims?: readonly number[],\n  ): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (\n    type: 'bool',\n    data: Tensor.DataTypeMap['bool'] | readonly boolean[],\n    dims?: readonly number[],\n  ): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new uint8 tensor object from a Uint8ClampedArray, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (type: 'uint8', data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new <T extends 'uint64' | 'int64'>(\n    type: T,\n    data: Tensor.DataTypeMap[T] | readonly bigint[] | readonly number[],\n    dims?: readonly number[],\n  ): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new <T extends Exclude<Tensor.Type, 'string' | 'bool' | 'uint64' | 'int64'>>(\n    type: T,\n    data: Tensor.DataTypeMap[T] | readonly number[],\n    dims?: readonly number[],\n  ): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (\n    type: Tensor.Type,\n    data: Tensor.DataType | readonly number[] | readonly string[] | readonly bigint[] | readonly boolean[],\n    dims?: readonly number[],\n  ): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as TensorConstructor;\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;AAGlC,OAAO,EAAE,MAAM,IAAI,UAAU,EAAE,MAAM,kBAAkB,CAAC;;AAkYjD,MAAM,MAAM,GAAG,gLAA+B,CAAC"}},
    {"offset": {"line": 1300, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/trace.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/trace.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env } from './env-impl.js';\n\n/**\n * @ignore\n */\nexport const TRACE = (deviceType: string, label: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  // eslint-disable-next-line no-console\n  console.timeStamp(`${deviceType}::ORT::${label}`);\n};\n\nconst TRACE_FUNC = (msg: string, extraMsg?: string) => {\n  const stack = new Error().stack?.split(/\\r\\n|\\r|\\n/g) || [];\n  let hasTraceFunc = false;\n  for (let i = 0; i < stack.length; i++) {\n    if (hasTraceFunc && !stack[i].includes('TRACE_FUNC')) {\n      let label = `FUNC_${msg}::${stack[i].trim().split(' ')[1]}`;\n      if (extraMsg) {\n        label += `::${extraMsg}`;\n      }\n      TRACE('CPU', label);\n      return;\n    }\n    if (stack[i].includes('TRACE_FUNC')) {\n      hasTraceFunc = true;\n    }\n  }\n};\n\n/**\n * @ignore\n */\nexport const TRACE_FUNC_BEGIN = (extraMsg?: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  TRACE_FUNC('BEGIN', extraMsg);\n};\n\n/**\n * @ignore\n */\nexport const TRACE_FUNC_END = (extraMsg?: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  TRACE_FUNC('END', extraMsg);\n};\n\n/**\n * @ignore\n */\nexport const TRACE_EVENT_BEGIN = (extraMsg?: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  // eslint-disable-next-line no-console\n  console.time(`ORT::${extraMsg}`);\n};\n\n/**\n * @ignore\n */\nexport const TRACE_EVENT_END = (extraMsg?: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  // eslint-disable-next-line no-console\n  console.timeEnd(`ORT::${extraMsg}`);\n};\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;;;;;;;;;AAElC,OAAO,EAAE,GAAG,EAAE,MAAM,eAAe,CAAC;;AAK7B,MAAM,KAAK,GAAG,CAAC,UAAkB,EAAE,KAAa,EAAE,EAAE;IACzD,IAAI,OAAO,0KAAG,CAAC,KAAK,KAAK,WAAW,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,KAAK,EAAE;QACnE,OAAO;KACR;IACD,sCAAsC;IACtC,OAAO,CAAC,SAAS,CAAC,GAAG,UAAU,CAAA,OAAA,EAAU,KAAK,EAAE,CAAC,CAAC;AACpD,CAAC,CAAC;AAEF,MAAM,UAAU,GAAG,CAAC,GAAW,EAAE,QAAiB,EAAE,EAAE;IACpD,MAAM,KAAK,GAAG,IAAI,KAAK,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,aAAa,CAAC,IAAI,EAAE,CAAC;IAC5D,IAAI,YAAY,GAAG,KAAK,CAAC;IACzB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;QACrC,IAAI,YAAY,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,YAAY,CAAC,EAAE;YACpD,IAAI,KAAK,GAAG,CAAA,KAAA,EAAQ,GAAG,CAAA,EAAA,EAAK,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;YAC5D,IAAI,QAAQ,EAAE;gBACZ,KAAK,IAAI,CAAA,EAAA,EAAK,QAAQ,EAAE,CAAC;aAC1B;YACD,KAAK,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;YACpB,OAAO;SACR;QACD,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,YAAY,CAAC,EAAE;YACnC,YAAY,GAAG,IAAI,CAAC;SACrB;KACF;AACH,CAAC,CAAC;AAKK,MAAM,gBAAgB,GAAG,CAAC,QAAiB,EAAE,EAAE;IACpD,IAAI,OAAO,0KAAG,CAAC,KAAK,KAAK,WAAW,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,KAAK,EAAE;QACnE,OAAO;KACR;IACD,UAAU,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC;AAChC,CAAC,CAAC;AAKK,MAAM,cAAc,GAAG,CAAC,QAAiB,EAAE,EAAE;IAClD,IAAI,OAAO,0KAAG,CAAC,KAAK,KAAK,WAAW,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,KAAK,EAAE;QACnE,OAAO;KACR;IACD,UAAU,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;AAC9B,CAAC,CAAC;AAKK,MAAM,iBAAiB,GAAG,CAAC,QAAiB,EAAE,EAAE;IACrD,IAAI,OAAO,0KAAG,CAAC,KAAK,KAAK,WAAW,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,KAAK,EAAE;QACnE,OAAO;KACR;IACD,sCAAsC;IACtC,OAAO,CAAC,IAAI,CAAC,CAAA,KAAA,EAAQ,QAAQ,EAAE,CAAC,CAAC;AACnC,CAAC,CAAC;AAKK,MAAM,eAAe,GAAG,CAAC,QAAiB,EAAE,EAAE;IACnD,IAAI,OAAO,0KAAG,CAAC,KAAK,KAAK,WAAW,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,0KAAG,CAAC,KAAK,EAAE;QACnE,OAAO;KACR;IACD,sCAAsC;IACtC,OAAO,CAAC,OAAO,CAAC,CAAA,KAAA,EAAQ,QAAQ,EAAE,CAAC,CAAC;AACtC,CAAC,CAAC"}},
    {"offset": {"line": 1370, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/inference-session-impl.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/inference-session-impl.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { resolveBackendAndExecutionProviders } from './backend-impl.js';\nimport { InferenceSessionHandler } from './backend.js';\nimport { InferenceSession as InferenceSessionInterface } from './inference-session.js';\nimport { OnnxValue } from './onnx-value.js';\nimport { Tensor } from './tensor.js';\nimport { TRACE_FUNC_BEGIN, TRACE_FUNC_END, TRACE_EVENT_BEGIN, TRACE_EVENT_END } from './trace.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType | RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    TRACE_FUNC_BEGIN();\n    TRACE_EVENT_BEGIN('InferenceSession.run');\n    const fetches: { [name: string]: OnnxValue | null } = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n        \"'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.\",\n      );\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError(\"'fetches' cannot be a Tensor\");\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError(\"'fetches' cannot be an empty array.\");\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError(\"'fetches' must be a string array or an object.\");\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError(\"'options' must be an object.\");\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError(\"'options' must be an object.\");\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError(\"Unexpected argument[1]: must be 'fetches' or 'options'.\");\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: { [name: string]: OnnxValue } = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    TRACE_EVENT_END('InferenceSession.run');\n    TRACE_FUNC_END();\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(\n    buffer: ArrayBufferLike,\n    byteOffset: number,\n    byteLength?: number,\n    options?: SessionOptions,\n  ): Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n    arg0: string | ArrayBufferLike | Uint8Array,\n    arg1?: SessionOptions | number,\n    arg2?: number,\n    arg3?: SessionOptions,\n  ): Promise<InferenceSessionInterface> {\n    TRACE_FUNC_BEGIN();\n    TRACE_EVENT_BEGIN('InferenceSession.create');\n    // either load from a file or buffer\n    let filePathOrUint8Array: string | Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError(\"'options' must be an object.\");\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError(\"'options' must be an object.\");\n      }\n    } else if (\n      arg0 instanceof ArrayBuffer ||\n      (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)\n    ) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError(\"'byteOffset' must be an integer.\");\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError(\"'byteLength' must be an integer.\");\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError(\"'options' must be an object.\");\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError(\"'byteLength' must be a number.\");\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError(\"'options' must be an object.\");\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError(\"Unexpected argument[0]: must be 'path' or 'buffer'.\");\n    }\n\n    // resolve backend, update session options with validated EPs, and create session handler\n    const [backend, optionsWithValidatedEPs] = await resolveBackendAndExecutionProviders(options);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, optionsWithValidatedEPs);\n    TRACE_EVENT_END('InferenceSession.create');\n    TRACE_FUNC_END();\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  get inputMetadata(): readonly InferenceSessionInterface.ValueMetadata[] {\n    return this.handler.inputMetadata;\n  }\n\n  get outputMetadata(): readonly InferenceSessionInterface.ValueMetadata[] {\n    return this.handler.outputMetadata;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;AAElC,OAAO,EAAE,mCAAmC,EAAE,MAAM,mBAAmB,CAAC;AAIxE,OAAO,EAAE,MAAM,EAAE,MAAM,aAAa,CAAC;AACrC,OAAO,EAAE,gBAAgB,EAAE,cAAc,EAAE,iBAAiB,EAAE,eAAe,EAAE,MAAM,YAAY,CAAC;;;;AAQ5F,MAAO,gBAAgB;IAC3B,YAAoB,OAAgC,CAAA;QAClD,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;IACzB,CAAC;IAGD,KAAK,CAAC,GAAG,CAAC,KAAgB,EAAE,IAA+B,EAAE,IAAiB,EAAA;YAC5E,iLAAgB,EAAE,CAAC;YACnB,kLAAiB,EAAC,sBAAsB,CAAC,CAAC;QAC1C,MAAM,OAAO,GAAyC,CAAA,CAAE,CAAC;QACzD,IAAI,OAAO,GAAe,CAAA,CAAE,CAAC;QAC7B,eAAe;QACf,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,KAAK,IAAI,IAAI,KAAK,YAAY,wKAAM,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE;YAClG,MAAM,IAAI,SAAS,CACjB,+FAA+F,CAChG,CAAC;SACH;QAED,IAAI,cAAc,GAAG,IAAI,CAAC;QAC1B,yCAAyC;QACzC,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;YAC5B,IAAI,IAAI,KAAK,IAAI,EAAE;gBACjB,MAAM,IAAI,SAAS,CAAC,yCAAyC,CAAC,CAAC;aAChE;YACD,IAAI,IAAI,YAAY,wKAAM,EAAE;gBAC1B,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;aACrD;YAED,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;gBACvB,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;oBACrB,MAAM,IAAI,SAAS,CAAC,qCAAqC,CAAC,CAAC;iBAC5D;gBACD,cAAc,GAAG,KAAK,CAAC;gBACvB,eAAe;gBACf,KAAK,MAAM,IAAI,IAAI,IAAI,CAAE;oBACvB,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;wBAC5B,MAAM,IAAI,SAAS,CAAC,gDAAgD,CAAC,CAAC;qBACvE;oBACD,IAAI,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;wBACzC,MAAM,IAAI,UAAU,CAAC,CAAA,wCAAA,EAA2C,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;qBAC1E;oBACD,OAAO,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC;iBACtB;gBAED,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,IAAI,EAAE;oBAC7C,OAAO,GAAG,IAAI,CAAC;iBAChB,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;oBACtC,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;iBACrD;aACF,MAAM;gBACL,4CAA4C;gBAC5C,yFAAyF;gBACzF,IAAI,SAAS,GAAG,KAAK,CAAC;gBACtB,MAAM,QAAQ,GAAG,MAAM,CAAC,mBAAmB,CAAC,IAAI,CAAC,CAAC;gBAClD,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,WAAW,CAAE;oBACnC,IAAI,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;wBACjC,MAAM,CAAC,GAAI,IAA2D,CAAC,IAAI,CAAC,CAAC;wBAC7E,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,YAAY,wKAAM,EAAE;4BACrC,SAAS,GAAG,IAAI,CAAC;4BACjB,cAAc,GAAG,KAAK,CAAC;4BACvB,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;yBACnB;qBACF;iBACF;gBAED,IAAI,SAAS,EAAE;oBACb,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,IAAI,EAAE;wBAC7C,OAAO,GAAG,IAAI,CAAC;qBAChB,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;wBACtC,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;qBACrD;iBACF,MAAM;oBACL,OAAO,GAAG,IAAkB,CAAC;iBAC9B;aACF;SACF,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;YACtC,MAAM,IAAI,SAAS,CAAC,yDAAyD,CAAC,CAAC;SAChF;QAED,kCAAkC;QAClC,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,UAAU,CAAE;YAClC,IAAI,OAAO,KAAK,CAAC,IAAI,CAAC,KAAK,WAAW,EAAE;gBACtC,MAAM,IAAI,KAAK,CAAC,CAAA,OAAA,EAAU,IAAI,CAAA,wBAAA,CAA0B,CAAC,CAAC;aAC3D;SACF;QAED,gEAAgE;QAChE,IAAI,cAAc,EAAE;YAClB,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,WAAW,CAAE;gBACnC,OAAO,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC;aACtB;SACF;QAED,0CAA0C;QAE1C,MAAM,OAAO,GAAG,MAAM,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC;QAChE,MAAM,WAAW,GAAkC,CAAA,CAAE,CAAC;QACtD,IAAK,MAAM,GAAG,IAAI,OAAO,CAAE;YACzB,IAAI,MAAM,CAAC,cAAc,CAAC,IAAI,CAAC,OAAO,EAAE,GAAG,CAAC,EAAE;gBAC5C,MAAM,MAAM,GAAG,OAAO,CAAC,GAAG,CAAC,CAAC;gBAC5B,IAAI,MAAM,YAAY,wKAAM,EAAE;oBAC5B,WAAW,CAAC,GAAG,CAAC,GAAG,MAAM,CAAC;iBAC3B,MAAM;oBACL,WAAW,CAAC,GAAG,CAAC,GAAG,IAAI,wKAAM,CAAC,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC,IAAI,CAAC,CAAC;iBACtE;aACF;SACF;YACD,gLAAe,EAAC,sBAAsB,CAAC,CAAC;YACxC,+KAAc,EAAE,CAAC;QACjB,OAAO,WAAW,CAAC;IACrB,CAAC;IAED,KAAK,CAAC,OAAO,GAAA;QACX,OAAO,IAAI,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC;IAChC,CAAC;IAWD,MAAM,CAAC,KAAK,CAAC,MAAM,CACjB,IAA2C,EAC3C,IAA8B,EAC9B,IAAa,EACb,IAAqB,EAAA;YAErB,iLAAgB,EAAE,CAAC;YACnB,kLAAiB,EAAC,yBAAyB,CAAC,CAAC;QAC7C,oCAAoC;QACpC,IAAI,oBAAyC,CAAC;QAC9C,IAAI,OAAO,GAAmB,CAAA,CAAE,CAAC;QAEjC,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;YAC5B,oBAAoB,GAAG,IAAI,CAAC;YAC5B,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,IAAI,EAAE;gBAC7C,OAAO,GAAG,IAAI,CAAC;aAChB,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;gBACtC,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;aACrD;SACF,MAAM,IAAI,IAAI,YAAY,UAAU,EAAE;YACrC,oBAAoB,GAAG,IAAI,CAAC;YAC5B,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,IAAI,EAAE;gBAC7C,OAAO,GAAG,IAAI,CAAC;aAChB,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;gBACtC,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;aACrD;SACF,MAAM,IACL,IAAI,YAAY,WAAW,IAC1B,OAAO,iBAAiB,KAAK,WAAW,IAAI,IAAI,YAAY,iBAAiB,CAAC,CAC/E;YACA,MAAM,MAAM,GAAG,IAAI,CAAC;YACpB,IAAI,UAAU,GAAG,CAAC,CAAC;YACnB,IAAI,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;YACjC,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,IAAI,EAAE;gBAC7C,OAAO,GAAG,IAAI,CAAC;aAChB,MAAM,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;gBACnC,UAAU,GAAG,IAAI,CAAC;gBAClB,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE;oBACrC,MAAM,IAAI,UAAU,CAAC,kCAAkC,CAAC,CAAC;iBAC1D;gBACD,IAAI,UAAU,GAAG,CAAC,IAAI,UAAU,IAAI,MAAM,CAAC,UAAU,EAAE;oBACrD,MAAM,IAAI,UAAU,CAAC,CAAA,iCAAA,EAAoC,MAAM,CAAC,UAAU,CAAA,EAAA,CAAI,CAAC,CAAC;iBACjF;gBACD,UAAU,GAAG,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;gBAC1C,IAAI,OAAO,IAAI,KAAK,QAAQ,EAAE;oBAC5B,UAAU,GAAG,IAAI,CAAC;oBAClB,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE;wBACrC,MAAM,IAAI,UAAU,CAAC,kCAAkC,CAAC,CAAC;qBAC1D;oBACD,IAAI,UAAU,IAAI,CAAC,IAAI,UAAU,GAAG,UAAU,GAAG,MAAM,CAAC,UAAU,EAAE;wBAClE,MAAM,IAAI,UAAU,CAAC,CAAA,iCAAA,EAAoC,MAAM,CAAC,UAAU,GAAG,UAAU,CAAA,EAAA,CAAI,CAAC,CAAC;qBAC9F;oBACD,IAAI,OAAO,IAAI,KAAK,QAAQ,IAAI,IAAI,KAAK,IAAI,EAAE;wBAC7C,OAAO,GAAG,IAAI,CAAC;qBAChB,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;wBACtC,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;qBACrD;iBACF,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;oBACtC,MAAM,IAAI,SAAS,CAAC,gCAAgC,CAAC,CAAC;iBACvD;aACF,MAAM,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;gBACtC,MAAM,IAAI,SAAS,CAAC,8BAA8B,CAAC,CAAC;aACrD;YACD,oBAAoB,GAAG,IAAI,UAAU,CAAC,MAAM,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC;SACvE,MAAM;YACL,MAAM,IAAI,SAAS,CAAC,qDAAqD,CAAC,CAAC;SAC5E;QAED,yFAAyF;QACzF,MAAM,CAAC,OAAO,EAAE,uBAAuB,CAAC,GAAG,UAAM,8MAAmC,EAAC,OAAO,CAAC,CAAC;QAC9F,MAAM,OAAO,GAAG,MAAM,OAAO,CAAC,6BAA6B,CAAC,oBAAoB,EAAE,uBAAuB,CAAC,CAAC;YAC3G,gLAAe,EAAC,yBAAyB,CAAC,CAAC;YAC3C,+KAAc,EAAE,CAAC;QACjB,OAAO,IAAI,gBAAgB,CAAC,OAAO,CAAC,CAAC;IACvC,CAAC;IAED,cAAc,GAAA;QACZ,IAAI,CAAC,OAAO,CAAC,cAAc,EAAE,CAAC;IAChC,CAAC;IACD,YAAY,GAAA;QACV,IAAI,CAAC,OAAO,CAAC,YAAY,EAAE,CAAC;IAC9B,CAAC;IAED,IAAI,UAAU,GAAA;QACZ,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC;IACjC,CAAC;IACD,IAAI,WAAW,GAAA;QACb,OAAO,IAAI,CAAC,OAAO,CAAC,WAAW,CAAC;IAClC,CAAC;IAED,IAAI,aAAa,GAAA;QACf,OAAO,IAAI,CAAC,OAAO,CAAC,aAAa,CAAC;IACpC,CAAC;IAED,IAAI,cAAc,GAAA;QAChB,OAAO,IAAI,CAAC,OAAO,CAAC,cAAc,CAAC;IACrC,CAAC;CAGF"}},
    {"offset": {"line": 1572, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/inference-session.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/inference-session.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { InferenceSession as InferenceSessionImpl } from './inference-session-impl.js';\nimport { OnnxModelOptions } from './onnx-model.js';\nimport { OnnxValue, OnnxValueDataLocation } from './onnx-value.js';\nimport type { Tensor } from './tensor.js';\nimport { TryGetGlobalType } from './type-helper.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = { readonly [name: string]: OnnxValue };\n  type NullableOnnxValueMapType = { readonly [name: string]: OnnxValue | null };\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[] | NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions extends OnnxModelOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: { readonly [dimensionName: string]: number };\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled' | 'basic' | 'extended' | 'layout' | 'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential' | 'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Whether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation | { readonly [outputName: string]: OnnxValueDataLocation };\n\n    /**\n     * Whether enable graph capture.\n     * This setting is available only in ONNXRuntime Web for WebGPU EP.\n     */\n    enableGraphCapture?: boolean;\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu', 'dml' (win32), 'coreml' (macOS) and 'cuda' (linux).\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'webgpu' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    coreml: CoreMLExecutionProviderOption;\n    cpu: CpuExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    qnn: QnnExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n    | ExecutionProviderOptionMap[ExecutionProviderName]\n    | ExecutionProviderOption\n    | ExecutionProviderName\n    | string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW' | 'NHWC';\n  }\n\n  // #region WebNN options\n\n  interface WebNNExecutionProviderName extends ExecutionProviderOption {\n    readonly name: 'webnn';\n  }\n\n  /**\n   * Represents a set of options for creating a WebNN MLContext.\n   *\n   * @see https://www.w3.org/TR/webnn/#dictdef-mlcontextoptions\n   */\n  export interface WebNNContextOptions {\n    deviceType?: 'cpu' | 'gpu' | 'npu';\n    numThreads?: number;\n    powerPreference?: 'default' | 'low-power' | 'high-performance';\n  }\n\n  /**\n   * Represents a set of options for WebNN execution provider without MLContext.\n   */\n  export interface WebNNOptionsWithoutMLContext extends WebNNExecutionProviderName, WebNNContextOptions {\n    context?: never;\n  }\n\n  /**\n   * Represents a set of options for WebNN execution provider with MLContext.\n   *\n   * When MLContext is provided, the deviceType is also required so that the WebNN EP can determine the preferred\n   * channel layout.\n   *\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext\n   */\n  export interface WebNNOptionsWithMLContext\n    extends WebNNExecutionProviderName,\n      Omit<WebNNContextOptions, 'deviceType'>,\n      Required<Pick<WebNNContextOptions, 'deviceType'>> {\n    context: TryGetGlobalType<'MLContext'>;\n  }\n\n  /**\n   * Represents a set of options for WebNN execution provider with MLContext which is created from GPUDevice.\n   *\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext-gpudevice\n   */\n  export interface WebNNOptionsWebGpu extends WebNNExecutionProviderName {\n    context: TryGetGlobalType<'MLContext'>;\n    gpuDevice: TryGetGlobalType<'GPUDevice'>;\n  }\n\n  /**\n   * Options for WebNN execution provider.\n   */\n  export type WebNNExecutionProviderOption =\n    | WebNNOptionsWithoutMLContext\n    | WebNNOptionsWithMLContext\n    | WebNNOptionsWebGpu;\n\n  // #endregion\n\n  export interface QnnExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'qnn';\n    /**\n     * Specify the QNN backend type. E.g., 'cpu' or 'htp'.\n     * Mutually exclusive with `backendPath`.\n     *\n     * @default 'htp'\n     */\n    backendType?: string;\n    /**\n     * Specify a path to the QNN backend library.\n     * Mutually exclusive with `backendType`.\n     */\n    backendPath?: string;\n    /**\n     * Specify whether to enable HTP FP16 precision.\n     *\n     * @default true\n     */\n    enableFp16Precision?: boolean;\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    /**\n     * The bit flags for CoreML execution provider.\n     *\n     * ```\n     * COREML_FLAG_USE_CPU_ONLY = 0x001\n     * COREML_FLAG_ENABLE_ON_SUBGRAPH = 0x002\n     * COREML_FLAG_ONLY_ENABLE_DEVICE_WITH_ANE = 0x004\n     * COREML_FLAG_ONLY_ALLOW_STATIC_INPUT_SHAPES = 0x008\n     * COREML_FLAG_CREATE_MLPROGRAM = 0x010\n     * COREML_FLAG_USE_CPU_AND_GPU = 0x020\n     * ```\n     *\n     * See include/onnxruntime/core/providers/coreml/coreml_provider_factory.h for more details.\n     *\n     * This flag is available only in ONNXRuntime (Node.js binding).\n     */\n    coreMlFlags?: number;\n    /**\n     * Specify whether to use CPU only in CoreML EP.\n     *\n     * This setting is available only in ONNXRuntime (react-native).\n     */\n    useCPUOnly?: boolean;\n    useCPUAndGPU?: boolean;\n    /**\n     * Specify whether to enable CoreML EP on subgraph.\n     *\n     * This setting is available only in ONNXRuntime (react-native).\n     */\n    enableOnSubgraph?: boolean;\n    /**\n     * Specify whether to only enable CoreML EP for Apple devices with ANE (Apple Neural Engine).\n     *\n     * This setting is available only in ONNXRuntime (react-native).\n     */\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  /**\n   * The common part of the value metadata type for both tensor and non-tensor values.\n   */\n  export interface ValueMetadataBase {\n    /**\n     * The name of the specified input or output.\n     */\n    readonly name: string;\n  }\n\n  /**\n   * Represents the metadata of a non-tensor value.\n   */\n  export interface NonTensorValueMetadata extends ValueMetadataBase {\n    /**\n     * Get a value indicating whether the value is a tensor.\n     */\n    readonly isTensor: false;\n  }\n\n  /**\n   * Represents the metadata of a tensor value.\n   */\n  export interface TensorValueMetadata extends ValueMetadataBase {\n    /**\n     * Get a value indicating whether the value is a tensor.\n     */\n    readonly isTensor: true;\n    /**\n     * Get the data type of the tensor.\n     */\n    readonly type: Tensor.Type;\n    /**\n     * Get the shape of the tensor.\n     *\n     * If the shape is not defined, the value will an empty array. Otherwise, it will be an array representing the shape\n     * of the tensor. Each element in the array can be a number or a string. If the element is a number, it represents\n     * the corresponding dimension size. If the element is a string, it represents a symbolic dimension.\n     */\n    readonly shape: ReadonlyArray<number | string>;\n  }\n\n  /**\n   * Represents the metadata of a value.\n   */\n  export type ValueMetadata = NonTensorValueMetadata | TensorValueMetadata;\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(\n    feeds: InferenceSession.FeedsType,\n    fetches: InferenceSession.FetchesType,\n    options?: InferenceSession.RunOptions,\n  ): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  /**\n   * Get input metadata of the loaded model.\n   */\n  readonly inputMetadata: readonly InferenceSession.ValueMetadata[];\n\n  /**\n   * Get output metadata of the loaded model.\n   */\n  readonly outputMetadata: readonly InferenceSession.ValueMetadata[];\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(\n    buffer: ArrayBufferLike,\n    byteOffset: number,\n    byteLength?: number,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;;;;;AAElC,OAAO,EAAE,gBAAgB,IAAI,oBAAoB,EAAE,MAAM,6BAA6B,CAAC;;AAwmBhF,MAAM,gBAAgB,GAA4B,wMAAoB,CAAC"}},
    {"offset": {"line": 1585, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-conversion.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-conversion.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { OptionsFormat, OptionsNormalizationParameters, OptionsTensorLayout } from './tensor-factory.js';\n\nexport interface TensorToDataUrlOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\n\nexport interface TensorToImageDataOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\n\nexport interface ConversionUtils {\n  /**\n   * creates a DataURL instance from tensor\n   *\n   * @param options - An optional object representing options for creating a DataURL instance from the tensor.\n   *\n   * The following default settings will be applied:\n   * - `format`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * @returns a DataURL string representing the image converted from tensor data\n   */\n  toDataURL(options?: TensorToDataUrlOptions): string;\n\n  /**\n   * creates an ImageData instance from tensor\n   *\n   * @param options - An optional object representing options for creating an ImageData instance from the tensor.\n   *\n   * The following default settings will be applied:\n   * - `format`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * @returns an ImageData instance representing the image converted from tensor data\n   */\n  toImageData(options?: TensorToImageDataOptions): ImageData;\n}\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC"}},
    {"offset": {"line": 1594, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/tensor-factory.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/tensor-factory.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor, TypedTensor } from './tensor.js';\n\nexport type ImageFormat = 'RGB' | 'RGBA' | 'BGR' | 'RBG';\nexport type ImageTensorLayout = 'NHWC' | 'NCHW';\n\n// the following region contains type definitions for constructing tensor from a specific location.\n\n// #region types for constructing a tensor from a specific location\n\n/**\n * represent common properties of the parameter for constructing a tensor from a specific location.\n */\ninterface CommonConstructorParameters<T> extends Pick<Tensor, 'dims'> {\n  /**\n   * Specify the data type of the tensor.\n   */\n  readonly type: T;\n}\n\n/**\n * represent the parameter for constructing a tensor from a GPU resource.\n */\ninterface GpuResourceConstructorParameters<T extends Tensor.Type> {\n  /**\n   * an optional callback function to download data from GPU to CPU.\n   *\n   * If not provided, the tensor treat the GPU data as external resource.\n   */\n  download?(): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * an optional callback function that will be called when the tensor is disposed.\n   *\n   * If not provided, the tensor treat the GPU data as external resource.\n   */\n  dispose?(): void;\n}\n\n/**\n * represent the parameter for constructing a tensor from a pinned CPU buffer\n */\nexport interface CpuPinnedConstructorParameters<T extends Tensor.CpuPinnedDataTypes = Tensor.CpuPinnedDataTypes>\n  extends CommonConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'cpu-pinned'.\n   */\n  readonly location: 'cpu-pinned';\n  /**\n   * Specify the CPU pinned buffer that holds the tensor data.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n}\n\n/**\n * represent the parameter for constructing a tensor from a WebGL texture\n */\nexport interface TextureConstructorParameters<T extends Tensor.TextureDataTypes = Tensor.TextureDataTypes>\n  extends CommonConstructorParameters<T>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'texture'.\n   */\n  readonly location: 'texture';\n  /**\n   * Specify the WebGL texture that holds the tensor data.\n   */\n  readonly texture: Tensor.TextureType;\n}\n\n/**\n * represent the parameter for constructing a tensor from a WebGPU buffer\n */\nexport interface GpuBufferConstructorParameters<T extends Tensor.GpuBufferDataTypes = Tensor.GpuBufferDataTypes>\n  extends CommonConstructorParameters<T>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'gpu-buffer'.\n   */\n  readonly location: 'gpu-buffer';\n  /**\n   * Specify the WebGPU buffer that holds the tensor data.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n}\n\nexport interface MLTensorConstructorParameters<T extends Tensor.MLTensorDataTypes = Tensor.MLTensorDataTypes>\n  extends CommonConstructorParameters<T>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'ml-tensor'.\n   */\n  readonly location: 'ml-tensor';\n\n  /**\n   * Specify the WebNN MLTensor that holds the tensor data.\n   */\n  readonly mlTensor: Tensor.MLTensorType;\n}\n\n// #endregion\n\n// the following region contains type definitions of each individual options.\n// the tensor factory functions use a composition of those options as the parameter type.\n\n// #region Options fields\n\nexport interface OptionsFormat {\n  /**\n   * Describes the image format represented in RGBA color space.\n   */\n  format?: ImageFormat;\n}\n\nexport interface OptionsTensorFormat {\n  /**\n   * Describes the image format of the tensor.\n   *\n   * NOTE: this is different from option 'format'. While option 'format' represents the original image, 'tensorFormat'\n   * represents the target format of the tensor. A transpose will be performed if they are different.\n   */\n  tensorFormat?: ImageFormat;\n}\n\nexport interface OptionsTensorDataType {\n  /**\n   * Describes the data type of the tensor.\n   */\n  dataType?: 'float32' | 'uint8';\n}\n\nexport interface OptionsTensorLayout {\n  /**\n   * Describes the tensor layout when representing data of one or more image(s).\n   */\n  tensorLayout?: ImageTensorLayout;\n}\n\nexport interface OptionsDimensions {\n  /**\n   * Describes the image height in pixel\n   */\n  height?: number;\n  /**\n   * Describes the image width in pixel\n   */\n  width?: number;\n}\n\nexport interface OptionResizedDimensions {\n  /**\n   * Describes the resized height. If omitted, original height will be used.\n   */\n  resizedHeight?: number;\n  /**\n   * Describes resized width - can be accessed via tensor dimensions as well\n   */\n  resizedWidth?: number;\n}\n\nexport interface OptionsNormalizationParameters {\n  /**\n   * Describes normalization parameters when preprocessing the image as model input.\n   *\n   * Data element are ranged from 0 to 255.\n   */\n  norm?: {\n    /**\n     * The 'bias' value for image normalization.\n     * - If omitted, use default value 0.\n     * - If it's a single number, apply to each channel\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\n     * for the corresponding image format\n     */\n    bias?: number | [number, number, number] | [number, number, number, number];\n    /**\n     * The 'mean' value for image normalization.\n     * - If omitted, use default value 255.\n     * - If it's a single number, apply to each channel\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\n     * for the corresponding image format\n     */\n    mean?: number | [number, number, number] | [number, number, number, number];\n  };\n}\n\n// #endregion\n\n// #region Options composition\n\nexport interface TensorFromImageDataOptions\n  extends OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromImageElementOptions\n  extends OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromUrlOptions\n  extends OptionsDimensions,\n    OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromImageBitmapOptions\n  extends OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromTextureOptions<T extends Tensor.TextureDataTypes>\n  extends Required<OptionsDimensions>,\n    OptionsFormat,\n    GpuResourceConstructorParameters<T> /* TODO: add more */ {}\n\nexport interface TensorFromGpuBufferOptions<T extends Tensor.GpuBufferDataTypes>\n  extends Pick<Tensor, 'dims'>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Describes the data type of the tensor.\n   */\n  dataType?: T;\n}\n\nexport interface TensorFromMLTensorOptions<T extends Tensor.MLTensorDataTypes>\n  extends Pick<Tensor, 'dims'>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Describes the data type of the tensor.\n   */\n  dataType?: T;\n}\n\n// #endregion\n\n/**\n * type TensorFactory defines the factory functions of 'Tensor' to create tensor instances from existing data or\n * resources.\n */\nexport interface TensorFactory {\n  /**\n   * create a tensor from an ImageData object\n   *\n   * @param imageData - the ImageData object to create tensor from\n   * @param options - An optional object representing options for creating tensor from ImageData.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(\n    imageData: ImageData,\n    options?: TensorFromImageDataOptions,\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from a HTMLImageElement object\n   *\n   * @param imageElement - the HTMLImageElement object to create tensor from\n   * @param options - An optional object representing options for creating tensor from HTMLImageElement.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(\n    imageElement: HTMLImageElement,\n    options?: TensorFromImageElementOptions,\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from URL\n   *\n   * @param urlSource - a string as a URL to the image or a data URL containing the image data.\n   * @param options - An optional object representing options for creating tensor from URL.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(urlSource: string, options?: TensorFromUrlOptions): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from an ImageBitmap object\n   *\n   * @param bitmap - the ImageBitmap object to create tensor from\n   * @param options - An optional object representing options for creating tensor from URL.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(\n    bitmap: ImageBitmap,\n    options: TensorFromImageBitmapOptions,\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from a WebGL texture\n   *\n   * @param texture - the WebGLTexture object to create tensor from\n   * @param options - An optional object representing options for creating tensor from WebGL texture.\n   *\n   * The options include following properties:\n   * - `width`: the width of the texture. Required.\n   * - `height`: the height of the texture. Required.\n   * - `format`: the format of the texture. If omitted, assume 'RGBA'.\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\n   * need to provide this function.\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\n   *\n   * @returns a tensor object\n   */\n  fromTexture<T extends Tensor.TextureDataTypes = 'float32'>(\n    texture: Tensor.TextureType,\n    options: TensorFromTextureOptions<T>,\n  ): TypedTensor<'float32'>;\n\n  /**\n   * create a tensor from a WebGPU buffer\n   *\n   * @param buffer - the GPUBuffer object to create tensor from\n   * @param options - An optional object representing options for creating tensor from WebGPU buffer.\n   *\n   * The options include following properties:\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\n   * - `dims`: the dimension of the tensor. Required.\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\n   * need to provide this function.\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\n   *\n   * @returns a tensor object\n   */\n  fromGpuBuffer<T extends Tensor.GpuBufferDataTypes>(\n    buffer: Tensor.GpuBufferType,\n    options: TensorFromGpuBufferOptions<T>,\n  ): TypedTensor<T>;\n\n  /**\n   * create a tensor from a WebNN MLTensor\n   *\n   * @param tensor - the MLTensor object to create tensor from\n   * @param options - An optional object representing options for creating tensor from a WebNN MLTensor.\n   *\n   * The options include following properties:\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\n   * - `dims`: the dimension of the tensor. Required.\n   * - `download`: an optional function to download the tensor data from the MLTensor to CPU. If omitted, the MLTensor\n   * data will not be able to download. Usually, this is provided by the WebNN backend for the inference outputs.\n   * Users don't need to provide this function.\n   * - `dispose`: an optional function to dispose the tensor data on the WebNN MLTensor. If omitted, the MLTensor will\n   * not be disposed. Usually, this is provided by the WebNN backend for the inference outputs. Users don't need to\n   * provide this function.\n   *\n   * @returns a tensor object\n   */\n  fromMLTensor<T extends Tensor.MLTensorDataTypes>(\n    tensor: Tensor.MLTensorType,\n    options: TensorFromMLTensorOptions<T>,\n  ): TypedTensor<T>;\n\n  /**\n   * create a tensor from a pre-allocated buffer. The buffer will be used as a pinned buffer.\n   *\n   * @param type - the tensor element type.\n   * @param buffer - a TypedArray corresponding to the type.\n   * @param dims - specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   *\n   * @returns a tensor object\n   */\n  fromPinnedBuffer<T extends Exclude<Tensor.Type, 'string'>>(\n    type: T,\n    buffer: Tensor.DataTypeMap[T],\n    dims?: readonly number[],\n  ): TypedTensor<T>;\n}\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC"}},
    {"offset": {"line": 1603, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/onnx-model.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/onnx-model.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * A string that represents a file's URL or path.\n *\n * Path is vailable only in onnxruntime-node or onnxruntime-web running in Node.js.\n */\nexport type FileUrlOrPath = string;\n\n/**\n * A Blob object that represents a file.\n */\nexport type FileBlob = Blob;\n\n/**\n * A Uint8Array, ArrayBuffer or SharedArrayBuffer object that represents a file content.\n *\n * When it is an ArrayBuffer or SharedArrayBuffer, the whole buffer is assumed to be the file content.\n */\nexport type FileData = Uint8Array | ArrayBufferLike;\n\n/**\n * Represents a file that can be loaded by the ONNX Runtime JavaScript API.\n */\nexport type FileType = FileUrlOrPath | FileBlob | FileData;\n\n/**\n * Represents an external data file.\n */\nexport interface ExternalDataFileDescription {\n  /**\n   * Specify the external data file.\n   */\n  data: FileType;\n  /**\n   * Specify the file path.\n   */\n  path: string;\n}\n\n/**\n * Represents an external data file.\n *\n * When using a string, it should be a file URL or path that in the same directory as the model file.\n */\nexport type ExternalDataFileType = ExternalDataFileDescription | FileUrlOrPath;\n\n/**\n * Options for model loading.\n */\nexport interface OnnxModelOptions {\n  /**\n   * Specifying a list of files that represents the external data.\n   */\n  externalData?: readonly ExternalDataFileType[];\n}\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC"}},
    {"offset": {"line": 1612, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/onnx-value.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/onnx-value.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from './tensor.js';\n\nexport type NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor | NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC"}},
    {"offset": {"line": 1621, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/onnxruntime-common/dist/esm/index.js","sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-common/lib/index.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript/)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './tensor-conversion.js';\nexport * from './tensor-factory.js';\nexport * from './trace.js';\nexport * from './onnx-model.js';\nexport * from './onnx-value.js';\n"],"names":[],"mappings":"AAAA,4DAA4D;AAC5D,kCAAkC;AAElC;;;;;;;;;;;;;;GAcG;AAEH,cAAc,cAAc,CAAC;AAC7B,cAAc,UAAU,CAAC;AACzB,cAAc,wBAAwB,CAAC;AACvC,cAAc,aAAa,CAAC;AAC5B,cAAc,wBAAwB,CAAC;AACvC,cAAc,qBAAqB,CAAC;AACpC,cAAc,YAAY,CAAC;AAC3B,cAAc,iBAAiB,CAAC;AAChC,cAAc,iBAAiB,CAAC"}},
    {"offset": {"line": 1707, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-utils-env.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-utils-import.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-factory.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-utils.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/run-options.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/session-options.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-common.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-utils-load-file.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/wasm-core-impl.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/proxy-wrapper.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/wasm/session-handler-inference.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/backend-wasm.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/index.ts","file:///C:/Users/Kaelo/store-link/node_modules/onnxruntime-web/lib/version.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nexport const isNode = !!(typeof process !== 'undefined' && process.versions && process.versions.node);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport type { OrtWasmModule } from './wasm-types';\nimport { isNode } from './wasm-utils-env';\n\n/**\n * The origin of the current location.\n *\n * In Node.js, this is undefined.\n */\nconst origin = isNode || typeof location === 'undefined' ? undefined : location.origin;\n\n/**\n * Some bundlers (eg. Webpack) will rewrite `import.meta.url` to a file URL at compile time.\n *\n * This function checks if `import.meta.url` starts with `file:`, but using the `>` and `<` operators instead of\n * `startsWith` function so that code minimizers can remove the dead code correctly.\n *\n * For example, if we use terser to minify the following code:\n * ```js\n * if (\"file://hard-coded-filename\".startsWith(\"file:\")) {\n *   console.log(1)\n * } else {\n *   console.log(2)\n * }\n *\n * if (\"file://hard-coded-filename\" > \"file:\" && \"file://hard-coded-filename\" < \"file;\") {\n *   console.log(3)\n * } else {\n *   console.log(4)\n * }\n * ```\n *\n * The minified code will be:\n * ```js\n * \"file://hard-coded-filename\".startsWith(\"file:\")?console.log(1):console.log(2),console.log(3);\n * ```\n *\n * (use Terser 5.39.0 with default options, https://try.terser.org/)\n *\n * @returns true if the import.meta.url is hardcoded as a file URI.\n */\nexport const isEsmImportMetaUrlHardcodedAsFileUri =\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ESM_IMPORT_META_URL! > 'file:' && BUILD_DEFS.ESM_IMPORT_META_URL! < 'file;';\n\nconst getScriptSrc = (): string | undefined => {\n  // if Nodejs, return undefined\n  if (isNode) {\n    return undefined;\n  }\n  // if It's ESM, use import.meta.url\n  if (BUILD_DEFS.IS_ESM) {\n    // For ESM, if the import.meta.url is a file URL, this usually means the bundler rewrites `import.meta.url` to\n    // the file path at compile time. In this case, this file path cannot be used to determine the runtime URL.\n    //\n    // We need to use the URL constructor like this:\n    // ```js\n    // new URL('actual-bundle-name.js', import.meta.url).href\n    // ```\n    // So that bundler can preprocess the URL correctly.\n    if (isEsmImportMetaUrlHardcodedAsFileUri) {\n      // if the rewritten URL is a relative path, we need to use the origin to resolve the URL.\n\n      // The following is a workaround for Vite.\n      //\n      // Vite uses a bundler(rollup/rolldown) that does not rewrite `import.meta.url` to a file URL. So in theory, this\n      // code path should not be executed in Vite. However, the bundler does not know it and it still try to load the\n      // following pattern:\n      // - `return new URL('filename', import.meta.url).href`\n      //\n      // By replacing the pattern above with the following code, we can skip the resource loading behavior:\n      // - `const URL2 = URL; return new URL2('filename', import.meta.url).href;`\n      //\n      // And it still works in Webpack.\n      const URL2 = URL;\n      return new URL(new URL2(BUILD_DEFS.BUNDLE_FILENAME, BUILD_DEFS.ESM_IMPORT_META_URL).href, origin).href;\n    }\n\n    return BUILD_DEFS.ESM_IMPORT_META_URL;\n  }\n\n  return typeof document !== 'undefined'\n    ? (document.currentScript as HTMLScriptElement)?.src\n    : // use `self.location.href` if available\n      typeof self !== 'undefined'\n      ? self.location?.href\n      : undefined;\n};\n\n/**\n * The classic script source URL. This is not always available in non ESModule environments.\n *\n * In Node.js, this is undefined.\n */\nexport const scriptSrc = getScriptSrc();\n\n/**\n * Infer the wasm path prefix from the script source URL.\n *\n * @returns The inferred wasm path prefix, or undefined if the script source URL is not available or is a blob URL.\n */\nexport const inferWasmPathPrefixFromScriptSrc = (): string | undefined => {\n  if (scriptSrc && !scriptSrc.startsWith('blob:')) {\n    return scriptSrc.substring(0, scriptSrc.lastIndexOf('/') + 1);\n  }\n  return undefined;\n};\n\n/**\n * Check if the given filename with prefix is from the same origin.\n */\nconst isSameOrigin = (filename: string, prefixOverride?: string) => {\n  try {\n    const baseUrl = prefixOverride ?? scriptSrc;\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\n    return url.origin === origin;\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Normalize the inputs to an absolute URL with the given prefix override. If failed, return undefined.\n */\nconst normalizeUrl = (filename: string, prefixOverride?: string) => {\n  const baseUrl = prefixOverride ?? scriptSrc;\n  try {\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\n    return url.href;\n  } catch {\n    return undefined;\n  }\n};\n\n/**\n * Create a fallback URL if an absolute URL cannot be created by the normalizeUrl function.\n */\nconst fallbackUrl = (filename: string, prefixOverride?: string) => `${prefixOverride ?? './'}${filename}`;\n\n/**\n * This helper function is used to preload a module from a URL.\n *\n * If the origin of the worker URL is different from the current origin, the worker cannot be loaded directly.\n * See discussions in https://github.com/webpack-contrib/worker-loader/issues/154\n *\n * In this case, we will fetch the worker URL and create a new Blob URL with the same origin as a workaround.\n *\n * @param absoluteUrl - The absolute URL to preload.\n *\n * @returns - A promise that resolves to a new Blob URL\n */\nconst preload = async (absoluteUrl: string): Promise<string> => {\n  const response = await fetch(absoluteUrl, { credentials: 'same-origin' });\n  const blob = await response.blob();\n  return URL.createObjectURL(blob);\n};\n\n/**\n * This helper function is used to dynamically import a module from a URL.\n *\n * The build script has special handling for this function to ensure that the URL is not bundled into the final output.\n *\n * @param url - The URL to import.\n *\n * @returns - A promise that resolves to the default export of the module.\n */\nconst dynamicImportDefault = async <T>(url: string): Promise<T> =>\n  (await import(/* webpackIgnore: true */ url)).default;\n\n/**\n * The proxy worker factory imported from the proxy worker module.\n *\n * This is only available when the WebAssembly proxy is not disabled.\n */\nconst createProxyWorker: ((urlOverride?: string) => Worker) | undefined =\n  // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n  BUILD_DEFS.DISABLE_WASM_PROXY ? undefined : require('./proxy-worker/main').default;\n\n/**\n * Import the proxy worker.\n *\n * This function will perform the following steps:\n * 1. If a preload is needed, it will preload the module and return the object URL.\n * 2. Use the proxy worker factory to create the proxy worker.\n *\n * @returns - A promise that resolves to a tuple of 2 elements:\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\n *            - The proxy worker.\n */\nexport const importProxyWorker = async (): Promise<[undefined | string, Worker]> => {\n  if (!scriptSrc) {\n    throw new Error('Failed to load proxy worker: cannot determine the script source URL.');\n  }\n\n  // If the script source is from the same origin, we can use the embedded proxy module directly.\n  if (isSameOrigin(scriptSrc)) {\n    return [undefined, createProxyWorker!()];\n  }\n\n  // Otherwise, need to preload\n  const url = await preload(scriptSrc);\n  return [url, createProxyWorker!(url)];\n};\n\n/**\n * The embedded WebAssembly module.\n *\n * This is only available in ESM and when embedding is not disabled.\n */\nconst embeddedWasmModule: EmscriptenModuleFactory<OrtWasmModule> | undefined =\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ENABLE_BUNDLE_WASM_JS\n    ? // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n      require(\n        !BUILD_DEFS.DISABLE_JSEP\n          ? '../../dist/ort-wasm-simd-threaded.jsep.mjs'\n          : !BUILD_DEFS.DISABLE_WEBGPU\n            ? '../../dist/ort-wasm-simd-threaded.asyncify.mjs'\n            : '../../dist/ort-wasm-simd-threaded.mjs',\n      ).default\n    : undefined;\n\n/**\n * Import the WebAssembly module.\n *\n * This function will perform the following steps:\n * 1. If the embedded module exists and no custom URL is specified, use the embedded module.\n * 2. If a preload is needed, it will preload the module and return the object URL.\n * 3. Otherwise, it will perform a dynamic import of the module.\n *\n * @returns - A promise that resolves to a tuple of 2 elements:\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\n *            - The default export of the module, which is a factory function to create the WebAssembly module.\n */\nexport const importWasmModule = async (\n  urlOverride: string | undefined,\n  prefixOverride: string | undefined,\n  isMultiThreaded: boolean,\n  isWasmOverridden: boolean,\n): Promise<[undefined | string, EmscriptenModuleFactory<OrtWasmModule>]> => {\n  //\n  // Check if we should use the embedded module.\n  //\n\n  // To use the embedded module, it should be available, and no URL override or prefix override should be specified.\n  let useEmbeddedModule = embeddedWasmModule && !(urlOverride || prefixOverride);\n  if (useEmbeddedModule) {\n    if (!scriptSrc) {\n      // no URL info available.\n      //\n      // Note: when the embedded module is available, it means the current script is ESM. Usually, in ESM, the\n      // `import.meta.url` is available. But in some cases (eg. Cloudflare Workers), the value of `import.meta.url`\n      // can be `null` or `undefined`. In this case, we can only load the embedded module when:\n      //\n      // 1. The WebAssembly module binary is overridden:\n      //    ```js\n      //    env.wasm.wasmPaths = undefined;  // or not specified\n      //    env.wasm.wasmBinary = /* a Uint8Array containing the WebAssembly binary */;\n      //    ```\n      //\n      // 2. The \".wasm\" only is overridden.\n      //    ```js\n      //    env.wasm.wasmPaths = { wasm: /* URL of the .wasm file */ };\n      //    ```\n      //\n      if (isWasmOverridden && !isMultiThreaded) {\n        useEmbeddedModule = true;\n      } else {\n        throw new Error('cannot determine the script source URL.');\n      }\n    } else {\n      // if the script source is available, we can check if it is from the same origin.\n      useEmbeddedModule = isSameOrigin(scriptSrc);\n    }\n  }\n  if (useEmbeddedModule) {\n    return [undefined, embeddedWasmModule!];\n  } else {\n    const wasmModuleFilename = !BUILD_DEFS.DISABLE_JSEP\n      ? 'ort-wasm-simd-threaded.jsep.mjs'\n      : !BUILD_DEFS.DISABLE_WEBGPU\n        ? 'ort-wasm-simd-threaded.asyncify.mjs'\n        : 'ort-wasm-simd-threaded.mjs';\n    const wasmModuleUrl = urlOverride ?? normalizeUrl(wasmModuleFilename, prefixOverride);\n    // need to preload if all of the following conditions are met:\n    // 1. not in Node.js.\n    //    - Node.js does not have the same origin policy for creating workers.\n    // 2. multi-threaded is enabled.\n    //    - If multi-threaded is disabled, no worker will be created. So we don't need to preload the module.\n    // 3. the absolute URL is available.\n    //    - If the absolute URL is failed to be created, the origin cannot be determined. In this case, we will not\n    //    preload the module.\n    // 4. the worker URL is not from the same origin.\n    //    - If the worker URL is from the same origin, we can create the worker directly.\n    const needPreload = !isNode && isMultiThreaded && wasmModuleUrl && !isSameOrigin(wasmModuleUrl, prefixOverride);\n    const url = needPreload\n      ? await preload(wasmModuleUrl)\n      : (wasmModuleUrl ?? fallbackUrl(wasmModuleFilename, prefixOverride));\n    return [needPreload ? url : undefined, await dynamicImportDefault<EmscriptenModuleFactory<OrtWasmModule>>(url)];\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Env } from 'onnxruntime-common';\n\nimport type { OrtWasmModule } from './wasm-types';\nimport { importWasmModule, inferWasmPathPrefixFromScriptSrc } from './wasm-utils-import';\n\nlet wasm: OrtWasmModule | undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n  if (typeof SharedArrayBuffer === 'undefined') {\n    return false;\n  }\n\n  try {\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(\n      new Uint8Array([\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16,\n        2, 0, 26, 11,\n      ]),\n    );\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(\n      new Uint8Array([\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11,\n      ]),\n    );\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isRelaxedSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly Relaxed SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing Relaxed SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    // (module\n    //   (func (result v128)\n    //      i32.const 1\n    //      i8x16.splat\n    //      i32.const 2\n    //      i8x16.splat\n    //      i32.const 3\n    //      i8x16.splat\n    //      i32x4.relaxed_dot_i8x16_i7x16_add_s\n    //   )\n    //  )\n    return WebAssembly.validate(\n      new Uint8Array([\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 19, 1, 17, 0, 65, 1, 253, 15, 65, 2, 253,\n        15, 65, 3, 253, 15, 253, 147, 2, 11,\n      ]),\n    );\n  } catch (e) {\n    return false;\n  }\n};\n\nexport const initializeWebAssembly = async (flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");\n  }\n  if (aborted) {\n    throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  let numThreads = flags.numThreads!;\n\n  // ensure SIMD is supported\n  if (flags.simd === false) {\n    // skip SIMD feature checking as it is disabled explicitly by user\n  } else if (flags.simd === 'relaxed') {\n    // check if relaxed SIMD is supported\n    if (!isRelaxedSimdSupported()) {\n      throw new Error('Relaxed WebAssembly SIMD is not supported in the current environment.');\n    }\n  } else if (!isSimdSupported()) {\n    throw new Error('WebAssembly SIMD is not supported in the current environment.');\n  }\n\n  // check if multi-threading is supported\n  const multiThreadSupported = isMultiThreadSupported();\n  if (numThreads > 1 && !multiThreadSupported) {\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        'env.wasm.numThreads is set to ' +\n          numThreads +\n          ', but this will not work unless you enable crossOriginIsolated mode. ' +\n          'See https://web.dev/cross-origin-isolation-guide/ for more info.',\n      );\n    }\n\n    // eslint-disable-next-line no-console\n    console.warn(\n      'WebAssembly multi-threading is not supported in the current environment. ' + 'Falling back to single-threading.',\n    );\n\n    // set flags.numThreads to 1 so that OrtInit() will not create a global thread pool.\n    flags.numThreads = numThreads = 1;\n  }\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const mjsPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.mjs;\n  const mjsPathOverride = (mjsPathOverrideFlag as URL)?.href ?? mjsPathOverrideFlag;\n  const wasmPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.wasm;\n  const wasmPathOverride = (wasmPathOverrideFlag as URL)?.href ?? wasmPathOverrideFlag;\n  const wasmBinaryOverride = flags.wasmBinary;\n\n  const [objectUrl, ortWasmFactory] = await importWasmModule(\n    mjsPathOverride,\n    wasmPrefixOverride,\n    numThreads > 1,\n    !!wasmBinaryOverride || !!wasmPathOverride,\n  );\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(\n      new Promise((resolve) => {\n        setTimeout(() => {\n          isTimeout = true;\n          resolve();\n        }, timeout);\n      }),\n    );\n  }\n\n  // promise for module initialization\n  tasks.push(\n    new Promise((resolve, reject) => {\n      const config: Partial<OrtWasmModule> = {\n        /**\n         * The number of threads. WebAssembly will create (Module.numThreads - 1) workers. If it is 1, no worker will be\n         * created.\n         */\n        numThreads,\n      };\n\n      if (wasmBinaryOverride) {\n        // Set a custom buffer which contains the WebAssembly binary. This will skip the wasm file fetching.\n        config.wasmBinary = wasmBinaryOverride;\n      } else if (wasmPathOverride || wasmPrefixOverride) {\n        // A callback function to locate the WebAssembly file. The function should return the full path of the file.\n        //\n        // Since Emscripten 3.1.58, this function is only called for the .wasm file.\n        config.locateFile = (fileName) => wasmPathOverride ?? wasmPrefixOverride + fileName;\n      } else if (mjsPathOverride && mjsPathOverride.indexOf('blob:') !== 0) {\n        // if mjs path is specified, use it as the base path for the .wasm file.\n        config.locateFile = (fileName) => new URL(fileName, mjsPathOverride).href;\n      } else if (objectUrl) {\n        const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\n        if (inferredWasmPathPrefix) {\n          // if the wasm module is preloaded, use the inferred wasm path as the base path for the .wasm file.\n          config.locateFile = (fileName) => inferredWasmPathPrefix + fileName;\n        }\n      }\n\n      ortWasmFactory(config).then(\n        // wasm module initialized successfully\n        (module) => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n          if (objectUrl) {\n            URL.revokeObjectURL(objectUrl);\n          }\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        },\n      );\n    }),\n  );\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    // TODO: currently \"PThread.terminateAllThreads()\" is not exposed in the wasm module.\n    //       And this function is not yet called by any code.\n    //       If it is needed in the future, we should expose it in the wasm module and uncomment the following line.\n\n    // wasm?.PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { getInstance } from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions = (\n  options: Record<string, unknown>,\n  prefix: string,\n  seen: WeakSet<Record<string, unknown>>,\n  handler: ExtraOptionsHandler,\n): void => {\n  if (typeof options == 'object' && options !== null) {\n    if (seen.has(options)) {\n      throw new Error('Circular reference in options');\n    } else {\n      seen.add(options);\n    }\n  }\n\n  Object.entries(options).forEach(([key, value]) => {\n    const name = prefix ? prefix + key : key;\n    if (typeof value === 'object') {\n      iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n    } else if (typeof value === 'string' || typeof value === 'number') {\n      handler(name, value.toString());\n    } else if (typeof value === 'boolean') {\n      handler(name, value ? '1' : '0');\n    } else {\n      throw new Error(`Can't handle extra config type: ${typeof value}`);\n    }\n  });\n};\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const ptrSize = wasm.PTR_SIZE;\n    const paramsOffset = wasm.stackAlloc(2 * ptrSize);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + ptrSize);\n    const errorCode = Number(wasm.getValue(paramsOffset, ptrSize === 4 ? 'i32' : 'i64'));\n    const errorMessagePointer = wasm.getValue(paramsOffset + ptrSize, '*');\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { InferenceSession } from 'onnxruntime-common';\n\nimport { getInstance } from './wasm-factory';\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2; // Default to warning\n    } else if (\n      typeof options.logSeverityLevel !== 'number' ||\n      !Number.isInteger(options.logSeverityLevel) ||\n      options.logSeverityLevel < 0 ||\n      options.logSeverityLevel > 4\n    ) {\n      throw new Error(`log severity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0; // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n      runOptions.logSeverityLevel!,\n      runOptions.logVerbosityLevel!,\n      !!runOptions.terminate!,\n      tagDataOffset,\n    );\n    if (runOptionsHandle === 0) {\n      checkLastError(\"Can't create run options.\");\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach((alloc) => wasm._free(alloc));\n    throw e;\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport type { InferenceSession } from 'onnxruntime-common';\n\nimport { getInstance } from './wasm-factory';\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string | unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'layout':\n      return 3;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential' | 'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (\n    options.executionProviders &&\n    options.executionProviders.some((ep) => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')\n  ) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst appendSessionConfig = (sessionOptionsHandle: number, key: string, value: string, allocs: number[]): void => {\n  const keyDataOffset = allocWasmString(key, allocs);\n  const valueDataOffset = allocWasmString(value, allocs);\n  if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n    checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n  }\n};\n\nconst appendEpOption = (epOptions: Array<[number, number]>, key: string, value: string, allocs: number[]): void => {\n  const keyDataOffset = allocWasmString(key, allocs);\n  const valueDataOffset = allocWasmString(value, allocs);\n  epOptions.push([keyDataOffset, valueDataOffset]);\n};\n\nconst setExecutionProviders = async (\n  sessionOptionsHandle: number,\n  executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n  allocs: number[],\n): Promise<void> => {\n  for (const ep of executionProviders) {\n    let epName = typeof ep === 'string' ? ep : ep.name;\n    const epOptions: Array<[number, number]> = [];\n\n    // check EP name\n    switch (epName) {\n      case 'webnn':\n        epName = 'WEBNN';\n        if (typeof ep !== 'string') {\n          const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n          // const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\n          if (deviceType) {\n            appendSessionConfig(sessionOptionsHandle, 'deviceType', deviceType, allocs);\n          }\n        }\n        break;\n      case 'webgpu':\n        if (!BUILD_DEFS.DISABLE_WEBGPU) {\n          epName = 'WebGPU';\n          let customDevice: GPUDevice | undefined;\n\n          if (typeof ep !== 'string') {\n            const customOptions = ep as unknown as { device: GPUDevice };\n            if (customOptions.device) {\n              if (typeof GPUDevice !== 'undefined' && customOptions.device instanceof GPUDevice) {\n                customDevice = customOptions.device;\n              } else {\n                throw new Error('Invalid GPU device set in WebGPU EP options.');\n              }\n            }\n\n            // TODO: handle more options\n          }\n\n          const info = getInstance().webgpuRegisterDevice!(customDevice);\n          if (info) {\n            const [deviceId, instanceHandle, deviceHandle] = info;\n            appendEpOption(epOptions, 'deviceId', deviceId.toString(), allocs);\n            appendEpOption(epOptions, 'webgpuInstance', instanceHandle.toString(), allocs);\n            appendEpOption(epOptions, 'webgpuDevice', deviceHandle.toString(), allocs);\n          }\n        } else {\n          epName = 'JS';\n          if (typeof ep !== 'string') {\n            const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n            if (webgpuOptions?.preferredLayout) {\n              if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n              }\n              appendSessionConfig(sessionOptionsHandle, 'preferredLayout', webgpuOptions.preferredLayout, allocs);\n            }\n          }\n        }\n        break;\n      case 'wasm':\n      case 'cpu':\n        continue;\n      default:\n        throw new Error(`not supported execution provider: ${epName}`);\n    }\n\n    const epNameDataOffset = allocWasmString(epName, allocs);\n    const epOptionsCount = epOptions.length;\n    let keysOffset = 0;\n    let valuesOffset = 0;\n    if (epOptionsCount > 0) {\n      keysOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\n      allocs.push(keysOffset);\n      valuesOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\n      allocs.push(valuesOffset);\n      for (let i = 0; i < epOptionsCount; i++) {\n        getInstance().setValue(keysOffset + i * getInstance().PTR_SIZE, epOptions[i][0], '*');\n        getInstance().setValue(valuesOffset + i * getInstance().PTR_SIZE, epOptions[i][1], '*');\n      }\n    }\n    if (\n      (await getInstance()._OrtAppendExecutionProvider(\n        sessionOptionsHandle,\n        epNameDataOffset,\n        keysOffset,\n        valuesOffset,\n        epOptionsCount,\n      )) !== 0\n    ) {\n      checkLastError(`Can't append execution provider: ${epName}.`);\n    }\n  }\n};\n\nexport const setSessionOptions = async (options?: InferenceSession.SessionOptions): Promise<[number, number[]]> => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n      typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2; // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log severity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0; // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset =\n      typeof sessionOptions.optimizedModelFilePath === 'string'\n        ? allocWasmString(sessionOptions.optimizedModelFilePath, allocs)\n        : 0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n      graphOptimizationLevel,\n      !!sessionOptions.enableCpuMemArena,\n      !!sessionOptions.enableMemPattern,\n      executionMode,\n      !!sessionOptions.enableProfiling,\n      0,\n      logIdDataOffset,\n      logSeverityLevel,\n      logVerbosityLevel,\n      optimizedModelFilePathOffset,\n    );\n    if (sessionOptionsHandle === 0) {\n      checkLastError(\"Can't create session options.\");\n    }\n\n    if (sessionOptions.executionProviders) {\n      await setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.enableGraphCapture !== undefined) {\n      if (typeof sessionOptions.enableGraphCapture !== 'boolean') {\n        throw new Error(`enableGraphCapture must be a boolean value: ${sessionOptions.enableGraphCapture}`);\n      }\n      appendSessionConfig(\n        sessionOptionsHandle,\n        'enableGraphCapture',\n        sessionOptions.enableGraphCapture.toString(),\n        allocs,\n      );\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        appendSessionConfig(sessionOptionsHandle, key, value, allocs);\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\n        checkLastError(\"Can't release session options.\");\n      }\n    }\n    allocs.forEach((alloc) => wasm._free(alloc));\n    throw e;\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from 'onnxruntime-common';\n\n// a dummy type declaration for Float16Array in case any polyfill is available.\ndeclare global {\n  // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\n  const Float16Array: any;\n}\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16,\n\n  // 4-bit data-types\n  uint4 = 21,\n  int4 = 22,\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n    case 'int4':\n      return DataType.int4;\n    case 'uint4':\n      return DataType.uint4;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n    case DataType.int4:\n      return 'int4';\n    case DataType.uint4:\n      return 'uint4';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor size in bytes by the given data type and dimensions\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const calculateTensorSizeInBytes = (\n  dateType: number,\n  dimsOrSize: readonly number[] | number,\n): number | undefined => {\n  const elementSize = [\n    -1, // undefined = 0\n    4, // float = 1\n    1, // uint8 = 2\n    1, // int8 = 3\n    2, // uint16 = 4\n    2, // int16 = 5\n    4, // int32 = 6\n    8, // int64 = 7\n    -1, // string = 8\n    1, // bool = 9\n    2, // float16 = 10\n    8, // double = 11\n    4, // uint32 = 12\n    8, // uint64 = 13\n    -1, // complex64 = 14\n    -1, // complex128 = 15\n    -1, // bfloat16 = 16\n    -1, // FLOAT8E4M3FN = 17\n    -1, // FLOAT8E4M3FNUZ = 18\n    -1, // FLOAT8E5M2 = 19\n    -1, // FLOAT8E5M2FNUZ = 20\n    0.5, // uint4 = 21\n    0.5, // int4 = 22\n  ][dateType];\n\n  const size = typeof dimsOrSize === 'number' ? dimsOrSize : dimsOrSize.reduce((a, b) => a * b, 1);\n  return elementSize > 0 ? Math.ceil(size * elementSize) : undefined;\n};\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (\n  type: Tensor.Type,\n):\n  | Float32ArrayConstructor\n  | Uint8ArrayConstructor\n  | Int8ArrayConstructor\n  | Uint16ArrayConstructor\n  | Int16ArrayConstructor\n  | Int32ArrayConstructor\n  | BigInt64ArrayConstructor\n  | Uint8ArrayConstructor\n  | Float64ArrayConstructor\n  | Uint32ArrayConstructor\n  | BigUint64ArrayConstructor => {\n  switch (type) {\n    case 'float16':\n      // allow Float16Array polyfill.\n      return typeof Float16Array !== 'undefined' && Float16Array.from ? Float16Array : Uint16Array;\n    case 'float32':\n      return Float32Array;\n    case 'uint8':\n      return Uint8Array;\n    case 'int8':\n      return Int8Array;\n    case 'uint16':\n      return Uint16Array;\n    case 'int16':\n      return Int16Array;\n    case 'int32':\n      return Int32Array;\n    case 'bool':\n      return Uint8Array;\n    case 'float64':\n      return Float64Array;\n    case 'uint32':\n      return Uint32Array;\n    case 'int64':\n      return BigInt64Array;\n    case 'uint64':\n      return BigUint64Array;\n    default:\n      throw new Error(`unsupported type: ${type}`);\n  }\n};\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes =>\n  type === 'float32' ||\n  type === 'float16' ||\n  type === 'int32' ||\n  type === 'int64' ||\n  type === 'uint32' ||\n  type === 'uint8' ||\n  type === 'bool' ||\n  type === 'uint4' ||\n  type === 'int4';\n\n/**\n * Check whether the given tensor type is supported by WebNN MLTensor\n */\nexport const isMLTensorSupportedType = (type: Tensor.Type): type is Tensor.MLTensorDataTypes =>\n  type === 'float32' ||\n  type === 'float16' ||\n  type === 'int32' ||\n  type === 'int64' ||\n  type === 'uint32' ||\n  type === 'uint64' ||\n  type === 'int8' ||\n  type === 'uint8' ||\n  type === 'bool' ||\n  type === 'uint4' ||\n  type === 'int4';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    case 'ml-tensor':\n      return 5;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation | undefined =>\n  (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer', 'ml-tensor'] as const)[location];\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { isNode } from './wasm-utils-env';\n\n/**\n * Load a file into a Uint8Array.\n *\n * @param file - the file to load. Can be a URL/path, a Blob, an ArrayBuffer, or a Uint8Array.\n * @returns a Uint8Array containing the file data.\n */\nexport const loadFile = async (file: string | Blob | ArrayBufferLike | Uint8Array): Promise<Uint8Array> => {\n  if (typeof file === 'string') {\n    if (isNode) {\n      // load file into ArrayBuffer in Node.js\n      try {\n        const { readFile } = require('node:fs/promises');\n        return new Uint8Array(await readFile(file));\n      } catch (e) {\n        if (e.code === 'ERR_FS_FILE_TOO_LARGE') {\n          // file is too large, use fs.createReadStream instead\n          const { createReadStream } = require('node:fs');\n          const stream = createReadStream(file);\n          const chunks: Uint8Array[] = [];\n          for await (const chunk of stream) {\n            chunks.push(chunk);\n          }\n          return new Uint8Array(Buffer.concat(chunks));\n        }\n        throw e;\n      }\n    } else {\n      // load file into ArrayBuffer in browsers\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`failed to load external data file: ${file}`);\n      }\n      const contentLengthHeader = response.headers.get('Content-Length');\n      const fileSize = contentLengthHeader ? parseInt(contentLengthHeader, 10) : 0;\n      if (fileSize < 1073741824 /* 1GB */) {\n        // when Content-Length header is not set, we cannot determine the file size. We assume it is small enough to\n        // load into memory.\n        return new Uint8Array(await response.arrayBuffer());\n      } else {\n        // file is too large, use stream instead\n        if (!response.body) {\n          throw new Error(`failed to load external data file: ${file}, no response body.`);\n        }\n        const reader = response.body.getReader();\n\n        let buffer;\n        try {\n          // try to create ArrayBuffer directly\n          buffer = new ArrayBuffer(fileSize);\n        } catch (e) {\n          if (e instanceof RangeError) {\n            // use WebAssembly Memory to allocate larger ArrayBuffer\n            const pages = Math.ceil(fileSize / 65536);\n            buffer = new WebAssembly.Memory({ initial: pages, maximum: pages }).buffer;\n          } else {\n            throw e;\n          }\n        }\n\n        let offset = 0;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n          const { done, value } = await reader.read();\n          if (done) {\n            break;\n          }\n          const chunkSize = value.byteLength;\n          const chunk = new Uint8Array(buffer, offset, chunkSize);\n          chunk.set(value);\n          offset += chunkSize;\n        }\n        return new Uint8Array(buffer, 0, fileSize);\n      }\n    }\n  } else if (file instanceof Blob) {\n    return new Uint8Array(await file.arrayBuffer());\n  } else if (file instanceof Uint8Array) {\n    return file;\n  } else {\n    return new Uint8Array(file);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\n// WebNN API specification.\n// https://github.com/webmachinelearning/webnn/issues/677\n/// <reference path=\"jsep/webnn/webnn.d.ts\" />\n\nimport { Env, InferenceSession, Tensor, TRACE_EVENT_BEGIN, TRACE_EVENT_END } from 'onnxruntime-common';\n\nimport {\n  SerializableInternalBuffer,\n  SerializableSessionMetadata,\n  SerializableTensorMetadata,\n  TensorMetadata,\n} from './proxy-messages';\nimport { setRunOptions } from './run-options';\nimport { setSessionOptions } from './session-options';\nimport {\n  calculateTensorSizeInBytes,\n  dataLocationStringToEnum,\n  isGpuBufferSupportedType,\n  isMLTensorSupportedType,\n  logLevelStringToEnum,\n  tensorDataTypeEnumToString,\n  tensorDataTypeStringToEnum,\n  tensorTypeToTypedArrayConstructor,\n} from './wasm-common';\nimport { getInstance } from './wasm-factory';\nimport { allocWasmString, checkLastError } from './wasm-utils';\nimport { loadFile } from './wasm-utils-load-file';\n\n// #region Initializations\n\n/**\n * There are 4 different \"initialization\" steps for ORT. They happen in different places and different time.\n *\n * 1. JavaScript initialization for onnxruntime-common and onnxruntime-web.\n *    This is the first initialization step. In this step, onnxruntime-web calls onnxruntime-common's registerBackend()\n * function multiple times to register all the available backends. The backend registration is very fast. It only\n * registers the backend name with the uninitialized backend object. No heavy initialization is done in this step.\n *    Refer to web/lib/index.ts for the backend registration.\n *\n * 2. WebAssembly artifact initialization.\n *    This happens when any registered wasm backend is used for the first time (ie. `ort.InferenceSession.create()` is\n * called). In this step, onnxruntime-web does the followings:\n *     - create a proxy worker and make sure the proxy worker is ready to receive messages, if proxy is enabled.\n *     - perform feature detection, locate correct WebAssembly artifact path and call the Emscripten generated\n * JavaScript code to initialize the WebAssembly runtime.\n *         - if proxy is enabled, this step happens in the proxy worker using message 'init-wasm'.\n *         - downloading the 'ort-wasm{...}.wasm' file is done in this step.\n *         - if multi-thread is enabled, one or more webworker will be created to initialize the PThread threadpool.\n *\n * 3. ORT environment initialization.\n *    This happens after step 2. In this step, onnxruntime-web performs ONNX Runtime environment initialization.\n * Function `_OrtInit()` is called in this step.\n *     - if proxy is enabled, this step happens in the proxy worker using message 'init-ort'.\n *     - logging level (ort.env.logLevel) and thread number (ort.env.wasm.numThreads) are set in this step.\n *\n * 4. Session initialization.\n *    This happens when `ort.InferenceSession.create()` is called. Unlike the first 3 steps (they only called once),\n * this step will be done for each session. In this step, onnxruntime-web does the followings:\n *    If the parameter is a URL:\n *    - download the model data from the URL.\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\n *    - dereference the model buffer. This step allows the original ArrayBuffer to be garbage collected.\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\n *\n *    If the parameter is a Uint8Array object:\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\n *\n *\n */\n\n/**\n * initialize ORT environment.\n *\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError(\"Can't initialize onnxruntime.\");\n  }\n};\n\n/**\n * initialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async (env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n};\n\n/**\n * perform EP specific initialization.\n *\n * @param env\n * @param epName\n */\nexport const initEp = async (env: Env, epName: string): Promise<void> => {\n  // initialize ASYNCIFY support\n  getInstance().asyncInit?.();\n\n  // perform WebGPU availability check ( either JSEP or WebGPU EP )\n  let webgpuAdapter = env.webgpu.adapter as GPUAdapter | null;\n  if (epName === 'webgpu') {\n    if (typeof navigator === 'undefined' || !navigator.gpu) {\n      throw new Error('WebGPU is not supported in current environment');\n    }\n    if (!webgpuAdapter) {\n      // if adapter is not set, request a new adapter.\n      const powerPreference = env.webgpu.powerPreference;\n      if (powerPreference !== undefined && powerPreference !== 'low-power' && powerPreference !== 'high-performance') {\n        throw new Error(`Invalid powerPreference setting: \"${powerPreference}\"`);\n      }\n      const forceFallbackAdapter = env.webgpu.forceFallbackAdapter;\n      if (forceFallbackAdapter !== undefined && typeof forceFallbackAdapter !== 'boolean') {\n        throw new Error(`Invalid forceFallbackAdapter setting: \"${forceFallbackAdapter}\"`);\n      }\n      webgpuAdapter = await navigator.gpu.requestAdapter({ powerPreference, forceFallbackAdapter });\n      if (!webgpuAdapter) {\n        throw new Error(\n          'Failed to get GPU adapter. ' +\n            'You may need to enable flag \"--enable-unsafe-webgpu\" if you are using Chrome.',\n        );\n      }\n    } else {\n      // if adapter is set, validate it.\n      if (\n        typeof webgpuAdapter.limits !== 'object' ||\n        typeof webgpuAdapter.features !== 'object' ||\n        typeof webgpuAdapter.requestDevice !== 'function'\n      ) {\n        throw new Error('Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.');\n      }\n    }\n  }\n\n  // perform WebNN availability check ( either JSEP or WebNN EP )\n  if (epName === 'webnn') {\n    if (typeof navigator === 'undefined' || !(navigator as unknown as { ml: unknown }).ml) {\n      throw new Error('WebNN is not supported in current environment');\n    }\n  }\n\n  if (!BUILD_DEFS.DISABLE_JSEP) {\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n\n    if (epName === 'webgpu') {\n      await initJsep('webgpu', getInstance(), env, webgpuAdapter);\n    }\n    if (epName === 'webnn') {\n      await initJsep('webnn', getInstance(), env);\n    }\n  } else {\n    if (!BUILD_DEFS.DISABLE_WEBGPU && epName === 'webgpu') {\n      getInstance().webgpuInit!((device) => {\n        env.webgpu.device = device;\n      });\n    }\n    if (!BUILD_DEFS.DISABLE_WEBNN && epName === 'webnn') {\n      // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n      const backend = new (require('./jsep/backend-webnn').WebNNBackend)(env);\n      getInstance().webnnInit!([\n        backend,\n        // webnnReserveTensorId\n        () => backend.reserveTensorId(),\n        // webnnReleaseTensorId,\n        (tensorId: number) => backend.releaseTensorId(tensorId),\n        // webnnEnsureTensor\n        async (sessionId: number | undefined, tensorId: number, onnxDataType: number, shape: number[], copyOld) =>\n          backend.ensureTensor(sessionId, tensorId, onnxDataType, shape, copyOld),\n        // webnnUploadTensor\n        (tensorId: number, data: Uint8Array) => {\n          backend.uploadTensor(tensorId, data);\n        },\n        // webnnDownloadTensor\n        async (tensorId: number, dstBuffer: ArrayBufferView | ArrayBuffer) =>\n          backend.downloadTensor(tensorId, dstBuffer),\n        // webnnRegisterMLContext\n        (sessionId: number, mlContext: MLContext) => backend.registerMLContext(sessionId, mlContext),\n        // webnnEnableTraceEvent\n        !!env.trace,\n      ]);\n    }\n  }\n};\n\n// #endregion Initializations\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput =\n  | 'cpu'\n  | 'cpu-pinned'\n  | 'gpu-buffer'\n  | 'ml-tensor'\n  // Use 'ml-tensor' during inference, but output a tensor located on the CPU.\n  | 'ml-tensor-cpu-output';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer', 'ml-tensor'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number,\n  inputNamesUTF8Encoded: number[],\n  outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState | null,\n  enableGraphCapture: boolean,\n  inputOutputBound: boolean,\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const ptrSize = wasm.PTR_SIZE;\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + ptrSize);\n    if (errorCode !== 0) {\n      checkLastError(\"Can't get session input/output count.\");\n    }\n    const type = ptrSize === 4 ? 'i32' : 'i64';\n    return [Number(wasm.getValue(dataOffset, type)), Number(wasm.getValue(dataOffset + ptrSize, type))];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\nconst getSessionInputOutputMetadata = (\n  sessionHandle: number,\n  index: number,\n): [nameOffset: number, elementType: number, dims?: Array<number | string>] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  let metadataOffset = 0;\n  try {\n    const ptrSize = wasm.PTR_SIZE;\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\n    const errorCode = wasm._OrtGetInputOutputMetadata(sessionHandle, index, dataOffset, dataOffset + ptrSize);\n    if (errorCode !== 0) {\n      checkLastError(\"Can't get session input/output metadata.\");\n    }\n    const nameOffset = Number(wasm.getValue(dataOffset, '*'));\n    metadataOffset = Number(wasm.getValue(dataOffset + ptrSize, '*'));\n    // get element type\n    const elementType = wasm.HEAP32[metadataOffset / 4];\n    if (elementType === 0) {\n      return [nameOffset, 0]; // non-tensor\n    }\n\n    // get dims count\n    const dimsCount = wasm.HEAPU32[metadataOffset / 4 + 1];\n    // get dims\n    const dims: Array<number | string> = [];\n    for (let i = 0; i < dimsCount; i++) {\n      const symbolicDimNameOffset = Number(wasm.getValue(metadataOffset + 8 + i * ptrSize, '*'));\n      dims.push(\n        symbolicDimNameOffset !== 0\n          ? wasm.UTF8ToString(symbolicDimNameOffset)\n          : Number(wasm.getValue(metadataOffset + 8 + (i + dimsCount) * ptrSize, '*')),\n      );\n    }\n    return [nameOffset, elementType, dims];\n  } finally {\n    wasm.stackRestore(stack);\n    if (metadataOffset !== 0) {\n      wasm._OrtFree(metadataOffset);\n    }\n  }\n};\n\n/**\n * allocate the memory and memcpy the external buffer.\n *\n * @param model - the external buffer containing the model data. Must not be the same buffer as the WASM heap.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const copyFromExternalBuffer = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session from a model data buffer.\n *\n * @param modelData - either a Uint8Array object representing the model data, or a 2-elements tuple containing the\n *     pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSession = async (\n  modelData: Uint8Array | SerializableInternalBuffer,\n  options?: InferenceSession.SessionOptions,\n): Promise<SerializableSessionMetadata> => {\n  let modelDataOffset: number, modelDataLength: number;\n  const wasm = getInstance();\n\n  if (Array.isArray(modelData)) {\n    // if model data is an array, it must be a 2-elements tuple containing the pointer and size of the model data\n    [modelDataOffset, modelDataLength] = modelData;\n  } else if (modelData.buffer === wasm.HEAPU8.buffer) {\n    // if model data uses the same buffer as the WASM heap, we don't need to copy it.\n    [modelDataOffset, modelDataLength] = [modelData.byteOffset, modelData.byteLength];\n  } else {\n    // otherwise, copy the model data to the WASM heap.\n    [modelDataOffset, modelDataLength] = copyFromExternalBuffer(modelData);\n  }\n\n  let sessionHandle = 0;\n  let sessionOptionsHandle = 0;\n  let ioBindingHandle = 0;\n  let allocs: number[] = [];\n  const inputNamesUTF8Encoded = [];\n  const outputNamesUTF8Encoded = [];\n\n  try {\n    [sessionOptionsHandle, allocs] = await setSessionOptions(options);\n\n    if (options?.externalData && wasm.mountExternalData) {\n      const loadingPromises = [];\n      for (const file of options.externalData) {\n        const path = typeof file === 'string' ? file : file.path;\n        loadingPromises.push(\n          loadFile(typeof file === 'string' ? file : file.data).then((data) => {\n            wasm.mountExternalData(path, data);\n          }),\n        );\n      }\n\n      // wait for all external data files to be loaded\n      await Promise.all(loadingPromises);\n    }\n\n    for (const provider of options?.executionProviders ?? []) {\n      const providerName = typeof provider === 'string' ? provider : provider.name;\n      if (providerName === 'webnn') {\n        wasm.shouldTransferToMLTensor = false;\n        if (typeof provider !== 'string') {\n          const webnnOptions = provider as InferenceSession.WebNNExecutionProviderOption;\n          const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\n          const gpuDevice = (webnnOptions as InferenceSession.WebNNOptionsWebGpu)?.gpuDevice;\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\n          const powerPreference = (webnnOptions as InferenceSession.WebNNContextOptions)?.powerPreference;\n          if (context) {\n            wasm.currentContext = context as MLContext;\n          } else if (gpuDevice) {\n            wasm.currentContext = await wasm.webnnCreateMLContext!(gpuDevice);\n          } else {\n            wasm.currentContext = await wasm.webnnCreateMLContext!({ deviceType, powerPreference });\n          }\n        } else {\n          wasm.currentContext = await wasm.webnnCreateMLContext!();\n        }\n        break;\n      }\n    }\n\n    sessionHandle = await wasm._OrtCreateSession(modelDataOffset, modelDataLength, sessionOptionsHandle);\n    wasm.webgpuOnCreateSession?.(sessionHandle);\n    if (sessionHandle === 0) {\n      checkLastError(\"Can't create a session.\");\n    }\n\n    wasm.jsepOnCreateSession?.();\n\n    // clear current MLContext after session creation\n    if (wasm.currentContext) {\n      wasm.webnnRegisterMLContext!(sessionHandle, wasm.currentContext);\n      wasm.currentContext = undefined;\n      wasm.shouldTransferToMLTensor = true;\n    }\n\n    const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n    const enableGraphCapture = !!options?.enableGraphCapture;\n\n    const inputNames = [];\n    const outputNames = [];\n    const inputMetadata: InferenceSession.ValueMetadata[] = [];\n    const outputMetadata: InferenceSession.ValueMetadata[] = [];\n    const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const [nameOffset, elementType, shape] = getSessionInputOutputMetadata(sessionHandle, i);\n      if (nameOffset === 0) {\n        checkLastError(\"Can't get an input name.\");\n      }\n      inputNamesUTF8Encoded.push(nameOffset);\n      const name = wasm.UTF8ToString(nameOffset);\n      inputNames.push(name);\n      inputMetadata.push(\n        elementType === 0\n          ? { name, isTensor: false }\n          : { name, isTensor: true, type: tensorDataTypeEnumToString(elementType), shape: shape! },\n      );\n    }\n    for (let i = 0; i < outputCount; i++) {\n      const [nameOffset, elementType, shape] = getSessionInputOutputMetadata(sessionHandle, i + inputCount);\n      if (nameOffset === 0) {\n        checkLastError(\"Can't get an output name.\");\n      }\n      outputNamesUTF8Encoded.push(nameOffset);\n      const nameString = wasm.UTF8ToString(nameOffset);\n      outputNames.push(nameString);\n      outputMetadata.push(\n        elementType === 0\n          ? { name: nameString, isTensor: false }\n          : { name: nameString, isTensor: true, type: tensorDataTypeEnumToString(elementType), shape: shape! },\n      );\n\n      if (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) {\n        if (enableGraphCapture && options?.preferredOutputLocation === undefined) {\n          outputPreferredLocations.push('gpu-buffer');\n          continue;\n        }\n        const location =\n          typeof options?.preferredOutputLocation === 'string'\n            ? options.preferredOutputLocation\n            : (options?.preferredOutputLocation?.[nameString] ?? 'cpu');\n        const isGraphOutput = wasm.webnnIsGraphOutput;\n        if (location === 'cpu' && isGraphOutput && isGraphOutput(sessionHandle, nameString)) {\n          outputPreferredLocations.push('ml-tensor-cpu-output');\n          continue;\n        }\n        if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer' && location !== 'ml-tensor') {\n          throw new Error(`Not supported preferred output location: ${location}.`);\n        }\n        if (enableGraphCapture && location !== 'gpu-buffer') {\n          throw new Error(\n            `Not supported preferred output location: ${location}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`,\n          );\n        }\n        outputPreferredLocations.push(location);\n      }\n    }\n\n    // use IO binding only when at least one output is preferred to be on GPU.\n    let bindingState: IOBindingState | null = null;\n    if (\n      (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) &&\n      outputPreferredLocations.some((l) => l === 'gpu-buffer' || l === 'ml-tensor' || l === 'ml-tensor-cpu-output')\n    ) {\n      ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n      if (ioBindingHandle === 0) {\n        checkLastError(\"Can't create IO binding.\");\n      }\n\n      bindingState = {\n        handle: ioBindingHandle,\n        outputPreferredLocations,\n        outputPreferredLocationsEncoded: outputPreferredLocations\n          // 'ml-tensor-cpu-output' is treated as 'ml-tensor' for the purpose of IO binding.\n          .map((l) => (l === 'ml-tensor-cpu-output' ? 'ml-tensor' : l))\n          .map((l) => dataLocationStringToEnum(l)),\n      };\n    }\n\n    activeSessions.set(sessionHandle, [\n      sessionHandle,\n      inputNamesUTF8Encoded,\n      outputNamesUTF8Encoded,\n      bindingState,\n      enableGraphCapture,\n      false,\n    ]);\n    return [sessionHandle, inputNames, outputNames, inputMetadata, outputMetadata];\n  } catch (e) {\n    inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n    outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n\n    if (ioBindingHandle !== 0) {\n      if (wasm._OrtReleaseBinding(ioBindingHandle) !== 0) {\n        checkLastError(\"Can't release IO binding.\");\n      }\n    }\n\n    if (sessionHandle !== 0) {\n      if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\n        checkLastError(\"Can't release session.\");\n      }\n    }\n    throw e;\n  } finally {\n    wasm._free(modelDataOffset);\n    if (sessionOptionsHandle !== 0) {\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\n        checkLastError(\"Can't release session options.\");\n      }\n    }\n    allocs.forEach((alloc) => wasm._free(alloc));\n\n    // unmount external data if necessary\n    wasm.unmountExternalData?.();\n  }\n};\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState, enableGraphCapture] = session;\n\n  if (ioBindingState) {\n    if (enableGraphCapture) {\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\n        checkLastError(\"Can't clear bound outputs.\");\n      }\n    }\n    if (wasm._OrtReleaseBinding(ioBindingState.handle) !== 0) {\n      checkLastError(\"Can't release IO binding.\");\n    }\n  }\n\n  wasm.jsepOnReleaseSession?.(sessionId);\n  wasm.webnnOnReleaseSession?.(sessionId);\n  wasm.webgpuOnReleaseSession?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n  if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\n    checkLastError(\"Can't release session.\");\n  }\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor = async (\n  tensor: TensorMetadata | null,\n  tensorHandles: number[],\n  allocs: number[],\n  sessionId: number,\n  tensorNameUTF8Encoded: number,\n  index: number,\n  enableGraphCapture = false,\n): Promise<void> => {\n  if (!tensor) {\n    tensorHandles.push(0);\n    return;\n  }\n\n  const wasm = getInstance();\n  const ptrSize = wasm.PTR_SIZE;\n\n  const dataType = tensor[0];\n  const dims = tensor[1];\n  const location = tensor[3];\n  let actualLocation = location;\n\n  let rawData: number;\n  let dataByteLength: number;\n\n  if (dataType === 'string' && (location === 'gpu-buffer' || location === 'ml-tensor')) {\n    throw new Error('String tensor is not supported on GPU.');\n  }\n\n  if (enableGraphCapture && location !== 'gpu-buffer') {\n    throw new Error(\n      `External buffer must be provided for input/output index ${index} when enableGraphCapture is true.`,\n    );\n  }\n\n  if (location === 'gpu-buffer') {\n    const gpuBuffer = tensor[2].gpuBuffer;\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU) {\n      const registerBuffer = wasm.webgpuRegisterBuffer;\n      if (!registerBuffer) {\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\n      }\n\n      rawData = registerBuffer(gpuBuffer, sessionId);\n    } else {\n      const registerBuffer = wasm.jsepRegisterBuffer;\n      if (!registerBuffer) {\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\n      }\n      rawData = registerBuffer(sessionId, index, gpuBuffer, dataByteLength);\n    }\n  } else if (location === 'ml-tensor') {\n    const mlTensor = tensor[2].mlTensor as MLTensor;\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\n\n    const registerMLTensor = wasm.webnnRegisterMLTensor;\n    if (!registerMLTensor) {\n      throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\n    }\n    rawData = registerMLTensor(sessionId, mlTensor, tensorDataTypeStringToEnum(dataType), dims);\n  } else {\n    const data = tensor[2];\n\n    if (Array.isArray(data)) {\n      // string tensor\n      dataByteLength = ptrSize * data.length;\n      rawData = wasm._malloc(dataByteLength);\n      allocs.push(rawData);\n      for (let i = 0; i < data.length; i++) {\n        if (typeof data[i] !== 'string') {\n          throw new TypeError(`tensor data at index ${i} is not a string`);\n        }\n        wasm.setValue(rawData + i * ptrSize, allocWasmString(data[i], allocs), '*');\n      }\n    } else {\n      const isGraphInput = wasm.webnnIsGraphInput;\n      const isGraphOutput = wasm.webnnIsGraphOutput;\n      if (dataType !== 'string' && isGraphInput && isGraphOutput) {\n        const tensorName = wasm.UTF8ToString(tensorNameUTF8Encoded);\n        // Promote the tensor to 'ml-tensor' if it is a graph input.\n        if (isGraphInput(sessionId, tensorName) || isGraphOutput(sessionId, tensorName)) {\n          const dataTypeEnum = tensorDataTypeStringToEnum(dataType);\n          dataByteLength = calculateTensorSizeInBytes(dataTypeEnum, dims)!;\n          actualLocation = 'ml-tensor';\n          const createTemporaryTensor = wasm.webnnCreateTemporaryTensor;\n          const uploadTensor = wasm.webnnUploadTensor;\n          if (!createTemporaryTensor || !uploadTensor) {\n            throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\n          }\n          const tensorId = await createTemporaryTensor(sessionId, dataTypeEnum, dims as number[]);\n          uploadTensor(tensorId, new Uint8Array(data.buffer, data.byteOffset, data.byteLength));\n          rawData = tensorId;\n        } else {\n          dataByteLength = data.byteLength;\n          rawData = wasm._malloc(dataByteLength);\n          allocs.push(rawData);\n          wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n        }\n      } else {\n        dataByteLength = data.byteLength;\n        rawData = wasm._malloc(dataByteLength);\n        allocs.push(rawData);\n        wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n      }\n    }\n  }\n\n  const stack = wasm.stackSave();\n  const dimsOffset = wasm.stackAlloc(4 * dims.length);\n  try {\n    dims.forEach((d, index) => wasm.setValue(dimsOffset + index * ptrSize, d, ptrSize === 4 ? 'i32' : 'i64'));\n    const tensor = wasm._OrtCreateTensor(\n      tensorDataTypeStringToEnum(dataType),\n      rawData,\n      dataByteLength,\n      dimsOffset,\n      dims.length,\n      dataLocationStringToEnum(actualLocation),\n    );\n    if (tensor === 0) {\n      checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n    }\n    tensorHandles.push(tensor);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * perform inference run\n */\nexport const run = async (\n  sessionId: number,\n  inputIndices: number[],\n  inputTensors: TensorMetadata[],\n  outputIndices: number[],\n  outputTensors: Array<TensorMetadata | null>,\n  options: InferenceSession.RunOptions,\n): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const ptrSize = wasm.PTR_SIZE;\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const sessionHandle = session[0];\n  const inputNamesUTF8Encoded = session[1];\n  const outputNamesUTF8Encoded = session[2];\n  const ioBindingState = session[3];\n  const enableGraphCapture = session[4];\n  const inputOutputBound = session[5];\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * ptrSize);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * ptrSize);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * ptrSize);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * ptrSize);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    TRACE_EVENT_BEGIN('wasm prepareInputOutputTensor');\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      await prepareInputOutputTensor(\n        inputTensors[i],\n        inputTensorHandles,\n        inputOutputAllocs,\n        sessionId,\n        inputNamesUTF8Encoded[inputIndices[i]],\n        inputIndices[i],\n        enableGraphCapture,\n      );\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      await prepareInputOutputTensor(\n        outputTensors[i],\n        outputTensorHandles,\n        inputOutputAllocs,\n        sessionId,\n        outputNamesUTF8Encoded[outputIndices[i]],\n        inputCount + outputIndices[i],\n        enableGraphCapture,\n      );\n    }\n    TRACE_EVENT_END('wasm prepareInputOutputTensor');\n\n    for (let i = 0; i < inputCount; i++) {\n      wasm.setValue(inputValuesOffset + i * ptrSize, inputTensorHandles[i], '*');\n      wasm.setValue(inputNamesOffset + i * ptrSize, inputNamesUTF8Encoded[inputIndices[i]], '*');\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.setValue(outputValuesOffset + i * ptrSize, outputTensorHandles[i], '*');\n      wasm.setValue(outputNamesOffset + i * ptrSize, outputNamesUTF8Encoded[outputIndices[i]], '*');\n    }\n\n    if ((!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) && ioBindingState && !inputOutputBound) {\n      const { handle, outputPreferredLocations, outputPreferredLocationsEncoded } = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(\n          `input count from feeds (${inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`,\n        );\n      }\n\n      TRACE_EVENT_BEGIN('wasm bindInputsOutputs');\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3]; // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode = wasm._OrtBindOutput(\n            handle,\n            outputNamesUTF8Encoded[index],\n            0,\n            outputPreferredLocationsEncoded[index],\n          );\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n      TRACE_EVENT_END('wasm bindInputsOutputs');\n      activeSessions.set(sessionId, [\n        sessionHandle,\n        inputNamesUTF8Encoded,\n        outputNamesUTF8Encoded,\n        ioBindingState,\n        enableGraphCapture,\n        true,\n      ]);\n    }\n\n    wasm.jsepOnRunStart?.(sessionHandle);\n    wasm.webnnOnRunStart?.(sessionHandle);\n\n    let errorCode: number;\n    if ((!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n        sessionHandle,\n        ioBindingState.handle,\n        outputCount,\n        outputValuesOffset,\n        runOptionsHandle,\n      );\n    } else {\n      errorCode = await wasm._OrtRun(\n        sessionHandle,\n        inputNamesOffset,\n        inputValuesOffset,\n        inputCount,\n        outputNamesOffset,\n        outputCount,\n        outputValuesOffset,\n        runOptionsHandle,\n      );\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n    const outputPromises: Array<Promise<[number, Tensor.DataType]>> = [];\n\n    TRACE_EVENT_BEGIN('wasm ProcessOutputTensor');\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = Number(wasm.getValue(outputValuesOffset + i * ptrSize, '*'));\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * ptrSize);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type | undefined,\n        dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n          tensor,\n          tensorDataOffset,\n          tensorDataOffset + ptrSize,\n          tensorDataOffset + 2 * ptrSize,\n\n          tensorDataOffset + 3 * ptrSize,\n        );\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        const valueType = ptrSize === 4 ? 'i32' : 'i64';\n        const dataType = Number(wasm.getValue(tensorDataOffset, valueType));\n        dataOffset = wasm.getValue(tensorDataOffset + ptrSize, '*');\n        const dimsOffset = wasm.getValue(tensorDataOffset + ptrSize * 2, '*');\n        const dimsLength = Number(wasm.getValue(tensorDataOffset + ptrSize * 3, valueType));\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(Number(wasm.getValue(dimsOffset + i * ptrSize, valueType)));\n        }\n        if (wasm._OrtFree(dimsOffset) !== 0) {\n          checkLastError(\"Can't free memory for tensor dims.\");\n        }\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer' || preferredLocation === 'ml-tensor') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.getValue(dataOffset + i * ptrSize, '*');\n            const nextOffset = wasm.getValue(dataOffset + (i + 1) * ptrSize, '*');\n            const maxBytesToRead = i === size - 1 ? undefined : nextOffset - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const getBuffer = !BUILD_DEFS.DISABLE_WEBGPU ? wasm.webgpuGetBuffer : wasm.jsepGetBuffer;\n            if (!getBuffer) {\n              throw new Error('preferredLocation \"gpu-buffer\" is not supported without using WebGPU.');\n            }\n            const gpuBuffer = getBuffer(dataOffset);\n            const bufferSize = calculateTensorSizeInBytes(dataType, size);\n            if (bufferSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            if (!BUILD_DEFS.DISABLE_WEBGPU) {\n              wasm.webgpuRegisterBuffer!(gpuBuffer, sessionId, dataOffset);\n              const downloadDataFunction = wasm.webgpuCreateDownloader!(gpuBuffer, bufferSize, sessionId);\n              output.push([\n                type,\n                dims,\n                {\n                  gpuBuffer,\n                  download: async () => {\n                    const arrayBuffer = await downloadDataFunction();\n                    const data = new (tensorTypeToTypedArrayConstructor(type!))(arrayBuffer);\n                    return data as Tensor.DataTypeMap[Tensor.GpuBufferDataTypes];\n                  },\n                  dispose: () => {\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\n                      checkLastError(\"Can't release tensor.\");\n                    }\n                  },\n                },\n                'gpu-buffer',\n              ]);\n            } else {\n              output.push([\n                type,\n                dims,\n                {\n                  gpuBuffer,\n                  download: wasm.jsepCreateDownloader!(gpuBuffer, bufferSize, type),\n                  dispose: () => {\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\n                      checkLastError(\"Can't release tensor.\");\n                    }\n                  },\n                },\n                'gpu-buffer',\n              ]);\n            }\n          } else if (preferredLocation === 'ml-tensor' && size > 0) {\n            const ensureTensor = wasm.webnnEnsureTensor;\n            const isGraphInputOutputTypeSupported = wasm.webnnIsGraphInputOutputTypeSupported;\n            if (!ensureTensor || !isGraphInputOutputTypeSupported) {\n              throw new Error('preferredLocation \"ml-tensor\" is not supported without using WebNN.');\n            }\n            const tensorSize = calculateTensorSizeInBytes(dataType, size);\n            if (tensorSize === undefined || !isMLTensorSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n            if (!isGraphInputOutputTypeSupported(sessionId, type, false)) {\n              throw new Error(\n                `preferredLocation \"ml-tensor\" for ${type} output is not supported by current WebNN Context.`,\n              );\n            }\n\n            // If the graph has been partitioned, the output tensor may have not been created. For this reason, we use\n            // ensureTensor to get/create the MLTensor. In which case, we don't need to copy the data if a new tensor\n            // has been created.\n            const mlTensor = await ensureTensor(sessionId, dataOffset, dataType, dims, false);\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type,\n              dims,\n              {\n                mlTensor,\n                download: wasm.webnnCreateMLTensorDownloader!(dataOffset, type),\n                dispose: () => {\n                  wasm.webnnReleaseTensorId!(dataOffset);\n                  wasm._OrtReleaseTensor(tensor);\n                },\n              },\n              'ml-tensor',\n            ]);\n          } else if (preferredLocation === 'ml-tensor-cpu-output' && size > 0) {\n            const data = wasm.webnnCreateMLTensorDownloader!(dataOffset, type as Tensor.MLTensorDataTypes)();\n            const index = output.length;\n            // Delay the data download and releasing the tensor until we can wait for all output tensors to be downloaded.\n            keepOutputTensor = true;\n            outputPromises.push(\n              (async () => {\n                const result: [number, Tensor.DataType] = [index, await data];\n                wasm.webnnReleaseTensorId!(dataOffset);\n                wasm._OrtReleaseTensor(tensor);\n                return result;\n              })(),\n            );\n            output.push([type, dims, [], 'cpu']);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength).set(\n              wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength),\n            );\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState && !enableGraphCapture) {\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\n        checkLastError(\"Can't clear bound outputs.\");\n      }\n      activeSessions.set(sessionId, [\n        sessionHandle,\n        inputNamesUTF8Encoded,\n        outputNamesUTF8Encoded,\n        ioBindingState,\n        enableGraphCapture,\n        false,\n      ]);\n    }\n    // Wait for all output tensor data to be downloaded.\n    for (const [index, data] of await Promise.all(outputPromises)) {\n      output[index][2] = data;\n    }\n    TRACE_EVENT_END('wasm ProcessOutputTensor');\n    return output;\n  } finally {\n    wasm.webnnOnRunEnd?.(sessionHandle);\n\n    wasm.stackRestore(beforeRunStack);\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU) {\n      inputTensors.forEach((t) => {\n        if (t && t[3] === 'gpu-buffer') {\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\n        }\n      });\n      outputTensors.forEach((t) => {\n        if (t && t[3] === 'gpu-buffer') {\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\n        }\n      });\n    }\n    inputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach((p) => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach((p) => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError(\"Can't get an profile file name.\");\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env, InferenceSession } from 'onnxruntime-common';\n\nimport {\n  OrtWasmMessage,\n  SerializableInternalBuffer,\n  SerializableSessionMetadata,\n  SerializableTensorMetadata,\n  TensorMetadata,\n} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport { initializeWebAssembly } from './wasm-factory';\nimport {\n  importProxyWorker,\n  inferWasmPathPrefixFromScriptSrc,\n  isEsmImportMetaUrlHardcodedAsFileUri,\n} from './wasm-utils-import';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker | undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\nlet temporaryObjectUrl: string | undefined;\n\ntype PromiseCallbacks<T = void> = [resolve: (result: T) => void, reject: (reason: unknown) => void];\nlet initWasmCallbacks: PromiseCallbacks;\nconst queuedCallbacks: Map<OrtWasmMessage['type'], Array<PromiseCallbacks<unknown>>> = new Map();\n\nconst enqueueCallbacks = (type: OrtWasmMessage['type'], callbacks: PromiseCallbacks<unknown>): void => {\n  const queue = queuedCallbacks.get(type);\n  if (queue) {\n    queue.push(callbacks);\n  } else {\n    queuedCallbacks.set(type, [callbacks]);\n  }\n};\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      if (temporaryObjectUrl) {\n        URL.revokeObjectURL(temporaryObjectUrl);\n        temporaryObjectUrl = undefined;\n      }\n      break;\n    case 'init-ep':\n    case 'copy-from':\n    case 'create':\n    case 'release':\n    case 'run':\n    case 'end-profiling': {\n      const callbacks = queuedCallbacks.get(ev.data.type)!;\n      if (ev.data.err) {\n        callbacks.shift()![1](ev.data.err);\n      } else {\n        callbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    }\n    default:\n  }\n};\n\nexport const initializeWebAssemblyAndOrtRuntime = async (): Promise<void> => {\n  if (initialized) {\n    return;\n  }\n  if (initializing) {\n    throw new Error(\"multiple calls to 'initWasm()' detected.\");\n  }\n  if (aborted) {\n    throw new Error(\"previous call to 'initWasm()' failed.\");\n  }\n\n  initializing = true;\n\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      void importProxyWorker().then(([objectUrl, worker]) => {\n        try {\n          proxyWorker = worker;\n          proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n          proxyWorker.onmessage = onProxyWorkerMessage;\n          initWasmCallbacks = [resolve, reject];\n          const message: OrtWasmMessage = { type: 'init-wasm', in: env };\n\n          // if the proxy worker is loaded from a blob URL, we need to make sure the path information is not lost.\n          //\n          // when `env.wasm.wasmPaths` is not set, we need to pass the path information to the worker.\n          //\n          if (!BUILD_DEFS.ENABLE_BUNDLE_WASM_JS && !message.in!.wasm.wasmPaths && objectUrl) {\n            // for a build not bundled the wasm JS, we need to pass the path prefix to the worker.\n            // the path prefix will be used to resolve the path to both the wasm JS and the wasm file.\n            const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\n            if (inferredWasmPathPrefix) {\n              message.in!.wasm.wasmPaths = inferredWasmPathPrefix;\n            }\n          }\n\n          if (\n            BUILD_DEFS.IS_ESM &&\n            BUILD_DEFS.ENABLE_BUNDLE_WASM_JS &&\n            !message.in!.wasm.wasmPaths &&\n            (objectUrl || isEsmImportMetaUrlHardcodedAsFileUri)\n          ) {\n            // for a build bundled the wasm JS, if either of the following conditions is met:\n            // - the proxy worker is loaded from a blob URL\n            // - `import.meta.url` is a file URL, it means it is overwritten by the bundler.\n            //\n            // in either case, the path information is lost, we need to pass the path of the .wasm file to the worker.\n            // we need to use the bundler preferred URL format:\n            // new URL('filename', import.meta.url)\n            // so that the bundler can handle the file using corresponding loaders.\n            message.in!.wasm.wasmPaths = {\n              wasm: !BUILD_DEFS.DISABLE_JSEP\n                ? new URL('ort-wasm-simd-threaded.jsep.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\n                : !BUILD_DEFS.DISABLE_WEBGPU\n                  ? new URL('ort-wasm-simd-threaded.asyncify.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\n                  : new URL('ort-wasm-simd-threaded.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href,\n            };\n          }\n          proxyWorker.postMessage(message);\n          temporaryObjectUrl = objectUrl;\n        } catch (e) {\n          reject(e);\n        }\n      }, reject);\n    });\n  } else {\n    try {\n      await initializeWebAssembly(env.wasm);\n      await core.initRuntime(env);\n      initialized = true;\n    } catch (e) {\n      aborted = true;\n      throw e;\n    } finally {\n      initializing = false;\n    }\n  }\n};\n\nexport const initializeOrtEp = async (epName: string): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('init-ep', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'init-ep', in: { epName, env } };\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initEp(env, epName);\n  }\n};\n\nexport const copyFromExternalBuffer = async (buffer: Uint8Array): Promise<SerializableInternalBuffer> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableInternalBuffer>((resolve, reject) => {\n      enqueueCallbacks('copy-from', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'copy-from', in: { buffer } };\n      proxyWorker!.postMessage(message, [buffer.buffer]);\n    });\n  } else {\n    return core.copyFromExternalBuffer(buffer);\n  }\n};\n\nexport const createSession = async (\n  model: SerializableInternalBuffer | Uint8Array,\n  options?: InferenceSession.SessionOptions,\n): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      enqueueCallbacks('create', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'create', in: { model, options: { ...options } } };\n      const transferable: Transferable[] = [];\n      if (model instanceof Uint8Array) {\n        transferable.push(model.buffer);\n      }\n      proxyWorker!.postMessage(message, transferable);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async (sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('release', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'release', in: sessionId };\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async (\n  sessionId: number,\n  inputIndices: number[],\n  inputs: TensorMetadata[],\n  outputIndices: number[],\n  outputs: Array<TensorMetadata | null>,\n  options: InferenceSession.RunOptions,\n): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some((t) => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some((t) => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      enqueueCallbacks('run', [resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[]; // every input is on CPU.\n      const message: OrtWasmMessage = {\n        type: 'run',\n        in: { sessionId, inputIndices, inputs: serializableInputs, outputIndices, options },\n      };\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async (sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('end-profiling', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'end-profiling', in: sessionId };\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {\n  InferenceSession,\n  InferenceSessionHandler,\n  SessionHandler,\n  Tensor,\n  TRACE_FUNC_BEGIN,\n  TRACE_FUNC_END,\n} from 'onnxruntime-common';\n\nimport { SerializableInternalBuffer, TensorMetadata } from './proxy-messages';\nimport { copyFromExternalBuffer, createSession, endProfiling, releaseSession, run } from './proxy-wrapper';\nimport { isGpuBufferSupportedType, isMLTensorSupportedType } from './wasm-common';\nimport { isNode } from './wasm-utils-env';\nimport { loadFile } from './wasm-utils-load-file';\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, { gpuBuffer: tensor.gpuBuffer }, 'gpu-buffer'];\n    case 'ml-tensor':\n      return [tensor.type, tensor.dims, { mlTensor: tensor.mlTensor }, 'ml-tensor'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const { gpuBuffer, download, dispose } = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, { dataType, dims: tensor[1], download, dispose });\n    }\n    case 'ml-tensor': {\n      const dataType = tensor[0];\n      if (!isMLTensorSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing MLTensor tensor`);\n      }\n      const { mlTensor, download, dispose } = tensor[2];\n      return Tensor.fromMLTensor(mlTensor, { dataType, dims: tensor[1], download, dispose });\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: readonly string[];\n  outputNames: readonly string[];\n  inputMetadata: readonly InferenceSession.ValueMetadata[];\n  outputMetadata: readonly InferenceSession.ValueMetadata[];\n\n  async fetchModelAndCopyToWasmMemory(path: string): Promise<SerializableInternalBuffer> {\n    // fetch model from url and move to wasm heap.\n    return copyFromExternalBuffer(await loadFile(path));\n  }\n\n  async loadModel(pathOrBuffer: string | Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    TRACE_FUNC_BEGIN();\n    let model: Parameters<typeof createSession>[0];\n\n    if (typeof pathOrBuffer === 'string') {\n      if (isNode) {\n        // node\n        model = await loadFile(pathOrBuffer);\n      } else {\n        // browser\n        // fetch model and copy to wasm heap.\n        model = await this.fetchModelAndCopyToWasmMemory(pathOrBuffer);\n      }\n    } else {\n      model = pathOrBuffer;\n    }\n\n    [this.sessionId, this.inputNames, this.outputNames, this.inputMetadata, this.outputMetadata] = await createSession(\n      model,\n      options,\n    );\n    TRACE_FUNC_END();\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(\n    feeds: SessionHandler.FeedsType,\n    fetches: SessionHandler.FetchesType,\n    options: InferenceSession.RunOptions,\n  ): Promise<SessionHandler.ReturnType> {\n    TRACE_FUNC_BEGIN();\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach((kvp) => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor | null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach((kvp) => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs = inputArray.map((t, i) =>\n      encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`),\n    );\n    const outputs = outputArray.map((t, i) =>\n      t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null,\n    );\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    TRACE_FUNC_END();\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Backend, env, InferenceSession, InferenceSessionHandler } from 'onnxruntime-common';\n\nimport { initializeOrtEp, initializeWebAssemblyAndOrtRuntime } from './wasm/proxy-wrapper';\nimport { OnnxruntimeWebAssemblySessionHandler } from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  const simd = env.wasm.simd;\n  if (typeof simd !== 'boolean' && simd !== undefined && simd !== 'fixed' && simd !== 'relaxed') {\n    // eslint-disable-next-line no-console\n    console.warn(\n      `Property \"env.wasm.simd\" is set to unknown value \"${simd}\". Reset it to \\`false\\` and ignore SIMD feature checking.`,\n    );\n    env.wasm.simd = false;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.trace !== 'boolean') {\n    env.wasm.trace = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    // The following logic only applies when `ort.env.wasm.numThreads` is not set by user. We will always honor user's\n    // setting if it is provided.\n\n    // Browser: when crossOriginIsolated is false, SharedArrayBuffer is not available so WebAssembly threads will not\n    // work. In this case, we will set numThreads to 1.\n    //\n    // There is an exception: when the browser is configured to force-enable SharedArrayBuffer (e.g. Chromuim with\n    // --enable-features=SharedArrayBuffer), it is possible that `self.crossOriginIsolated` is false and\n    // SharedArrayBuffer is available at the same time. This is usually for testing. In this case,  we will still set\n    // numThreads to 1 here. If we want to enable multi-threading in test, we should set `ort.env.wasm.numThreads` to a\n    // value greater than 1.\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\n      env.wasm.numThreads = 1;\n    } else {\n      const numCpuLogicalCores =\n        typeof navigator === 'undefined' ? require('node:os').cpus().length : navigator.hardwareConcurrency;\n      env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n    }\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  /**\n   * This function initializes the WebAssembly backend.\n   *\n   * This function will be called only once for each backend name. It will be called the first time when\n   * `ort.InferenceSession.create()` is called with a registered backend name.\n   *\n   * @param backendName - the registered backend name.\n   */\n  async init(backendName: string): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyAndOrtRuntime();\n\n    // performe EP specific initialization\n    await initializeOrtEp(backendName);\n  }\n  createInferenceSessionHandler(\n    path: string,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(\n    buffer: Uint8Array,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(\n    pathOrBuffer: string | Uint8Array,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return handler;\n  }\n}\n\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport { registerBackend, env } from 'onnxruntime-common';\nimport { version } from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_JSEP && !BUILD_DEFS.DISABLE_WEBGPU) {\n  throw new Error(\n    'The current build is specified to enable both JSEP and WebGPU EP. This is not a valid configuration. ' +\n      'JSEP and WebGPU EPs cannot be enabled at the same time.',\n  );\n}\n\nif (!BUILD_DEFS.DISABLE_WEBNN && BUILD_DEFS.DISABLE_JSEP && BUILD_DEFS.DISABLE_WEBGPU) {\n  throw new Error(\n    'The current build is specified to enable WebNN EP without JSEP or WebGPU EP. This is not a valid configuration. ' +\n      'WebNN EP requires either JSEP or WebGPU EP to be enabled.',\n  );\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = require('./backend-wasm').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_JSEP || !BUILD_DEFS.DISABLE_WEBGPU) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  if (!BUILD_DEFS.DISABLE_WEBNN) {\n    registerBackend('webnn', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n}\n\nObject.defineProperty(env.versions, 'web', { value: version, enumerable: true });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.23.2';\n"],"names":["isNode","init_wasm_utils_env","__esmMin","origin","isEsmImportMetaUrlHardcodedAsFileUri","getScriptSrc","scriptSrc","inferWasmPathPrefixFromScriptSrc","isSameOrigin","normalizeUrl","fallbackUrl","preload","dynamicImportDefault","embeddedWasmModule","importWasmModule","init_wasm_utils_import","URL2","filename","prefixOverride","baseUrl","absoluteUrl","blob","url","urlOverride","isMultiThreaded","isWasmOverridden","useEmbeddedModule","wasmModuleFilename","wasmModuleUrl","needPreload","wasm","initialized","initializing","aborted","isMultiThreadSupported","isSimdSupported","isRelaxedSimdSupported","initializeWebAssembly","getInstance","init_wasm_factory","flags","timeout","numThreads","multiThreadSupported","wasmPaths","wasmPrefixOverride","mjsPathOverrideFlag","mjsPathOverride","wasmPathOverrideFlag","wasmPathOverride","wasmBinaryOverride","objectUrl","ortWasmFactory","isTimeout","tasks","resolve","reject","config","fileName","inferredWasmPathPrefix","module","what","allocWasmString","iterateExtraOptions","checkLastError","init_wasm_utils","data","allocs","dataLength","dataOffset","options","prefix","seen","handler","key","value","name","message","stack","ptrSize","paramsOffset","errorCode","errorMessagePointer","errorMessage","setRunOptions","init_run_options","runOptionsHandle","runOptions","tagDataOffset","keyDataOffset","valueDataOffset","e","alloc","getGraphOptimzationLevel","getExecutionMode","appendDefaultOptions","appendSessionConfig","setExecutionProviders","setSessionOptions","init_session_options","graphOptimizationLevel","executionMode","session","ep","sessionOptionsHandle","executionProviders","epName","epOptions","deviceType","webgpuOptions","epNameDataOffset","epOptionsCount","keysOffset","valuesOffset","i","sessionOptions","logIdDataOffset","logSeverityLevel","logVerbosityLevel","optimizedModelFilePathOffset","nameOffset","tensorDataTypeStringToEnum","tensorDataTypeEnumToString","calculateTensorSizeInBytes","tensorTypeToTypedArrayConstructor","logLevelStringToEnum","isGpuBufferSupportedType","isMLTensorSupportedType","dataLocationStringToEnum","init_wasm_common","type","typeProto","dateType","dimsOrSize","elementSize","size","a","b","logLevel","location","loadFile","init_wasm_utils_load_file","file","readFile","createReadStream","stream","chunks","chunk","response","contentLengthHeader","fileSize","reader","buffer","pages","offset","done","chunkSize","TRACE_EVENT_BEGIN","TRACE_EVENT_END","initOrt","initRuntime","initEp","activeSessions","getSessionInputOutputCount","getSessionInputOutputMetadata","copyFromExternalBuffer","createSession","releaseSession","prepareInputOutputTensor","run","endProfiling","init_wasm_core_impl","loggingLevel","env","webgpuAdapter","powerPreference","forceFallbackAdapter","sessionHandle","index","metadataOffset","elementType","dimsCount","dims","symbolicDimNameOffset","model","modelDataOffset","modelData","modelDataLength","ioBindingHandle","inputNamesUTF8Encoded","outputNamesUTF8Encoded","loadingPromises","path","provider","webnnOptions","context","gpuDevice","inputCount","outputCount","enableGraphCapture","inputNames","outputNames","inputMetadata","outputMetadata","outputPreferredLocations","shape","nameString","buf","sessionId","ioBindingState","tensor","tensorHandles","tensorNameUTF8Encoded","dataType","actualLocation","rawData","dataByteLength","gpuBuffer","registerBuffer","mlTensor","registerMLTensor","isGraphInput","isGraphOutput","tensorName","dataTypeEnum","createTemporaryTensor","uploadTensor","tensorId","dimsOffset","d","inputIndices","inputTensors","outputIndices","outputTensors","inputOutputBound","runOptionsAllocs","inputTensorHandles","outputTensorHandles","inputOutputAllocs","beforeRunStack","inputValuesOffset","inputNamesOffset","outputValuesOffset","outputNamesOffset","output","outputPromises","beforeGetTensorDataStack","tensorDataOffset","keepOutputTensor","valueType","dimsLength","preferredLocation","stringData","nextOffset","maxBytesToRead","getBuffer","bufferSize","ensureTensor","isGraphInputOutputTypeSupported","result","typedArrayConstructor","v","p","profileFileName","initializeWebAssemblyAndOrtRuntime","initializeOrtEp","init_proxy_wrapper","inputs","outputs","Tensor","TRACE_FUNC_BEGIN","TRACE_FUNC_END","encodeTensorMetadata","decodeTensorMetadata","OnnxruntimeWebAssemblySessionHandler","init_session_handler_inference","getName","download","dispose","pathOrBuffer","feeds","fetches","inputArray","kvp","outputArray","t","results","resultMap","backend_wasm_exports","__export","OnnxruntimeWebAssemblyBackend","initializeFlags","wasmBackend","init_backend_wasm","simd","numCpuLogicalCores","backendName","ort","registerBackend","version","index_default"],"mappings":";;;;;;;;;;AQQA,OAAwC,qBAAA6J,GAAmB,mBAAAC,OAAuB;ACLlF,OAAS,OAAAe,OAA6B;ACAtC,OAIE,UAAAgG,GACA,oBAAAC,GACA,kBAAAC,OACK;AEAP,UAAY0B,OAAS;AAGrB,OAAS,mBAAAC,GAAiB,OAAA7H,OAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AZbrC,IAGa7K,GAHbC,KAAAC,EAAA;IAAA;IAGaF,IAAS,CAAC,CAAA,CAAE,OAAO,UAAY,OAAe,QAAQ,QAAA,IAAY,QAAQ,QAAA,CAAS,IAAA;AAAA;ACHhG,IAWMG,IAgCOC,IAGPC,IAiDOC,GAOAC,IAUPC,IAaAC,IAaAC,IAcAC,IAeAC,IA2CAC,IAwBOC,IA1ObC,KAAAb,EAAA;IAAA;IAIAD;IAOME,KAASH,KAAU,OAAO,WAAa,MAAc,KAAA,IAAY,SAAS,MAAA,EAgCnEI,KACU,8BAAA,GAAA,GAAkC,WAAW,8BAAA,GAAA,GAAkC,SAEhGC,KAAe,IAA0B;QAE7C,IAAI,CAAAL,GAaF;YAAA,IAAII,IAAsC;gBAcxC,IAAMY,IAAO;gBACb,OAAO,IAAI,IAAI,IAAIA,EAAK,mBAA4B,eAA8B,oGAAE,IAAA,EAAMb,EAAM,EAAE;YACpG;YAEA,OAAO,8BAAA,GAAA;QAAA;IASX,GAOaG,IAAYD,GAAa,GAOzBE,KAAmC,IAA0B;QACxE,IAAID,KAAa,CAACA,EAAU,UAAA,CAAW,OAAO,GAC5C,OAAOA,EAAU,SAAA,CAAU,GAAGA,EAAU,WAAA,CAAY,GAAG,IAAI,CAAC;IAGhE,GAKME,KAAe,CAACS,GAAkBC,IAA4B;QAClE,IAAI;YACF,IAAMC,IAAUD,KAAkBZ;YAElC,OAAA,CADYa,IAAU,IAAI,IAAIF,GAAUE,CAAO,IAAI,IAAI,IAAIF,CAAQ,CAAA,EACxD,MAAA,KAAWd;QACxB,EAAA,OAAQ;YACN,OAAO,CAAA;QACT;IACF,GAKMM,KAAe,CAACQ,GAAkBC,IAA4B;QAClE,IAAMC,IAAUD,KAAkBZ;QAClC,IAAI;YAEF,OAAA,CADYa,IAAU,IAAI,IAAIF,GAAUE,CAAO,IAAI,IAAI,IAAIF,CAAQ,CAAA,EACxD;QACb,EAAA,OAAQ;YACN;QACF;IACF,GAKMP,KAAc,CAACO,GAAkBC,IAA4B,GAAGA,KAAkB,IAAI,GAAGD,CAAQ,EAAA,EAcjGN,KAAU,OAAOS,GAAyC;QAE9D,IAAMC,IAAO,MAAA,CADI,MAAM,MAAMD,GAAa;YAAE,aAAa;QAAc,CAAC,CAAA,EAC5C,IAAA,CAAK;QACjC,OAAO,IAAI,eAAA,CAAgBC,CAAI;IACjC,GAWMT,KAAuB,OAAUU,IAAAA,CACpC,MAAM,MAAA,CAAA,oBAAA,GAAiCA,EAAAA,EAAM,OAAA,EA0C1CT,KAUA,KAAA,GAcOC,KAAmB,OAC9BS,GACAL,GACAM,GACAC,IAC0E;QAM1E,IAAIC,IAAoBb,MAAsB,CAAA,CAAEU,KAAeL,CAAAA;QAC/D,IAAIQ,GACF,IAAKpB,GAyBHoB,IAAoBlB,GAAaF,CAAS;aAAA,IAPtCmB,KAAoB,CAACD,GACvBE,IAAoB,CAAA,MAEpB;aAAA,MAAM,IAAI,MAAM,yCAAyC;QAO/D,IAAIA,GACF,OAAO;YAAC,KAAA;YAAWb,EAAmB;SAAA;QACjC;YACL,IAAMc,IAIA,8BACAC,IAAgBL,KAAed,GAAakB,GAAoBT,CAAc,GAW9EW,IAAc,CAAC7B,KAAUwB,KAAmBI,KAAiB,CAACpB,GAAaoB,GAAeV,CAAc,GACxGI,IAAMO,IACR,MAAMlB,GAAQiB,CAAa,IAC1BA,KAAiBlB,GAAYiB,GAAoBT,CAAc;YACpE,OAAO;gBAACW,IAAcP,IAAM,KAAA;gBAAW,MAAMV,GAA6DU,CAAG,CAAC;;QAChH;IACF;AAAA;AC5SA,IAQIQ,IACAC,IACAC,IACAC,IAEEC,IA0BAC,IA2BAC,IA4BOC,IA4IAC,GA1ObC,IAAArC,EAAA;IAAA;IAMAa;IAGIgB,KAAc,CAAA,GACdC,KAAe,CAAA,GACfC,KAAU,CAAA,GAERC,KAAyB,IAAe;QAE5C,IAAI,OAAO,oBAAsB,KAC/B,OAAO,CAAA;QAGT,IAAI;YAGF,OAAI,OAAO,iBAAmB,OAC5B,IAAI,eAAe,EAAE,KAAA,CAAM,WAAA,CAAY,IAAI,kBAAkB,CAAC,CAAC,GAK1D,YAAY,QAAA,CACjB,IAAI,WAAW;gBACb;gBAAG;gBAAI;gBAAK;gBAAK;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAI;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAI;gBAAI;gBAAG;gBAAG;gBAAG;gBAAI;gBAAG;gBAAK;gBAC3G;gBAAG;gBAAG;gBAAI,EACZ;aAAC,CACH;QACF,EAAA,OAAY;YACV,OAAO,CAAA;QACT;IACF,GAEMC,KAAkB,IAAe;QACrC,IAAI;YAeF,OAAO,YAAY,QAAA,CACjB,IAAI,WAAW;gBACb;gBAAG;gBAAI;gBAAK;gBAAK;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAI;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAI;gBAAI;gBAAG;gBAAI;gBAAG;gBAAI;gBAAG;gBAAK;gBAAI;gBAAK;gBAAI;gBAAG;gBAAG;gBAC7G;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAK;gBAAK;gBAAG;gBAAI,EAC1D;aAAC,CACH;QACF,EAAA,OAAY;YACV,OAAO,CAAA;QACT;IACF,GAEMC,KAAyB,IAAe;QAC5C,IAAI;YAgBF,OAAO,YAAY,QAAA,CACjB,IAAI,WAAW;gBACb;gBAAG;gBAAI;gBAAK;gBAAK;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAG;gBAAI;gBAAG;gBAAG;gBAAK;gBAAG;gBAAG;gBAAG;gBAAG;gBAAI;gBAAI;gBAAG;gBAAI;gBAAG;gBAAI;gBAAG;gBAAK;gBAAI;gBAAI;gBAAG;gBAC1G;gBAAI;gBAAI;gBAAG;gBAAK;gBAAI;gBAAK;gBAAK;gBAAG,EACnC;aAAC,CACH;QACF,EAAA,OAAY;YACV,OAAO,CAAA;QACT;IACF,GAEaC,KAAwB,OAAOG,GAA+C;QACzF,IAAIT,IACF,OAAO,QAAQ,OAAA,CAAQ;QAEzB,IAAIC,IACF,MAAM,IAAI,MAAM,uDAAuD;QAEzE,IAAIC,IACF,MAAM,IAAI,MAAM,oDAAoD;QAGtED,KAAe,CAAA;QAGf,IAAMS,IAAUD,EAAM,WAAA,EAClBE,IAAaF,EAAM,UAAA;QAGvB,IAAIA,EAAM,IAAA,KAAS,CAAA,GAAA;YAEZ,IAAIA,EAAM,IAAA,KAAS,WAAA;gBAExB,IAAI,CAACJ,GAAuB,GAC1B,MAAM,IAAI,MAAM,uEAAuE;YAAA,OAAA,IAEhF,CAACD,GAAgB,GAC1B,MAAM,IAAI,MAAM,+DAA+D;QAAA;QAIjF,IAAMQ,IAAuBT,GAAuB;QAChDQ,IAAa,KAAK,CAACC,KAAAA,CACjB,OAAO,OAAS,OAAe,CAAC,KAAK,mBAAA,IAEvC,QAAQ,IAAA,CACN,mCACED,IACA,uIAEJ,GAIF,QAAQ,IAAA,CACN,4GACF,GAGAF,EAAM,UAAA,GAAaE,IAAa,CAAA;QAGlC,IAAME,IAAYJ,EAAM,SAAA,EAClBK,IAAqB,OAAOD,KAAc,WAAWA,IAAY,KAAA,GACjEE,IAAuBF,GAAiC,KACxDG,IAAmBD,GAA6B,QAAQA,GACxDE,IAAwBJ,GAAiC,MACzDK,IAAoBD,GAA8B,QAAQA,GAC1DE,IAAqBV,EAAM,UAAA,EAE3B,CAACW,GAAWC,CAAc,CAAA,GAAI,MAAMtC,GACxCiC,GACAF,GACAH,IAAa,GACb,CAAC,CAACQ,KAAsB,CAAC,CAACD,CAC5B,GAEII,IAAY,CAAA,GAEVC,IAA8B,CAAC,CAAA;QAmErC,IAhEIb,IAAU,KACZa,EAAM,IAAA,CACJ,IAAI,SAASC,GAAY;YACvB,WAAW,IAAM;gBACfF,IAAY,CAAA,GACZE,EAAQ;YACV,GAAGd,CAAO;QACZ,CAAC,CACH,GAIFa,EAAM,IAAA,CACJ,IAAI,QAAQ,CAACC,GAASC,IAAW;YAC/B,IAAMC,IAAiC;gBAKrC,YAAAf;YACF;YAEA,IAAIQ,GAEFO,EAAO,UAAA,GAAaP;iBAAAA,IACXD,KAAoBJ,GAI7BY,EAAO,UAAA,IAAcC,IAAaT,KAAoBJ,IAAqBa;iBAAAA,IAClEX,KAAmBA,EAAgB,OAAA,CAAQ,OAAO,MAAM,GAEjEU,EAAO,UAAA,GAAcC,KAAa,IAAI,IAAIA,GAAUX,CAAe,EAAE,IAAA;iBAAA,IAC5DI,GAAW;gBACpB,IAAMQ,IAAyBpD,GAAiC;gBAC5DoD,KAAAA,CAEFF,EAAO,UAAA,IAAcC,IAAaC,IAAyBD,CAAAA;YAE/D;YAEAN,EAAeK,CAAM,EAAE,IAAA,EAEpBG,GAAW;gBACV5B,KAAe,CAAA,GACfD,KAAc,CAAA,GACdD,KAAO8B,GACPL,EAAQ,GACJJ,KACF,IAAI,eAAA,CAAgBA,CAAS;YAEjC,IAECU,GAAS;gBACR7B,KAAe,CAAA,GACfC,KAAU,CAAA,GACVuB,EAAOK,CAAI;YACb,CACF;QACF,CAAC,CACH,GAEA,MAAM,QAAQ,IAAA,CAAKP,CAAK,GAEpBD,GACF,MAAM,IAAI,MAAM,CAAA,wDAAA,EAA2DZ,CAAO,CAAA,EAAA,CAAI;IAE1F,GAEaH,IAAc,IAAqB;QAC9C,IAAIP,MAAeD,IACjB,OAAOA;QAGT,MAAM,IAAI,MAAM,qCAAqC;IACvD;AAAA;AChPA,IAKagC,GAeAC,GAgCAC,GApDbC,KAAA/D,EAAA;IAAA;IAGAqC;IAEauB,IAAkB,CAACI,GAAcC,IAA6B;QACzE,IAAMrC,IAAOQ,EAAY,GAEnB8B,IAAatC,EAAK,eAAA,CAAgBoC,CAAI,IAAI,GAC1CG,IAAavC,EAAK,OAAA,CAAQsC,CAAU;QAC1C,OAAAtC,EAAK,YAAA,CAAaoC,GAAMG,GAAYD,CAAU,GAC9CD,EAAO,IAAA,CAAKE,CAAU,GAEfA;IACT,GAMaN,IAAsB,CACjCO,GACAC,GACAC,GACAC,IACS;QACT,IAAI,OAAOH,KAAW,YAAYA,MAAY,MAAM;YAClD,IAAIE,EAAK,GAAA,CAAIF,CAAO,GAClB,MAAM,IAAI,MAAM,+BAA+B;YAE/CE,EAAK,GAAA,CAAIF,CAAO;QAEpB;QAEA,OAAO,OAAA,CAAQA,CAAO,EAAE,OAAA,CAAQ,CAAC,CAACI,GAAKC,CAAK,CAAA,GAAM;YAChD,IAAMC,IAAOL,IAASA,IAASG,IAAMA;YACrC,IAAI,OAAOC,KAAU,UACnBZ,EAAoBY,GAAkCC,IAAO,KAAKJ,GAAMC,CAAO;iBAAA,IACtE,OAAOE,KAAU,YAAY,OAAOA,KAAU,UACvDF,EAAQG,GAAMD,EAAM,QAAA,CAAS,CAAC;iBAAA,IACrB,OAAOA,KAAU,WAC1BF,EAAQG,GAAMD,IAAQ,MAAM,GAAG,MAE/B;iBAAA,MAAM,IAAI,MAAM,CAAA,gCAAA,EAAmC,OAAOA,CAAK,EAAE;QAErE,CAAC;IACH,GAMaX,IAAkBa,GAA0B;QACvD,IAAM/C,IAAOQ,EAAY,GAEnBwC,IAAQhD,EAAK,SAAA,CAAU;QAC7B,IAAI;YACF,IAAMiD,IAAUjD,EAAK,QAAA,EACfkD,IAAelD,EAAK,UAAA,CAAW,IAAIiD,CAAO;YAChDjD,EAAK,gBAAA,CAAiBkD,GAAcA,IAAeD,CAAO;YAC1D,IAAME,IAAY,OAAOnD,EAAK,QAAA,CAASkD,GAAcD,MAAY,IAAI,QAAQ,KAAK,CAAC,GAC7EG,IAAsBpD,EAAK,QAAA,CAASkD,IAAeD,GAAS,GAAG,GAC/DI,IAAeD,IAAsBpD,EAAK,YAAA,CAAaoD,CAAmB,IAAI;YACpF,MAAM,IAAI,MAAM,GAAGL,CAAO,CAAA,aAAA,EAAgBI,CAAS,CAAA,iBAAA,EAAoBE,CAAY,EAAE;QACvF,SAAE;YACArD,EAAK,YAAA,CAAagD,CAAK;QACzB;IACF;AAAA;ACnEA,IAQaM,IARbC,KAAAnF,EAAA;IAAA;IAKAqC;IACA0B;IAEamB,MAAiBd,GAA6D;QACzF,IAAMxC,IAAOQ,EAAY,GACrBgD,IAAmB,GACjBnB,IAAmB,CAAC,CAAA,EAEpBoB,IAA0CjB,KAAW,CAAC;QAE5D,IAAI;YACF,IAAIA,GAAS,qBAAqB,KAAA,GAChCiB,EAAW,gBAAA,GAAmB;iBAAA,IAE9B,OAAOjB,EAAQ,gBAAA,IAAqB,YACpC,CAAC,OAAO,SAAA,CAAUA,EAAQ,gBAAgB,KAC1CA,EAAQ,gBAAA,GAAmB,KAC3BA,EAAQ,gBAAA,GAAmB,GAE3B,MAAM,IAAI,MAAM,CAAA,iCAAA,EAAoCA,EAAQ,gBAAgB,EAAE;YAGhF,IAAIA,GAAS,sBAAsB,KAAA,GACjCiB,EAAW,iBAAA,GAAoB;iBAAA,IACtB,OAAOjB,EAAQ,iBAAA,IAAsB,YAAY,CAAC,OAAO,SAAA,CAAUA,EAAQ,iBAAiB,GACrG,MAAM,IAAI,MAAM,CAAA,kCAAA,EAAqCA,EAAQ,iBAAiB,EAAE;YAG9EA,GAAS,cAAc,KAAA,KAAA,CACzBiB,EAAW,SAAA,GAAY,CAAA,CAAA;YAGzB,IAAIC,IAAgB;YACpB,OAAIlB,GAAS,QAAQ,KAAA,KAAA,CACnBkB,IAAgB1B,EAAgBQ,EAAQ,GAAA,EAAKH,CAAM,CAAA,GAGrDmB,IAAmBxD,EAAK,oBAAA,CACtByD,EAAW,gBAAA,EACXA,EAAW,iBAAA,EACX,CAAC,CAACA,EAAW,SAAA,EACbC,CACF,GACIF,MAAqB,KACvBtB,EAAe,2BAA2B,GAGxCM,GAAS,UAAU,KAAA,KACrBP,EAAoBO,EAAQ,KAAA,EAAO,IAAI,IAAI,SAAoC,CAACI,GAAKC,IAAU;gBAC7F,IAAMc,IAAgB3B,EAAgBY,GAAKP,CAAM,GAC3CuB,IAAkB5B,EAAgBa,GAAOR,CAAM;gBAEjDrC,EAAK,qBAAA,CAAsBwD,GAAkBG,GAAeC,CAAe,MAAM,KACnF1B,EAAe,CAAA,8BAAA,EAAiCU,CAAG,CAAA,GAAA,EAAMC,CAAK,CAAA,CAAA,CAAG;YAErE,CAAC,GAGI;gBAACW;gBAAkBnB,CAAM;;QAClC,EAAA,OAASwB,GAAG;YACV,MAAIL,MAAqB,KACvBxD,EAAK,qBAAA,CAAsBwD,CAAgB,GAE7CnB,EAAO,OAAA,EAASyB,IAAU9D,EAAK,KAAA,CAAM8D,CAAK,CAAC,GACrCD;QACR;IACF;AAAA;ACvEA,IAQME,IAiBAC,IAWAC,IAsBAC,IAcAC,IA+FOC,IAvKbC,KAAAjG,EAAA;IAAA;IAKAqC;IACA0B;IAEM4B,MAA4BO,GAAqD;QACrF,OAAQA,EAAwB;YAC9B,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT;gBACE,MAAM,IAAI,MAAM,CAAA,sCAAA,EAAyCA,CAAsB,EAAE;QACrF;IACF,GAEMN,MAAoBO,GAAqD;QAC7E,OAAQA,EAAe;YACrB,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT;gBACE,MAAM,IAAI,MAAM,CAAA,4BAAA,EAA+BA,CAAa,EAAE;QAClE;IACF,GAEMN,MAAwBzB,GAAmD;QAC1EA,EAAQ,KAAA,IAAA,CACXA,EAAQ,KAAA,GAAQ,CAAC,CAAA,GAEdA,EAAQ,KAAA,CAAM,OAAA,IAAA,CACjBA,EAAQ,KAAA,CAAM,OAAA,GAAU,CAAC,CAAA;QAE3B,IAAMgC,IAAUhC,EAAQ,KAAA,CAAM,OAAA;QACzBgC,EAAQ,4BAAA,IAAA,CAEXA,EAAQ,4BAAA,GAA+B,GAAA,GAKvChC,EAAQ,kBAAA,IACRA,EAAQ,kBAAA,CAAmB,IAAA,EAAMiC,IAAAA,CAAQ,OAAOA,KAAO,WAAWA,IAAKA,EAAG,IAAA,MAAU,QAAQ,KAAA,CAE5FjC,EAAQ,gBAAA,GAAmB,CAAA,CAAA;IAE/B,GAEM0B,KAAsB,CAACQ,GAA8B9B,GAAaC,GAAeR,IAA2B;QAChH,IAAMsB,IAAgB3B,EAAgBY,GAAKP,CAAM,GAC3CuB,IAAkB5B,EAAgBa,GAAOR,CAAM;QACjD7B,EAAY,EAAE,yBAAA,CAA0BkE,GAAsBf,GAAeC,CAAe,MAAM,KACpG1B,EAAe,CAAA,kCAAA,EAAqCU,CAAG,CAAA,GAAA,EAAMC,CAAK,CAAA,CAAA,CAAG;IAEzE,GAQMsB,KAAwB,OAC5BO,GACAC,GACAtC,IACkB;QAClB,KAAA,IAAWoC,KAAME,EAAoB;YACnC,IAAIC,IAAS,OAAOH,KAAO,WAAWA,IAAKA,EAAG,IAAA,EACxCI,IAAqC,CAAC,CAAA;YAG5C,OAAQD,EAAQ;gBACd,KAAK;oBAEH,IADAA,IAAS,SACL,OAAOH,KAAO,UAAU;wBAG1B,IAAMK,IAFeL,GAEsD;wBACvEK,KACFZ,GAAoBQ,GAAsB,cAAcI,GAAYzC,CAAM;oBAE9E;oBACA;gBACF,KAAK;oBA2BD,IADAuC,IAAS,MACL,OAAOH,KAAO,UAAU;wBAC1B,IAAMM,IAAgBN;wBACtB,IAAIM,GAAe,iBAAiB;4BAClC,IAAIA,EAAc,eAAA,KAAoB,UAAUA,EAAc,eAAA,KAAoB,QAChF,MAAM,IAAI,MAAM,CAAA,iDAAA,EAAoDA,EAAc,eAAe,EAAE;4BAErGb,GAAoBQ,GAAsB,mBAAmBK,EAAc,eAAA,EAAiB1C,CAAM;wBACpG;oBACF;oBAEF;gBACF,KAAK;gBACL,KAAK;oBACH;gBACF;oBACE,MAAM,IAAI,MAAM,CAAA,kCAAA,EAAqCuC,CAAM,EAAE;YACjE;YAEA,IAAMI,IAAmBhD,EAAgB4C,GAAQvC,CAAM,GACjD4C,IAAiBJ,EAAU,MAAA,EAC7BK,IAAa,GACbC,IAAe;YACnB,IAAIF,IAAiB,GAAG;gBACtBC,IAAa1E,EAAY,EAAE,OAAA,CAAQyE,IAAiBzE,EAAY,EAAE,QAAQ,GAC1E6B,EAAO,IAAA,CAAK6C,CAAU,GACtBC,IAAe3E,EAAY,EAAE,OAAA,CAAQyE,IAAiBzE,EAAY,EAAE,QAAQ,GAC5E6B,EAAO,IAAA,CAAK8C,CAAY;gBACxB,IAAA,IAASC,IAAI,GAAGA,IAAIH,GAAgBG,IAClC5E,EAAY,EAAE,QAAA,CAAS0E,IAAaE,IAAI5E,EAAY,EAAE,QAAA,EAAUqE,CAAAA,CAAUO,CAAC,CAAA,CAAE,CAAC,CAAA,EAAG,GAAG,GACpF5E,EAAY,EAAE,QAAA,CAAS2E,IAAeC,IAAI5E,EAAY,EAAE,QAAA,EAAUqE,CAAAA,CAAUO,CAAC,CAAA,CAAE,CAAC,CAAA,EAAG,GAAG;YAE1F;YAEG,MAAM5E,EAAY,EAAE,2BAAA,CACnBkE,GACAM,GACAE,GACAC,GACAF,CACF,MAAO,KAEP/C,EAAe,CAAA,iCAAA,EAAoC0C,CAAM,CAAA,CAAA,CAAG;QAEhE;IACF,GAEaR,KAAoB,OAAO5B,GAA2E;QACjH,IAAMxC,IAAOQ,EAAY,GACrBkE,IAAuB,GACrBrC,IAAmB,CAAC,CAAA,EAEpBgD,IAAkD7C,KAAW,CAAC;QACpEyB,GAAqBoB,CAAc;QAEnC,IAAI;YACF,IAAMf,IAAyBP,GAAyBsB,EAAe,sBAAA,IAA0B,KAAK,GAChGd,IAAgBP,GAAiBqB,EAAe,aAAA,IAAiB,YAAY,GAC7EC,IACJ,OAAOD,EAAe,KAAA,IAAU,WAAWrD,EAAgBqD,EAAe,KAAA,EAAOhD,CAAM,IAAI,GAEvFkD,IAAmBF,EAAe,gBAAA,IAAoB;YAC5D,IAAI,CAAC,OAAO,SAAA,CAAUE,CAAgB,KAAKA,IAAmB,KAAKA,IAAmB,GACpF,MAAM,IAAI,MAAM,CAAA,iCAAA,EAAoCA,CAAgB,EAAE;YAGxE,IAAMC,IAAoBH,EAAe,iBAAA,IAAqB;YAC9D,IAAI,CAAC,OAAO,SAAA,CAAUG,CAAiB,KAAKA,IAAoB,KAAKA,IAAoB,GACvF,MAAM,IAAI,MAAM,CAAA,kCAAA,EAAqCA,CAAiB,EAAE;YAG1E,IAAMC,IACJ,OAAOJ,EAAe,sBAAA,IAA2B,WAC7CrD,EAAgBqD,EAAe,sBAAA,EAAwBhD,CAAM,IAC7D;YAsBN,IApBAqC,IAAuB1E,EAAK,wBAAA,CAC1BsE,GACA,CAAC,CAACe,EAAe,iBAAA,EACjB,CAAC,CAACA,EAAe,gBAAA,EACjBd,GACA,CAAC,CAACc,EAAe,eAAA,EACjB,GACAC,GACAC,GACAC,GACAC,CACF,GACIf,MAAyB,KAC3BxC,EAAe,+BAA+B,GAG5CmD,EAAe,kBAAA,IACjB,MAAMlB,GAAsBO,GAAsBW,EAAe,kBAAA,EAAoBhD,CAAM,GAGzFgD,EAAe,kBAAA,KAAuB,KAAA,GAAW;gBACnD,IAAI,OAAOA,EAAe,kBAAA,IAAuB,WAC/C,MAAM,IAAI,MAAM,CAAA,4CAAA,EAA+CA,EAAe,kBAAkB,EAAE;gBAEpGnB,GACEQ,GACA,sBACAW,EAAe,kBAAA,CAAmB,QAAA,CAAS,GAC3ChD,CACF;YACF;YAEA,IAAIgD,EAAe,sBAAA,EACjB,KAAA,IAAW,CAACvC,GAAMD,CAAK,CAAA,IAAK,OAAO,OAAA,CAAQwC,EAAe,sBAAsB,EAAG;gBACjF,IAAI,OAAOvC,KAAS,UAClB,MAAM,IAAI,MAAM,CAAA,+CAAA,EAAkDA,CAAI,EAAE;gBAE1E,IAAI,OAAOD,KAAU,YAAY,CAAC,OAAO,SAAA,CAAUA,CAAK,KAAKA,IAAQ,GACnE,MAAM,IAAI,MAAM,CAAA,8DAAA,EAAiEA,CAAK,EAAE;gBAE1F,IAAM6C,IAAa1D,EAAgBc,GAAMT,CAAM;gBAC3CrC,EAAK,4BAAA,CAA6B0E,GAAsBgB,GAAY7C,CAAK,MAAM,KACjFX,EAAe,CAAA,qCAAA,EAAwCY,CAAI,CAAA,GAAA,EAAMD,CAAK,CAAA,CAAA,CAAG;YAE7E;YAGF,OAAIwC,EAAe,KAAA,KAAU,KAAA,KAC3BpD,EAAoBoD,EAAe,KAAA,EAAO,IAAI,IAAI,SAAoC,CAACzC,GAAKC,IAAU;gBACpGqB,GAAoBQ,GAAsB9B,GAAKC,GAAOR,CAAM;YAC9D,CAAC,GAGI;gBAACqC;gBAAsBrC,CAAM;;QACtC,EAAA,OAASwB,GAAG;YACV,MAAIa,MAAyB,KACvB1E,EAAK,yBAAA,CAA0B0E,CAAoB,MAAM,KAC3DxC,EAAe,gCAAgC,GAGnDG,EAAO,OAAA,EAASyB,IAAU9D,EAAK,KAAA,CAAM8D,CAAK,CAAC,GACrCD;QACR;IACF;AAAA;ACnQA,IA2Ca8B,GAyCAC,IA0CAC,GAqCAC,IAgDAC,IAoBAC,IAcAC,IAgBAC,IArQbC,KAAA/H,EAAA;IAAA;IA2CauH,KAA8BS,GAA2B;QACpE,OAAQA,EAAM;YACZ,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YAET;gBACE,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0BA,CAAI,EAAE;QACpD;IACF,GAKaR,MAA8BS,GAAqC;QAC9E,OAAQA,EAAW;YACjB,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YACT,IAAK,CAAA;gBACH,OAAO;YAET;gBACE,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0BA,CAAS,EAAE;QACzD;IACF,GAMaR,IAA6B,CACxCS,GACAC,IACuB;QACvB,IAAMC,IAAc;YAClB,CAAA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA,CAAA;YACA;YACA;YACA;YACA;YACA;YACA,CAAA;YACA,CAAA;YACA,CAAA;YACA,CAAA;YACA,CAAA;YACA,CAAA;YACA,CAAA;YACA;YACA,EACF;SAAA,CAAEF,CAAQ,CAAA,EAEJG,IAAO,OAAOF,KAAe,WAAWA,IAAaA,EAAW,MAAA,CAAO,CAACG,GAAGC,IAAMD,IAAIC,GAAG,CAAC;QAC/F,OAAOH,IAAc,IAAI,KAAK,IAAA,CAAKC,IAAOD,CAAW,IAAI,KAAA;IAC3D,GAKaV,MACXM,GAY+B;QAC/B,OAAQA,EAAM;YACZ,KAAK;gBAEH,OAAO,OAAO,eAAiB,OAAe,aAAa,IAAA,GAAO,eAAe;YACnF,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT,KAAK;gBACH,OAAO;YACT;gBACE,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqBA,CAAI,EAAE;QAC/C;IACF,GAKaL,MAAwBa,GAA0E;QAC7G,OAAQA,EAAU;YAChB,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT;gBACE,MAAM,IAAI,MAAM,CAAA,2BAAA,EAA8BA,CAAQ,EAAE;QAC5D;IACF,GAKaZ,MAA4BI,IACvCA,MAAS,aACTA,MAAS,aACTA,MAAS,WACTA,MAAS,WACTA,MAAS,YACTA,MAAS,WACTA,MAAS,UACTA,MAAS,WACTA,MAAS,QAKEH,MAA2BG,IACtCA,MAAS,aACTA,MAAS,aACTA,MAAS,WACTA,MAAS,WACTA,MAAS,YACTA,MAAS,YACTA,MAAS,UACTA,MAAS,WACTA,MAAS,UACTA,MAAS,WACTA,MAAS,QAKEF,MAA4BW,GAA0C;QACjF,OAAQA,EAAU;YAChB,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT,KAAK;gBACH,MAAO,CAAA;YACT;gBACE,MAAM,IAAI,MAAM,CAAA,2BAAA,EAA8BA,CAAQ,EAAE;QAC5D;IACF;AAAA;ACtRA,IAWaC,GAXbC,KAAA3I,EAAA;IAAA;IAGAD;IAQa2I,IAAW,OAAOE,GAA4E;QACzG,IAAI,OAAOA,KAAS,UAClB,IAAI9I,GAEF,IAAI;YACF,IAAM,EAAE,UAAA+I,CAAS,EAAA,GAAI,GAAQ,kBAAkB;YAC/C,OAAO,IAAI,WAAW,MAAMA,EAASD,CAAI,CAAC;QAC5C,EAAA,OAASnD,GAAG;YACV,IAAIA,EAAE,IAAA,KAAS,yBAAyB;gBAEtC,IAAM,EAAE,kBAAAqD,CAAiB,EAAA,GAAI,GAAQ,SAAS,GACxCC,IAASD,EAAiBF,CAAI,GAC9BI,IAAuB,CAAC,CAAA;gBAC9B,WAAA,IAAiBC,KAASF,EACxBC,EAAO,IAAA,CAAKC,CAAK;gBAEnB,OAAO,IAAI,WAAW,OAAO,MAAA,CAAOD,CAAM,CAAC;YAC7C;YACA,MAAMvD;QACR;aACK;YAEL,IAAMyD,IAAW,MAAM,MAAMN,CAAI;YACjC,IAAI,CAACM,EAAS,EAAA,EACZ,MAAM,IAAI,MAAM,CAAA,mCAAA,EAAsCN,CAAI,EAAE;YAE9D,IAAMO,IAAsBD,EAAS,OAAA,CAAQ,GAAA,CAAI,gBAAgB,GAC3DE,IAAWD,IAAsB,SAASA,GAAqB,EAAE,IAAI;YAC3E,IAAIC,IAAW,YAGb,OAAO,IAAI,WAAW,MAAMF,EAAS,WAAA,CAAY,CAAC;YAC7C;gBAEL,IAAI,CAACA,EAAS,IAAA,EACZ,MAAM,IAAI,MAAM,CAAA,mCAAA,EAAsCN,CAAI,CAAA,mBAAA,CAAqB;gBAEjF,IAAMS,IAASH,EAAS,IAAA,CAAK,SAAA,CAAU,GAEnCI;gBACJ,IAAI;oBAEFA,IAAS,IAAI,YAAYF,CAAQ;gBACnC,EAAA,OAAS3D,GAAG;oBACV,IAAIA,aAAa,YAAY;wBAE3B,IAAM8D,IAAQ,KAAK,IAAA,CAAKH,IAAW,KAAK;wBACxCE,IAAS,IAAI,YAAY,MAAA,CAAO;4BAAE,SAASC;4BAAO,SAASA;wBAAM,CAAC,EAAE;oBACtE,KACE,EAAA,MAAM9D;gBAEV;gBAEA,IAAI+D,IAAS;gBAEb,OAAa;oBACX,IAAM,EAAE,MAAAC,CAAAA,EAAM,OAAAhF,CAAM,EAAA,GAAI,MAAM4E,EAAO,IAAA,CAAK;oBAC1C,IAAII,GACF;oBAEF,IAAMC,IAAYjF,EAAM,UAAA;oBACV,IAAI,WAAW6E,GAAQE,GAAQE,CAAS,EAChD,GAAA,CAAIjF,CAAK,GACf+E,KAAUE;gBACZ;gBACA,OAAO,IAAI,WAAWJ,GAAQ,GAAGF,CAAQ;YAC3C;QACF,KACK;aAAA,OAAIR,aAAgB,OAClB,IAAI,WAAW,MAAMA,EAAK,WAAA,CAAY,CAAC,IACrCA,aAAgB,aAClBA,IAEA,IAAI,WAAWA,CAAI;IAE9B;AAAA;;ACtFA,IAiFMiB,IAWOC,IAWAC,IAsIPC,GAOAC,IAiBAC,IAiDOC,IAkBAC,IA6MAC,IA+BAC,IAqIAC,IA2YAC,IApkCbC,KAAAzK,EAAA;IAAA;IAgBAmF;IACAc;IACA8B;IAUA1F;IACA0B;IACA4E;IAmDMkB,KAAU,CAACrH,GAAoBkI,IAA+B;QAChDtI,EAAY,EAAE,QAAA,CAASI,GAAYkI,CAAY,MAC/C,KAChB5G,EAAe,+BAA+B;IAElD,GAMagG,KAAc,OAAOa,GAA4B;QAE5Dd,GAAQc,EAAI,IAAA,CAAK,UAAA,EAAahD,GAAqBgD,EAAI,QAAQ,CAAC;IAClE,GAQaZ,KAAS,OAAOY,GAAUnE,IAAkC;QAEvEpE,EAAY,EAAE,SAAA,GAAY;QAG1B,IAAIwI,IAAgBD,EAAI,MAAA,CAAO,OAAA;QAC/B,IAAInE,MAAW,UAAU;YACvB,IAAI,OAAO,YAAc,OAAe,CAAC,UAAU,GAAA,EACjD,MAAM,IAAI,MAAM,gDAAgD;YAElE,IAAKoE,GAAAA;gBAmBH,IACE,OAAOA,EAAc,MAAA,IAAW,YAChC,OAAOA,EAAc,QAAA,IAAa,YAClC,OAAOA,EAAc,aAAA,IAAkB,YAEvC,MAAM,IAAI,MAAM,kFAAkF;YAAA,OAxBlF;gBAElB,IAAMC,IAAkBF,EAAI,MAAA,CAAO,eAAA;gBACnC,IAAIE,MAAoB,KAAA,KAAaA,MAAoB,eAAeA,MAAoB,oBAC1F,MAAM,IAAI,MAAM,CAAA,kCAAA,EAAqCA,CAAe,CAAA,CAAA,CAAG;gBAEzE,IAAMC,IAAuBH,EAAI,MAAA,CAAO,oBAAA;gBACxC,IAAIG,MAAyB,KAAA,KAAa,OAAOA,KAAyB,WACxE,MAAM,IAAI,MAAM,CAAA,uCAAA,EAA0CA,CAAoB,CAAA,CAAA,CAAG;gBAGnF,IADAF,IAAgB,MAAM,UAAU,GAAA,CAAI,cAAA,CAAe;oBAAE,iBAAAC;oBAAiB,sBAAAC;gBAAqB,CAAC,GACxF,CAACF,GACH,MAAM,IAAI,MACR,0GAEF;YAEJ;QAUF;QAGA,IAAIpE,MAAW,WAAA,CACT,OAAO,YAAc,OAAe,CAAE,UAAyC,EAAA,GACjF,MAAM,IAAI,MAAM,+CAA+C;IA8CrE,GA8CMwD,IAAiB,IAAI,KAOrBC,MAA8Bc,GAA4C;QAC9E,IAAMnJ,IAAOQ,EAAY,GACnBwC,IAAQhD,EAAK,SAAA,CAAU;QAC7B,IAAI;YACF,IAAMiD,IAAUjD,EAAK,QAAA,EACfuC,IAAavC,EAAK,UAAA,CAAW,IAAIiD,CAAO;YAC5BjD,EAAK,uBAAA,CAAwBmJ,GAAe5G,GAAYA,IAAaU,CAAO,MAC5E,KAChBf,EAAe,uCAAuC;YAExD,IAAMkE,IAAOnD,MAAY,IAAI,QAAQ;YACrC,OAAO;gBAAC,OAAOjD,EAAK,QAAA,CAASuC,GAAY6D,CAAI,CAAC;gBAAG,OAAOpG,EAAK,QAAA,CAASuC,IAAaU,GAASmD,CAAI,CAAC,CAAC;;QACpG,SAAE;YACApG,EAAK,YAAA,CAAagD,CAAK;QACzB;IACF,GAEMsF,KAAgC,CACpCa,GACAC,IAC6E;QAC7E,IAAMpJ,IAAOQ,EAAY,GACnBwC,IAAQhD,EAAK,SAAA,CAAU,GACzBqJ,IAAiB;QACrB,IAAI;YACF,IAAMpG,IAAUjD,EAAK,QAAA,EACfuC,IAAavC,EAAK,UAAA,CAAW,IAAIiD,CAAO;YAC5BjD,EAAK,0BAAA,CAA2BmJ,GAAeC,GAAO7G,GAAYA,IAAaU,CAAO,MACtF,KAChBf,EAAe,0CAA0C;YAE3D,IAAMwD,IAAa,OAAO1F,EAAK,QAAA,CAASuC,GAAY,GAAG,CAAC;YACxD8G,IAAiB,OAAOrJ,EAAK,QAAA,CAASuC,IAAaU,GAAS,GAAG,CAAC;YAEhE,IAAMqG,IAActJ,EAAK,MAAA,CAAOqJ,IAAiB,CAAC,CAAA;YAClD,IAAIC,MAAgB,GAClB,OAAO;gBAAC5D;gBAAY,CAAC;aAAA;YAIvB,IAAM6D,IAAYvJ,EAAK,OAAA,CAAQqJ,IAAiB,IAAI,CAAC,CAAA,EAE/CG,IAA+B,CAAC,CAAA;YACtC,IAAA,IAASpE,IAAI,GAAGA,IAAImE,GAAWnE,IAAK;gBAClC,IAAMqE,IAAwB,OAAOzJ,EAAK,QAAA,CAASqJ,IAAiB,IAAIjE,IAAInC,GAAS,GAAG,CAAC;gBACzFuG,EAAK,IAAA,CACHC,MAA0B,IACtBzJ,EAAK,YAAA,CAAayJ,CAAqB,IACvC,OAAOzJ,EAAK,QAAA,CAASqJ,IAAiB,IAAA,CAAKjE,IAAImE,CAAAA,IAAatG,GAAS,GAAG,CAAC,CAC/E;YACF;YACA,OAAO;gBAACyC;gBAAY4D;gBAAaE,CAAI;;QACvC,SAAE;YACAxJ,EAAK,YAAA,CAAagD,CAAK,GACnBqG,MAAmB,KACrBrJ,EAAK,QAAA,CAASqJ,CAAc;QAEhC;IACF,GAQad,MAA0BmB,GAAwC;QAC7E,IAAM1J,IAAOQ,EAAY,GACnBmJ,IAAkB3J,EAAK,OAAA,CAAQ0J,EAAM,UAAU;QACrD,IAAIC,MAAoB,GACtB,MAAM,IAAI,MAAM,CAAA,4DAAA,EAA+DD,EAAM,UAAU,CAAA,CAAA,CAAG;QAEpG,OAAA1J,EAAK,MAAA,CAAO,GAAA,CAAI0J,GAAOC,CAAe,GAC/B;YAACA;YAAiBD,EAAM,UAAU;;IAC3C,GAUalB,KAAgB,OAC3BoB,GACApH,IACyC;QACzC,IAAImH,GAAyBE,GACvB7J,IAAOQ,EAAY;QAErB,MAAM,OAAA,CAAQoJ,CAAS,IAEzB,CAACD,GAAiBE,CAAe,CAAA,GAAID,IAC5BA,EAAU,MAAA,KAAW5J,EAAK,MAAA,CAAO,MAAA,GAE1C,CAAC2J,GAAiBE,CAAe,CAAA,GAAI;YAACD,EAAU,UAAA;YAAYA,EAAU,UAAU;SAAA,GAGhF,CAACD,GAAiBE,CAAe,CAAA,GAAItB,GAAuBqB,CAAS;QAGvE,IAAIT,IAAgB,GAChBzE,IAAuB,GACvBoF,IAAkB,GAClBzH,IAAmB,CAAC,CAAA,EAClB0H,IAAwB,CAAC,CAAA,EACzBC,IAAyB,CAAC,CAAA;QAEhC,IAAI;YAGF,IAFA,CAACtF,GAAsBrC,CAAM,CAAA,GAAI,MAAM+B,GAAkB5B,CAAO,GAE5DA,GAAS,gBAAgBxC,EAAK,iBAAA,EAAmB;gBACnD,IAAMiK,IAAkB,CAAC,CAAA;gBACzB,KAAA,IAAWjD,KAAQxE,EAAQ,YAAA,CAAc;oBACvC,IAAM0H,IAAO,OAAOlD,KAAS,WAAWA,IAAOA,EAAK,IAAA;oBACpDiD,EAAgB,IAAA,CACdnD,EAAS,OAAOE,KAAS,WAAWA,IAAOA,EAAK,IAAI,EAAE,IAAA,CAAM5E,GAAS;wBACnEpC,EAAK,iBAAA,CAAkBkK,GAAM9H,CAAI;oBACnC,CAAC,CACH;gBACF;gBAGA,MAAM,QAAQ,GAAA,CAAI6H,CAAe;YACnC;YAEA,KAAA,IAAWE,KAAY3H,GAAS,sBAAsB,CAAC,CAAA,CAErD,IAAA,CADqB,OAAO2H,KAAa,WAAWA,IAAWA,EAAS,IAAA,MACnD,SAAS;gBAE5B,IADAnK,EAAK,wBAAA,GAA2B,CAAA,GAC5B,OAAOmK,KAAa,UAAU;oBAChC,IAAMC,IAAeD,GACfE,IAAWD,GAA6D,SACxEE,IAAaF,GAAsD,WACnEtF,IAAcsF,GAAuD,YACrEnB,IAAmBmB,GAAuD;oBAC5EC,IACFrK,EAAK,cAAA,GAAiBqK,IACbC,IACTtK,EAAK,cAAA,GAAiB,MAAMA,EAAK,oBAAA,CAAsBsK,CAAS,IAEhEtK,EAAK,cAAA,GAAiB,MAAMA,EAAK,oBAAA,CAAsB;wBAAE,YAAA8E;wBAAY,iBAAAmE;oBAAgB,CAAC;gBAE1F,OACEjJ,EAAK,cAAA,GAAiB,MAAMA,EAAK,oBAAA,CAAsB;gBAEzD;YACF;YAGFmJ,IAAgB,MAAMnJ,EAAK,iBAAA,CAAkB2J,GAAiBE,GAAiBnF,CAAoB,GACnG1E,EAAK,qBAAA,GAAwBmJ,CAAa,GACtCA,MAAkB,KACpBjH,EAAe,yBAAyB,GAG1ClC,EAAK,mBAAA,GAAsB,GAGvBA,EAAK,cAAA,IAAA,CACPA,EAAK,sBAAA,CAAwBmJ,GAAenJ,EAAK,cAAc,GAC/DA,EAAK,cAAA,GAAiB,KAAA,GACtBA,EAAK,wBAAA,GAA2B,CAAA,CAAA;YAGlC,IAAM,CAACuK,GAAYC,CAAW,CAAA,GAAInC,GAA2Bc,CAAa,GAEpEsB,IAAqB,CAAC,CAACjI,GAAS,oBAEhCkI,IAAa,CAAC,CAAA,EACdC,IAAc,CAAC,CAAA,EACfC,IAAkD,CAAC,CAAA,EACnDC,IAAmD,CAAC,CAAA,EACpDC,IAAwE,CAAC,CAAA;YAC/E,IAAA,IAAS1F,IAAI,GAAGA,IAAImF,GAAYnF,IAAK;gBACnC,IAAM,CAACM,GAAY4D,GAAayB,CAAK,CAAA,GAAIzC,GAA8Ba,GAAe/D,CAAC;gBACnFM,MAAe,KACjBxD,EAAe,0BAA0B,GAE3C6H,EAAsB,IAAA,CAAKrE,CAAU;gBACrC,IAAM5C,IAAO9C,EAAK,YAAA,CAAa0F,CAAU;gBACzCgF,EAAW,IAAA,CAAK5H,CAAI,GACpB8H,EAAc,IAAA,CACZtB,MAAgB,IACZ;oBAAE,MAAAxG;oBAAM,UAAU,CAAA;gBAAM,IACxB;oBAAE,MAAAA;oBAAM,UAAU,CAAA;oBAAM,MAAM8C,GAA2B0D,CAAW;oBAAG,OAAOyB;gBAAO,CAC3F;YACF;YACA,IAAA,IAAS3F,IAAI,GAAGA,IAAIoF,GAAapF,IAAK;gBACpC,IAAM,CAACM,GAAY4D,GAAayB,CAAK,CAAA,GAAIzC,GAA8Ba,GAAe/D,IAAImF,CAAU;gBAChG7E,MAAe,KACjBxD,EAAe,2BAA2B,GAE5C8H,EAAuB,IAAA,CAAKtE,CAAU;gBACtC,IAAMsF,IAAahL,EAAK,YAAA,CAAa0F,CAAU;gBAC/CiF,EAAY,IAAA,CAAKK,CAAU,GAC3BH,EAAe,IAAA,CACbvB,MAAgB,IACZ;oBAAE,MAAM0B;oBAAY,UAAU,CAAA;gBAAM,IACpC;oBAAE,MAAMA;oBAAY,UAAU,CAAA;oBAAM,MAAMpF,GAA2B0D,CAAW;oBAAG,OAAOyB;gBAAO,CACvG;YA0BF;YAuBA,OAAA3C,EAAe,GAAA,CAAIe,GAAe;gBAChCA;gBACAY;gBACAC;gBAvBwC;gBAyBxCS;gBACA,CAAA,CACF;aAAC,GACM;gBAACtB;gBAAeuB;gBAAYC;gBAAaC;gBAAeC,CAAc;;QAC/E,EAAA,OAAShH,GAAG;YACV,MAAAkG,EAAsB,OAAA,EAASkB,IAAQjL,EAAK,QAAA,CAASiL,CAAG,CAAC,GACzDjB,EAAuB,OAAA,EAASiB,IAAQjL,EAAK,QAAA,CAASiL,CAAG,CAAC,GAEtDnB,MAAoB,KAClB9J,EAAK,kBAAA,CAAmB8J,CAAe,MAAM,KAC/C5H,EAAe,2BAA2B,GAI1CiH,MAAkB,KAChBnJ,EAAK,kBAAA,CAAmBmJ,CAAa,MAAM,KAC7CjH,EAAe,wBAAwB,GAGrC2B;QACR,SAAE;YACA7D,EAAK,KAAA,CAAM2J,CAAe,GACtBjF,MAAyB,KACvB1E,EAAK,yBAAA,CAA0B0E,CAAoB,MAAM,KAC3DxC,EAAe,gCAAgC,GAGnDG,EAAO,OAAA,EAASyB,IAAU9D,EAAK,KAAA,CAAM8D,CAAK,CAAC,GAG3C9D,EAAK,mBAAA,GAAsB;QAC7B;IACF,GAEayI,MAAkByC,GAA4B;QACzD,IAAMlL,IAAOQ,EAAY,GACnBgE,IAAU4D,EAAe,GAAA,CAAI8C,CAAS;QAC5C,IAAI,CAAC1G,GACH,MAAM,IAAI,MAAM,CAAA,4CAAA,EAA+C0G,CAAS,EAAE;QAE5E,IAAM,CAAC/B,GAAeY,GAAuBC,GAAwBmB,GAAgBV,CAAkB,CAAA,GAAIjG;QAEvG2G,KAAAA,CACEV,KACEzK,EAAK,qBAAA,CAAsBmL,EAAe,MAAM,MAAM,KACxDjJ,EAAe,4BAA4B,GAG3ClC,EAAK,kBAAA,CAAmBmL,EAAe,MAAM,MAAM,KACrDjJ,EAAe,2BAA2B,CAAA,GAI9ClC,EAAK,oBAAA,GAAuBkL,CAAS,GACrClL,EAAK,qBAAA,GAAwBkL,CAAS,GACtClL,EAAK,sBAAA,GAAyBkL,CAAS,GAEvCnB,EAAsB,OAAA,EAASkB,IAAQjL,EAAK,QAAA,CAASiL,CAAG,CAAC,GACzDjB,EAAuB,OAAA,EAASiB,IAAQjL,EAAK,QAAA,CAASiL,CAAG,CAAC,GACtDjL,EAAK,kBAAA,CAAmBmJ,CAAa,MAAM,KAC7CjH,EAAe,wBAAwB,GAEzCkG,EAAe,MAAA,CAAO8C,CAAS;IACjC,GAEaxC,KAA2B,OACtC0C,GACAC,GACAhJ,GACA6I,GACAI,GACAlC,GACAqB,IAAqB,CAAA,CAAA,GACH;QAClB,IAAI,CAACW,GAAQ;YACXC,EAAc,IAAA,CAAK,CAAC;YACpB;QACF;QAEA,IAAMrL,IAAOQ,EAAY,GACnByC,IAAUjD,EAAK,QAAA,EAEfuL,IAAWH,CAAAA,CAAO,CAAC,CAAA,EACnB5B,IAAO4B,CAAAA,CAAO,CAAC,CAAA,EACfvE,IAAWuE,CAAAA,CAAO,CAAC,CAAA,EACrBI,IAAiB3E,GAEjB4E,GACAC;QAEJ,IAAIH,MAAa,YAAA,CAAa1E,MAAa,gBAAgBA,MAAa,WAAA,GACtE,MAAM,IAAI,MAAM,wCAAwC;QAG1D,IAAI4D,KAAsB5D,MAAa,cACrC,MAAM,IAAI,MACR,CAAA,wDAAA,EAA2DuC,CAAK,CAAA,iCAAA,CAClE;QAGF,IAAIvC,MAAa,cAAc;YAC7B,IAAM8E,IAAYP,CAAAA,CAAO,CAAC,CAAA,CAAE,SAAA;YAC5BM,IAAiB7F,EAA2BF,EAA2B4F,CAAQ,GAAG/B,CAAI;YAS/E;gBACL,IAAMoC,IAAiB5L,EAAK,kBAAA;gBAC5B,IAAI,CAAC4L,GACH,MAAM,IAAI,MAAM,qEAAqE;gBAEvFH,IAAUG,EAAeV,GAAW9B,GAAOuC,GAAWD,CAAc;YACtE;QACF,OAAA,IAAW7E,MAAa,aAAa;YACnC,IAAMgF,IAAWT,CAAAA,CAAO,CAAC,CAAA,CAAE,QAAA;YAC3BM,IAAiB7F,EAA2BF,EAA2B4F,CAAQ,GAAG/B,CAAI;YAEtF,IAAMsC,IAAmB9L,EAAK,qBAAA;YAC9B,IAAI,CAAC8L,GACH,MAAM,IAAI,MAAM,mEAAmE;YAErFL,IAAUK,EAAiBZ,GAAWW,GAAUlG,EAA2B4F,CAAQ,GAAG/B,CAAI;QAC5F,OAAO;YACL,IAAMpH,IAAOgJ,CAAAA,CAAO,CAAC,CAAA;YAErB,IAAI,MAAM,OAAA,CAAQhJ,CAAI,GAAG;gBAEvBsJ,IAAiBzI,IAAUb,EAAK,MAAA,EAChCqJ,IAAUzL,EAAK,OAAA,CAAQ0L,CAAc,GACrCrJ,EAAO,IAAA,CAAKoJ,CAAO;gBACnB,IAAA,IAASrG,IAAI,GAAGA,IAAIhD,EAAK,MAAA,EAAQgD,IAAK;oBACpC,IAAI,OAAOhD,CAAAA,CAAKgD,CAAC,CAAA,IAAM,UACrB,MAAM,IAAI,UAAU,CAAA,qBAAA,EAAwBA,CAAC,CAAA,gBAAA,CAAkB;oBAEjEpF,EAAK,QAAA,CAASyL,IAAUrG,IAAInC,GAASjB,EAAgBI,CAAAA,CAAKgD,CAAC,CAAA,EAAG/C,CAAM,GAAG,GAAG;gBAC5E;YACF,OAAO;gBACL,IAAM0J,IAAe/L,EAAK,iBAAA,EACpBgM,IAAgBhM,EAAK,kBAAA;gBAC3B,IAAIuL,MAAa,YAAYQ,KAAgBC,GAAe;oBAC1D,IAAMC,IAAajM,EAAK,YAAA,CAAasL,CAAqB;oBAE1D,IAAIS,EAAab,GAAWe,CAAU,KAAKD,EAAcd,GAAWe,CAAU,GAAG;wBAC/E,IAAMC,IAAevG,EAA2B4F,CAAQ;wBACxDG,IAAiB7F,EAA2BqG,GAAc1C,CAAI,GAC9DgC,IAAiB;wBACjB,IAAMW,IAAwBnM,EAAK,0BAAA,EAC7BoM,IAAepM,EAAK,iBAAA;wBAC1B,IAAI,CAACmM,KAAyB,CAACC,GAC7B,MAAM,IAAI,MAAM,mEAAmE;wBAErF,IAAMC,IAAW,MAAMF,EAAsBjB,GAAWgB,GAAc1C,CAAgB;wBACtF4C,EAAaC,GAAU,IAAI,WAAWjK,EAAK,MAAA,EAAQA,EAAK,UAAA,EAAYA,EAAK,UAAU,CAAC,GACpFqJ,IAAUY;oBACZ,OACEX,IAAiBtJ,EAAK,UAAA,EACtBqJ,IAAUzL,EAAK,OAAA,CAAQ0L,CAAc,GACrCrJ,EAAO,IAAA,CAAKoJ,CAAO,GACnBzL,EAAK,MAAA,CAAO,GAAA,CAAI,IAAI,WAAWoC,EAAK,MAAA,EAAQA,EAAK,UAAA,EAAYsJ,CAAc,GAAGD,CAAO;gBAEzF,OACEC,IAAiBtJ,EAAK,UAAA,EACtBqJ,IAAUzL,EAAK,OAAA,CAAQ0L,CAAc,GACrCrJ,EAAO,IAAA,CAAKoJ,CAAO,GACnBzL,EAAK,MAAA,CAAO,GAAA,CAAI,IAAI,WAAWoC,EAAK,MAAA,EAAQA,EAAK,UAAA,EAAYsJ,CAAc,GAAGD,CAAO;YAEzF;QACF;QAEA,IAAMzI,IAAQhD,EAAK,SAAA,CAAU,GACvBsM,IAAatM,EAAK,UAAA,CAAW,IAAIwJ,EAAK,MAAM;QAClD,IAAI;YACFA,EAAK,OAAA,CAAQ,CAAC+C,GAAGnD,IAAUpJ,EAAK,QAAA,CAASsM,IAAalD,IAAQnG,GAASsJ,GAAGtJ,MAAY,IAAI,QAAQ,KAAK,CAAC;YACxG,IAAMmI,IAASpL,EAAK,gBAAA,CAClB2F,EAA2B4F,CAAQ,GACnCE,GACAC,GACAY,GACA9C,EAAK,MAAA,EACLtD,GAAyBsF,CAAc,CACzC;YACIJ,MAAW,KACblJ,EAAe,CAAA,8CAAA,EAAiDgJ,CAAS,CAAA,QAAA,EAAW9B,CAAK,CAAA,CAAA,CAAG,GAE9FiC,EAAc,IAAA,CAAKD,CAAM;QAC3B,SAAE;YACApL,EAAK,YAAA,CAAagD,CAAK;QACzB;IACF,GAKa2F,KAAM,OACjBuC,GACAsB,GACAC,GACAC,GACAC,GACAnK,IAC8B;QAC9B,IAAMxC,IAAOQ,EAAY,GACnByC,IAAUjD,EAAK,QAAA,EACfwE,IAAU4D,EAAe,GAAA,CAAI8C,CAAS;QAC5C,IAAI,CAAC1G,GACH,MAAM,IAAI,MAAM,CAAA,0CAAA,EAA6C0G,CAAS,EAAE;QAE1E,IAAM/B,IAAgB3E,CAAAA,CAAQ,CAAC,CAAA,EACzBuF,IAAwBvF,CAAAA,CAAQ,CAAC,CAAA,EACjCwF,IAAyBxF,CAAAA,CAAQ,CAAC,CAAA,EAClC2G,IAAiB3G,CAAAA,CAAQ,CAAC,CAAA,EAC1BiG,IAAqBjG,CAAAA,CAAQ,CAAC,CAAA,EAC9BoI,IAAmBpI,CAAAA,CAAQ,CAAC,CAAA,EAE5B+F,IAAaiC,EAAa,MAAA,EAC1BhC,IAAckC,EAAc,MAAA,EAE9BlJ,IAAmB,GACnBqJ,IAA6B,CAAC,CAAA,EAE5BC,IAA+B,CAAC,CAAA,EAChCC,IAAgC,CAAC,CAAA,EACjCC,IAA8B,CAAC,CAAA,EAE/BC,IAAiBjN,EAAK,SAAA,CAAU,GAChCkN,IAAoBlN,EAAK,UAAA,CAAWuK,IAAatH,CAAO,GACxDkK,IAAmBnN,EAAK,UAAA,CAAWuK,IAAatH,CAAO,GACvDmK,IAAqBpN,EAAK,UAAA,CAAWwK,IAAcvH,CAAO,GAC1DoK,IAAoBrN,EAAK,UAAA,CAAWwK,IAAcvH,CAAO;QAE/D,IAAI;YACF,CAACO,GAAkBqJ,CAAgB,CAAA,GAAIvJ,GAAcd,CAAO,OAE5DuF,kLAAAA,EAAkB,+BAA+B;YAEjD,IAAA,IAAS3C,IAAI,GAAGA,IAAImF,GAAYnF,IAC9B,MAAMsD,GACJ+D,CAAAA,CAAarH,CAAC,CAAA,EACd0H,GACAE,GACA9B,GACAnB,CAAAA,CAAsByC,CAAAA,CAAapH,CAAC,CAAC,CAAA,EACrCoH,CAAAA,CAAapH,CAAC,CAAA,EACdqF,CACF;YAIF,IAAA,IAASrF,IAAI,GAAGA,IAAIoF,GAAapF,IAC/B,MAAMsD,GACJiE,CAAAA,CAAcvH,CAAC,CAAA,EACf2H,GACAC,GACA9B,GACAlB,CAAAA,CAAuB0C,CAAAA,CAActH,CAAC,CAAC,CAAA,EACvCmF,IAAamC,CAAAA,CAActH,CAAC,CAAA,EAC5BqF,CACF;gBAEFzC,gLAAAA,EAAgB,+BAA+B;YAE/C,IAAA,IAAS5C,IAAI,GAAGA,IAAImF,GAAYnF,IAC9BpF,EAAK,QAAA,CAASkN,IAAoB9H,IAAInC,GAAS6J,CAAAA,CAAmB1H,CAAC,CAAA,EAAG,GAAG,GACzEpF,EAAK,QAAA,CAASmN,IAAmB/H,IAAInC,GAAS8G,CAAAA,CAAsByC,CAAAA,CAAapH,CAAC,CAAC,CAAA,EAAG,GAAG;YAE3F,IAAA,IAASA,IAAI,GAAGA,IAAIoF,GAAapF,IAC/BpF,EAAK,QAAA,CAASoN,IAAqBhI,IAAInC,GAAS8J,CAAAA,CAAoB3H,CAAC,CAAA,EAAG,GAAG,GAC3EpF,EAAK,QAAA,CAASqN,IAAoBjI,IAAInC,GAAS+G,CAAAA,CAAuB0C,CAAAA,CAActH,CAAC,CAAC,CAAA,EAAG,GAAG;YAyD9FpF,EAAK,cAAA,GAAiBmJ,CAAa,GACnCnJ,EAAK,eAAA,GAAkBmJ,CAAa;YAEpC,IAAIhG;YAUFA,IAAY,MAAMnD,EAAK,OAAA,CACrBmJ,GACAgE,GACAD,GACA3C,GACA8C,GACA7C,GACA4C,GACA5J,CACF,GAGEL,MAAc,KAChBjB,EAAe,0BAA0B;YAG3C,IAAMoL,IAA2B,CAAC,CAAA,EAC5BC,KAA4D,CAAC,CAAA;gBAEnExF,kLAAAA,EAAkB,0BAA0B;YAC5C,IAAA,IAAS3C,IAAI,GAAGA,IAAIoF,GAAapF,IAAK;gBACpC,IAAMgG,IAAS,OAAOpL,EAAK,QAAA,CAASoN,IAAqBhI,IAAInC,GAAS,GAAG,CAAC;gBAC1E,IAAImI,MAAW2B,CAAAA,CAAoB3H,CAAC,CAAA,EAAG;oBAErCkI,EAAO,IAAA,CAAKX,CAAAA,CAAcvH,CAAC,CAAE;oBAC7B;gBACF;gBAEA,IAAMoI,KAA2BxN,EAAK,SAAA,CAAU,GAE1CyN,IAAmBzN,EAAK,UAAA,CAAW,IAAIiD,CAAO,GAEhDyK,IAAmB,CAAA,GACnBtH,GACF7D,IAAa;gBACf,IAAI;oBACgBvC,EAAK,iBAAA,CACrBoL,GACAqC,GACAA,IAAmBxK,GACnBwK,IAAmB,IAAIxK,GAEvBwK,IAAmB,IAAIxK,CACzB,MACkB,KAChBf,EAAe,CAAA,yCAAA,EAA4CkD,CAAC,CAAA,CAAA,CAAG;oBAEjE,IAAMuI,KAAY1K,MAAY,IAAI,QAAQ,OACpCsI,KAAW,OAAOvL,EAAK,QAAA,CAASyN,GAAkBE,EAAS,CAAC;oBAClEpL,IAAavC,EAAK,QAAA,CAASyN,IAAmBxK,GAAS,GAAG;oBAC1D,IAAMqJ,KAAatM,EAAK,QAAA,CAASyN,IAAmBxK,IAAU,GAAG,GAAG,GAC9D2K,KAAa,OAAO5N,EAAK,QAAA,CAASyN,IAAmBxK,IAAU,GAAG0K,EAAS,CAAC,GAC5EnE,IAAO,CAAC,CAAA;oBACd,IAAA,IAASpE,IAAI,GAAGA,IAAIwI,IAAYxI,IAC9BoE,EAAK,IAAA,CAAK,OAAOxJ,EAAK,QAAA,CAASsM,KAAalH,IAAInC,GAAS0K,EAAS,CAAC,CAAC;oBAElE3N,EAAK,QAAA,CAASsM,EAAU,MAAM,KAChCpK,EAAe,oCAAoC;oBAErD,IAAMuE,IAAO+C,EAAK,MAAA,CAAO,CAAC9C,GAAGC,IAAMD,IAAIC,GAAG,CAAC;oBAC3CP,IAAOR,GAA2B2F,EAAQ;oBAE1C,IAAMsC,IAAoB1C,GAAgB,wBAAA,CAAyBuB,CAAAA,CAActH,CAAC,CAAC,CAAA;oBAEnF,IAAIgB,MAAS,UAAU;wBACrB,IAAIyH,MAAsB,gBAAgBA,MAAsB,aAC9D,MAAM,IAAI,MAAM,wCAAwC;wBAE1D,IAAMC,IAAuB,CAAC,CAAA;wBAC9B,IAAA,IAAS1I,IAAI,GAAGA,IAAIqB,GAAMrB,IAAK;4BAC7B,IAAMwC,IAAS5H,EAAK,QAAA,CAASuC,IAAa6C,IAAInC,GAAS,GAAG,GACpD8K,KAAa/N,EAAK,QAAA,CAASuC,IAAAA,CAAc6C,IAAI,CAAA,IAAKnC,GAAS,GAAG,GAC9D+K,KAAiB5I,MAAMqB,IAAO,IAAI,KAAA,IAAYsH,KAAanG;4BACjEkG,EAAW,IAAA,CAAK9N,EAAK,YAAA,CAAa4H,GAAQoG,EAAc,CAAC;wBAC3D;wBACAV,EAAO,IAAA,CAAK;4BAAClH;4BAAMoD;4BAAMsE;4BAAY,KAAK;yBAAC;oBAC7C,OAAA,IAGMD,MAAsB,gBAAgBpH,IAAO,GAAG;wBAClD,IAAMwH,IAAgEjO,EAAK,aAAA;wBAC3E,IAAI,CAACiO,GACH,MAAM,IAAI,MAAM,uEAAuE;wBAEzF,IAAMtC,IAAYsC,EAAU1L,CAAU,GAChC2L,IAAarI,EAA2B0F,IAAU9E,CAAI;wBAC5D,IAAIyH,MAAe,KAAA,KAAa,CAAClI,GAAyBI,CAAI,GAC5D,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0BA,CAAI,EAAE;wBAIlDsH,IAAmB,CAAA,GAwBjBJ,EAAO,IAAA,CAAK;4BACVlH;4BACAoD;4BACA;gCACE,WAAAmC;gCACA,UAAU3L,EAAK,oBAAA,CAAsB2L,GAAWuC,GAAY9H,CAAI;gCAChE,SAAS,IAAM;oCACTpG,EAAK,iBAAA,CAAkBoL,CAAM,MAAM,KACrClJ,EAAe,uBAAuB;gCAE1C;4BACF;4BACA,YACF;yBAAC;oBAEL,OAAA,IAAW2L,MAAsB,eAAepH,IAAO,GAAG;wBACxD,IAAM0H,IAAenO,EAAK,iBAAA,EACpBoO,IAAkCpO,EAAK,oCAAA;wBAC7C,IAAI,CAACmO,KAAgB,CAACC,GACpB,MAAM,IAAI,MAAM,qEAAqE;wBAGvF,IADmBvI,EAA2B0F,IAAU9E,CAAI,MACzC,KAAA,KAAa,CAACR,GAAwBG,CAAI,GAC3D,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0BA,CAAI,EAAE;wBAElD,IAAI,CAACgI,EAAgClD,GAAW9E,GAAM,CAAA,CAAK,GACzD,MAAM,IAAI,MACR,CAAA,kCAAA,EAAqCA,CAAI,CAAA,kDAAA,CAC3C;wBAMF,IAAMyF,KAAW,MAAMsC,EAAajD,GAAW3I,GAAYgJ,IAAU/B,GAAM,CAAA,CAAK;wBAGhFkE,IAAmB,CAAA,GAEnBJ,EAAO,IAAA,CAAK;4BACVlH;4BACAoD;4BACA;gCACE,UAAAqC;gCACA,UAAU7L,EAAK,6BAAA,CAA+BuC,GAAY6D,CAAI;gCAC9D,SAAS,IAAM;oCACbpG,EAAK,oBAAA,CAAsBuC,CAAU,GACrCvC,EAAK,iBAAA,CAAkBoL,CAAM;gCAC/B;4BACF;4BACA,WACF;yBAAC;oBACH,OAAA,IAAWyC,MAAsB,0BAA0BpH,IAAO,GAAG;wBACnE,IAAMrE,IAAOpC,EAAK,6BAAA,CAA+BuC,GAAY6D,CAAgC,EAAE,GACzFgD,IAAQkE,EAAO,MAAA;wBAErBI,IAAmB,CAAA,GACnBH,GAAe,IAAA,CAAA,CACZ,SAAY;4BACX,IAAMc,IAAoC;gCAACjF;gCAAO,MAAMhH,CAAI;6BAAA;4BAC5D,OAAApC,EAAK,oBAAA,CAAsBuC,CAAU,GACrCvC,EAAK,iBAAA,CAAkBoL,CAAM,GACtBiD;wBACT,CAAA,EAAG,CACL,GACAf,EAAO,IAAA,CAAK;4BAAClH;4BAAMoD;4BAAM,CAAC,CAAA;4BAAG,KAAK;yBAAC;oBACrC,OAAO;wBACL,IAAM8E,IAAwBxI,GAAkCM,CAAI,GAC9DhE,IAAO,IAAIkM,EAAsB7H,CAAI;wBAC3C,IAAI,WAAWrE,EAAK,MAAA,EAAQA,EAAK,UAAA,EAAYA,EAAK,UAAU,EAAE,GAAA,CAC5DpC,EAAK,MAAA,CAAO,QAAA,CAASuC,GAAYA,IAAaH,EAAK,UAAU,CAC/D,GACAkL,EAAO,IAAA,CAAK;4BAAClH;4BAAMoD;4BAAMpH;4BAAM,KAAK;yBAAC;oBACvC;gBAEJ,SAAE;oBACApC,EAAK,YAAA,CAAawN,EAAwB,GACtCpH,MAAS,YAAY7D,KACvBvC,EAAK,KAAA,CAAMuC,CAAU,GAElBmL,KACH1N,EAAK,iBAAA,CAAkBoL,CAAM;gBAEjC;YACF;YAEID,KAAkB,CAACV,KAAAA,CACjBzK,EAAK,qBAAA,CAAsBmL,EAAe,MAAM,MAAM,KACxDjJ,EAAe,4BAA4B,GAE7CkG,EAAe,GAAA,CAAI8C,GAAW;gBAC5B/B;gBACAY;gBACAC;gBACAmB;gBACAV;gBACA,CAAA,CACF;aAAC,CAAA;YAGH,KAAA,IAAW,CAACrB,GAAOhH,CAAI,CAAA,KAAK,MAAM,QAAQ,GAAA,CAAImL,GAAc,EAC1DD,CAAAA,CAAOlE,CAAK,CAAA,CAAE,CAAC,CAAA,GAAIhH;YAErB,OAAA4F,oLAAAA,EAAgB,0BAA0B,GACnCsF;QACT,SAAE;YACAtN,EAAK,aAAA,GAAgBmJ,CAAa,GAElCnJ,EAAK,YAAA,CAAaiN,CAAc,GAchCH,EAAmB,OAAA,EAASyB,IAAMvO,EAAK,iBAAA,CAAkBuO,CAAC,CAAC,GAC3DxB,EAAoB,OAAA,EAASwB,IAAMvO,EAAK,iBAAA,CAAkBuO,CAAC,CAAC,GAC5DvB,EAAkB,OAAA,EAASwB,IAAMxO,EAAK,KAAA,CAAMwO,CAAC,CAAC,GAE1ChL,MAAqB,KACvBxD,EAAK,qBAAA,CAAsBwD,CAAgB,GAE7CqJ,EAAiB,OAAA,CAAS2B,KAAMxO,EAAK,KAAA,CAAMwO,CAAC,CAAC;QAC/C;IACF,GAKa5F,MAAgBsC,GAA4B;QACvD,IAAMlL,IAAOQ,EAAY,GACnBgE,IAAU4D,EAAe,GAAA,CAAI8C,CAAS;QAC5C,IAAI,CAAC1G,GACH,MAAM,IAAI,MAAM,oBAAoB;QAEtC,IAAM2E,IAAgB3E,CAAAA,CAAQ,CAAC,CAAA,EAGzBiK,IAAkBzO,EAAK,gBAAA,CAAiBmJ,CAAa;QACvDsF,MAAoB,KACtBvM,EAAe,iCAAiC,GAElDlC,EAAK,QAAA,CAASyO,CAAe;IAC/B;AAAA;;ACllCA,IAsBIvO,IACAD,IACAE,IAwDSuO,IAiFAC,IAaApG,IAaAC,IAwBAC,IAaAE,IAgCAC,IAhQbgG,KAAAxQ,EAAA;IAAA;IAYAyK;IACApI;IACAxB;IAQIiB,KAAe,CAAA,GACfD,KAAc,CAAA,GACdE,KAAU,CAAA,GAwDDuO,KAAqC,SAA2B;QAC3E,IAAI,CAAAzO,IAGJ;YAAA,IAAIC,IACF,MAAM,IAAI,MAAM,0CAA0C;YAE5D,IAAIC,IACF,MAAM,IAAI,MAAM,uCAAuC;YAGzDD,KAAe,CAAA;YAyDb,IAAI;gBACF,MAAMK,GAAsBwI,kKAAAA,CAAI,IAAI,GACpC,MAAWb,GAAYa,kKAAG,GAC1B9I,KAAc,CAAA;YAChB,EAAA,OAAS,GAAG;gBACV,MAAAE,KAAU,CAAA,GACJ;YACR,SAAE;gBACAD,KAAe,CAAA;YACjB;QAAA;IAEJ,GAEayO,KAAkB,OAAO/J,GAAkC;QASpE,MAAWuD,GAAOY,kKAAAA,EAAKnE,CAAM;IAEjC,GAEa2D,KAAyB,OAAOb,IAS7Ba,GAAuBb,CAAM,GAIhCc,KAAgB,OAC3BkB,GACAlH,IAkBcgG,GAAckB,GAAOlH,CAAO,GAI/BiG,KAAiB,OAAOyC,GAAqC;QASjEzC,GAAeyC,CAAS;IAEjC,GAEavC,KAAM,OACjBuC,GACAsB,GACAqC,GACAnC,GACAoC,GACAtM,IAsBcmG,GAAIuC,GAAWsB,GAAcqC,GAAQnC,GAAeoC,GAAStM,CAAO,GAIvEoG,KAAe,OAAOsC,GAAqC;QAS/DtC,GAAasC,CAAS;IAE/B;AAAA;;AC3QA,IAkBagE,IAaAC,IAyBAC,IAxDbC,KAAAjR,EAAA;IAAA;IAaAwQ;IACAzI;IACAhI;IACA4I;IAEamI,KAAuB,CAAC9D,GAAgBkE,IAA0C;QAC7F,OAAQlE,EAAO,QAAA,CAAU;YACvB,KAAK;gBACH,OAAO;oBAACA,EAAO,IAAA;oBAAMA,EAAO,IAAA;oBAAMA,EAAO,IAAA;oBAAM,KAAK;iBAAA;YACtD,KAAK;gBACH,OAAO;oBAACA,EAAO,IAAA;oBAAMA,EAAO,IAAA;oBAAM;wBAAE,WAAWA,EAAO;oBAAU;oBAAG,YAAY;iBAAA;YACjF,KAAK;gBACH,OAAO;oBAACA,EAAO,IAAA;oBAAMA,EAAO,IAAA;oBAAM;wBAAE,UAAUA,EAAO;oBAAS;oBAAG,WAAW;iBAAA;YAC9E;gBACE,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0BA,EAAO,QAAQ,CAAA,KAAA,EAAQkE,EAAQ,CAAC,EAAE;QAChF;IACF,GAEaH,MAAwB/D,GAAmC;QACtE,OAAQA,CAAAA,CAAO,CAAC,CAAA,CAAG;YACjB,KAAK;gBACH,OAAO,IAAI2D,wKAAAA,CAAO3D,CAAAA,CAAO,CAAC,CAAA,EAAGA,CAAAA,CAAO,CAAC,CAAA,EAAGA,CAAAA,CAAO,CAAC,CAAC;YACnD,KAAK;gBAAc;oBACjB,IAAMG,IAAWH,CAAAA,CAAO,CAAC,CAAA;oBACzB,IAAI,CAACpF,GAAyBuF,CAAQ,GACpC,MAAM,IAAI,MAAM,CAAA,yBAAA,EAA4BA,CAAQ,CAAA,6BAAA,CAA+B;oBAErF,IAAM,EAAE,WAAAI,CAAAA,EAAW,UAAA4D,CAAAA,EAAU,SAAAC,CAAQ,EAAA,GAAIpE,CAAAA,CAAO,CAAC,CAAA;oBACjD,OAAO2D,wKAAAA,CAAO,aAAA,CAAcpD,GAAW;wBAAE,UAAAJ;wBAAU,MAAMH,CAAAA,CAAO,CAAC,CAAA;wBAAG,UAAAmE;wBAAU,SAAAC;oBAAQ,CAAC;gBACzF;YACA,KAAK;gBAAa;oBAChB,IAAMjE,IAAWH,CAAAA,CAAO,CAAC,CAAA;oBACzB,IAAI,CAACnF,GAAwBsF,CAAQ,GACnC,MAAM,IAAI,MAAM,CAAA,yBAAA,EAA4BA,CAAQ,CAAA,kCAAA,CAAoC;oBAE1F,IAAM,EAAE,UAAAM,CAAAA,EAAU,UAAA0D,CAAAA,EAAU,SAAAC,CAAQ,EAAA,GAAIpE,CAAAA,CAAO,CAAC,CAAA;oBAChD,OAAO2D,wKAAAA,CAAO,YAAA,CAAalD,GAAU;wBAAE,UAAAN;wBAAU,MAAMH,CAAAA,CAAO,CAAC,CAAA;wBAAG,UAAAmE;wBAAU,SAAAC;oBAAQ,CAAC;gBACvF;YACA;gBACE,MAAM,IAAI,MAAM,CAAA,uBAAA,EAA0BpE,CAAAA,CAAO,CAAC,CAAC,EAAE;QACzD;IACF,GAEagE,KAAN,KAA8E;QAQnF,MAAM,8BAA8BlF,CAAAA,EAAmD;YAErF,OAAO3B,GAAuB,MAAMzB,EAASoD,CAAI,CAAC;QACpD;QAEA,MAAM,UAAUuF,CAAAA,EAAmCjN,CAAAA,EAA0D;gBAC3GwM,iLAAAA,CAAiB;YACjB,IAAItF;YAEA,OAAO+F,KAAiB,WACtBvR,IAEFwL,IAAQ,MAAM5C,EAAS2I,CAAY,IAInC/F,IAAQ,MAAM,IAAA,CAAK,6BAAA,CAA8B+F,CAAY,IAG/D/F,IAAQ+F,GAGV,CAAC,IAAA,CAAK,SAAA,EAAW,IAAA,CAAK,UAAA,EAAY,IAAA,CAAK,WAAA,EAAa,IAAA,CAAK,aAAA,EAAe,IAAA,CAAK,cAAc,CAAA,GAAI,MAAMjH,GACnGkB,GACAlH,CACF,OACAyM,+KAAAA,CAAe;QACjB;QAEA,MAAM,UAAyB;YAC7B,OAAOxG,GAAe,IAAA,CAAK,SAAS;QACtC;QAEA,MAAM,IACJiH,CAAAA,EACAC,CAAAA,EACAnN,CAAAA,EACoC;gBACpCwM,iLAAAA,CAAiB;YACjB,IAAMY,IAAuB,CAAC,CAAA,EACxBpD,IAAyB,CAAC,CAAA;YAChC,OAAO,OAAA,CAAQkD,CAAK,EAAE,OAAA,EAASG,GAAQ;gBACrC,IAAM/M,IAAO+M,CAAAA,CAAI,CAAC,CAAA,EACZzE,IAASyE,CAAAA,CAAI,CAAC,CAAA,EACdzG,IAAQ,IAAA,CAAK,UAAA,CAAW,OAAA,CAAQtG,CAAI;gBAC1C,IAAIsG,MAAU,CAAA,GACZ,MAAM,IAAI,MAAM,CAAA,eAAA,EAAkBtG,CAAI,CAAA,CAAA,CAAG;gBAE3C8M,EAAW,IAAA,CAAKxE,CAAM,GACtBoB,EAAa,IAAA,CAAKpD,CAAK;YACzB,CAAC;YAED,IAAM0G,IAAoC,CAAC,CAAA,EACrCpD,IAA0B,CAAC,CAAA;YACjC,OAAO,OAAA,CAAQiD,CAAO,EAAE,OAAA,EAASE,GAAQ;gBACvC,IAAM/M,IAAO+M,CAAAA,CAAI,CAAC,CAAA,EACZzE,IAASyE,CAAAA,CAAI,CAAC,CAAA,EACdzG,IAAQ,IAAA,CAAK,WAAA,CAAY,OAAA,CAAQtG,CAAI;gBAC3C,IAAIsG,MAAU,CAAA,GACZ,MAAM,IAAI,MAAM,CAAA,gBAAA,EAAmBtG,CAAI,CAAA,CAAA,CAAG;gBAE5CgN,EAAY,IAAA,CAAK1E,CAAM,GACvBsB,EAAc,IAAA,CAAKtD,CAAK;YAC1B,CAAC;YAED,IAAMyF,IAASe,EAAW,GAAA,CAAI,CAACG,GAAG3K,IAChC8J,GAAqBa,GAAG,IAAM,CAAA,OAAA,EAAU,IAAA,CAAK,UAAA,CAAWvD,CAAAA,CAAapH,CAAC,CAAC,CAAC,CAAA,CAAA,CAAG,CAC7E,GACM0J,IAAUgB,EAAY,GAAA,CAAI,CAACC,GAAG3K,IAClC2K,IAAIb,GAAqBa,GAAG,IAAM,CAAA,QAAA,EAAW,IAAA,CAAK,WAAA,CAAYrD,CAAAA,CAActH,CAAC,CAAC,CAAC,CAAA,CAAA,CAAG,IAAI,IACxF,GAEM4K,IAAU,MAAMrH,GAAI,IAAA,CAAK,SAAA,EAAW6D,GAAcqC,GAAQnC,GAAeoC,GAAStM,CAAO,GAEzFyN,IAAuC,CAAC;YAC9C,IAAA,IAAS7K,IAAI,GAAGA,IAAI4K,EAAQ,MAAA,EAAQ5K,IAClC6K,CAAAA,CAAU,IAAA,CAAK,WAAA,CAAYvD,CAAAA,CAActH,CAAC,CAAC,CAAC,CAAA,GAAI0K,CAAAA,CAAY1K,CAAC,CAAA,IAAK+J,GAAqBa,CAAAA,CAAQ5K,CAAC,CAAC;YAEnG,WAAA6J,+KAAAA,CAAe,IACRgB;QACT;QAEA,iBAAuB,CAEvB;QAEA,eAAqB;YACdrH,GAAa,IAAA,CAAK,SAAS;QAClC;IACF;AAAA;ACzJA,IAAAsH,KAAA,CAAA;AAAAC,GAAAD,IAAA;IAAA,+BAAA,IAAAE;IAAA,iBAAA,IAAAC;IAAA,aAAA,IAAAC;AAAAA,GAGA,OAAkB,OAAAvH,MAAsD;;AAHxE,IAcasH,IA4CAD,IAqCAE,IA/FbC,KAAAnS,EAAA;IAAA;IAKAwQ;IACAS;IAQagB,KAAkB,IAAY;QAAA,CACrC,OAAOtH,kKAAAA,CAAI,IAAA,CAAK,WAAA,IAAgB,YAAYA,kKAAAA,CAAI,IAAA,CAAK,WAAA,GAAc,CAAA,KAAA,CACrEA,kKAAAA,CAAI,IAAA,CAAK,WAAA,GAAc,CAAA;QAGzB,IAAMyH,IAAOzH,kKAAAA,CAAI,IAAA,CAAK,IAAA;QAiBtB,IAhBI,OAAOyH,KAAS,aAAaA,MAAS,KAAA,KAAaA,MAAS,WAAWA,MAAS,aAAA,CAElF,QAAQ,IAAA,CACN,CAAA,kDAAA,EAAqDA,CAAI,CAAA,0DAAA,CAC3D,GACAzH,kKAAAA,CAAI,IAAA,CAAK,IAAA,GAAO,CAAA,CAAA,GAGd,OAAOA,kKAAAA,CAAI,IAAA,CAAK,KAAA,IAAU,aAAA,CAC5BA,kKAAAA,CAAI,IAAA,CAAK,KAAA,GAAQ,CAAA,CAAA,GAGf,OAAOA,kKAAAA,CAAI,IAAA,CAAK,KAAA,IAAU,aAAA,CAC5BA,kKAAAA,CAAI,IAAA,CAAK,KAAA,GAAQ,CAAA,CAAA,GAGf,OAAOA,kKAAAA,CAAI,IAAA,CAAK,UAAA,IAAe,YAAY,CAAC,OAAO,SAAA,CAAUA,kKAAAA,CAAI,IAAA,CAAK,UAAU,KAAKA,kKAAAA,CAAI,IAAA,CAAK,UAAA,IAAc,GAY9G,IAAI,OAAO,OAAS,OAAe,CAAC,KAAK,mBAAA,EACvCA,kKAAAA,CAAI,IAAA,CAAK,UAAA,GAAa;aACjB;YACL,IAAM0H,IACJ,OAAO,YAAc,MAAc,GAAQ,SAAS,EAAE,IAAA,CAAK,EAAE,MAAA,GAAS,UAAU,mBAAA;YAClF1H,kKAAAA,CAAI,IAAA,CAAK,UAAA,GAAa,KAAK,GAAA,CAAI,GAAG,KAAK,IAAA,CAAA,CAAM0H,KAAsB,CAAA,IAAK,CAAC,CAAC;QAC5E;IAEJ,GAEaL,KAAN,KAAuD;QAS5D,MAAM,KAAKM,CAAAA,EAAoC;YAE7CL,GAAgB,GAGhB,MAAM3B,GAAmC,GAGzC,MAAMC,GAAgB+B,CAAW;QACnC;QASA,MAAM,8BACJjB,CAAAA,EACAjN,CAAAA,EACkC;YAClC,IAAMG,IAAU,IAAIyM;YACpB,OAAA,MAAMzM,EAAQ,SAAA,CAAU8M,GAAcjN,CAAO,GACtCG;QACT;IACF,GAEa2N,KAAc,IAAIF;AAAAA,GCtF/B,WAAc;;;;ACHP,IAAMS,KAAU;ADKvB,IAAOC,KAAQH;AAwBe;IAC5B,IAAML,IAAc,CAAA,MAAA,GAAA,GAAA,EAA0B,WAAA;QAO9CM,kLAAAA,EAAgB,OAAON,GAAa,EAAE,OACtCM,kLAAAA,EAAgB,QAAQN,GAAa,EAAE;AACzC,CAEA,OAAO,cAAA,CAAevH,kKAAAA,CAAI,QAAA,EAAU,OAAO;IAAE,OAAO8H;IAAS,YAAY,CAAA;AAAK,CAAC"}}]
}